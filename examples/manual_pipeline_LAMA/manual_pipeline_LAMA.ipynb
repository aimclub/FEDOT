{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6bffc52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, accuracy_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d4cb5da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 8 # threads cnt for lgbm and linear models\n",
    "N_FOLDS = 5 # folds cnt for AutoML\n",
    "RANDOM_STATE = 30 # fixed random state for various reasons\n",
    "TEST_SIZE = 0.2 # Test size for metric check\n",
    "TARGET_NAME = 'TARGET' # Target column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e597f043",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = './test_data_files'\n",
    "DATASET_NAME = 'sampled_app_train.csv'\n",
    "DATASET_FULLNAME = os.path.join(DATASET_DIR, DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fd9f212c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313802</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>327024.0</td>\n",
       "      <td>15372.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>319656</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>108000.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>19737.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207678</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>381593</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>142200.0</td>\n",
       "      <td>9630.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>258153</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>337500.0</td>\n",
       "      <td>1483231.5</td>\n",
       "      <td>46570.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      313802       0         Cash loans           M            N   \n",
       "1      319656       0         Cash loans           F            N   \n",
       "2      207678       0    Revolving loans           F            Y   \n",
       "3      381593       0         Cash loans           F            N   \n",
       "4      258153       0         Cash loans           F            Y   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          270000.0    327024.0      15372.0   \n",
       "1               N             0          108000.0    675000.0      19737.0   \n",
       "2               Y             2          112500.0    270000.0      13500.0   \n",
       "3               N             1           67500.0    142200.0       9630.0   \n",
       "4               Y             0          337500.0   1483231.5      46570.5   \n",
       "\n",
       "   ...  FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                 0                0                0                0   \n",
       "1  ...                 0                0                0                0   \n",
       "2  ...                 0                0                0                0   \n",
       "3  ...                 0                0                0                0   \n",
       "4  ...                 0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                       0.0   \n",
       "3                        0.0                       0.0   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         0.0                        0.0   \n",
       "4                         0.0                        2.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         1.0  \n",
       "1                        0.0                         0.0  \n",
       "2                        0.0                         1.0  \n",
       "3                        0.0                         4.0  \n",
       "4                        0.0                         0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(DATASET_FULLNAME)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "48c175bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 122 entries, SK_ID_CURR to AMT_REQ_CREDIT_BUREAU_YEAR\n",
      "dtypes: float64(65), int64(41), object(16)\n",
      "memory usage: 9.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9aa82bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BIRTH_DATE'] = (np.datetime64('2018-01-01') + data['DAYS_BIRTH'].astype(np.dtype('timedelta64[D]'))).astype(str)\n",
    "data['EMP_DATE'] = (np.datetime64('2018-01-01') + np.clip(data['DAYS_EMPLOYED'], None, 0).astype(np.dtype('timedelta64[D]'))\n",
    "                    ).astype(str)\n",
    "\n",
    "data['constant'] = 1\n",
    "data['allnan'] = np.nan\n",
    "\n",
    "data['report_dt'] = np.datetime64('2018-01-01')\n",
    "\n",
    "data.drop(['DAYS_BIRTH', 'DAYS_EMPLOYED'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63fddcb",
   "metadata": {},
   "source": [
    "![AutoML pipeline for this task](tutorial_1_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178a2678",
   "metadata": {},
   "source": [
    "### SimpleFeatures for TreeBasedModel\n",
    "\n",
    "- Numeric stay as is, Datetime transforms to numeric.\n",
    "- Categorical label encoding.\n",
    "- Maps input to output features exactly one-to-one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e289b7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = data._get_numeric_data().columns\n",
    "date_columns = ['BIRTH_DATE', 'EMP_DATE']\n",
    "categorycal_columns = list(set(data.columns) - set(numerical_columns) - set(date_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0cabf547",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fe058716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>EMP_DATE</th>\n",
       "      <th>constant</th>\n",
       "      <th>allnan</th>\n",
       "      <th>report_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313802</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>327024.0</td>\n",
       "      <td>15372.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1967-02-08</td>\n",
       "      <td>2017-05-20</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>319656</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>108000.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>19737.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1962-05-19</td>\n",
       "      <td>2007-07-16</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207678</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1991-11-14</td>\n",
       "      <td>2015-01-21</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>381593</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>142200.0</td>\n",
       "      <td>9630.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1986-09-25</td>\n",
       "      <td>2011-10-13</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>258153</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>337500.0</td>\n",
       "      <td>1483231.5</td>\n",
       "      <td>46570.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1981-11-08</td>\n",
       "      <td>2013-02-21</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      313802       0         Cash loans           M            N   \n",
       "1      319656       0         Cash loans           F            N   \n",
       "2      207678       0    Revolving loans           F            Y   \n",
       "3      381593       0         Cash loans           F            N   \n",
       "4      258153       0         Cash loans           F            Y   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          270000.0    327024.0      15372.0   \n",
       "1               N             0          108000.0    675000.0      19737.0   \n",
       "2               Y             2          112500.0    270000.0      13500.0   \n",
       "3               N             1           67500.0    142200.0       9630.0   \n",
       "4               Y             0          337500.0   1483231.5      46570.5   \n",
       "\n",
       "   ...  AMT_REQ_CREDIT_BUREAU_DAY AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
       "0  ...                        0.0                        0.0   \n",
       "1  ...                        0.0                        0.0   \n",
       "2  ...                        0.0                        0.0   \n",
       "3  ...                        0.0                        0.0   \n",
       "4  ...                        0.0                        0.0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_MON AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       2.0                       0.0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_YEAR  BIRTH_DATE    EMP_DATE  constant  allnan  \\\n",
       "0                        1.0  1967-02-08  2017-05-20         1     NaN   \n",
       "1                        0.0  1962-05-19  2007-07-16         1     NaN   \n",
       "2                        1.0  1991-11-14  2015-01-21         1     NaN   \n",
       "3                        4.0  1986-09-25  2011-10-13         1     NaN   \n",
       "4                        0.0  1981-11-08  2013-02-21         1     NaN   \n",
       "\n",
       "   report_dt  \n",
       "0 2018-01-01  \n",
       "1 2018-01-01  \n",
       "2 2018-01-01  \n",
       "3 2018-01-01  \n",
       "4 2018-01-01  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca938a8",
   "metadata": {},
   "source": [
    "#### LavelEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "085c47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_col in categorycal_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[cat_col] = le.fit_transform(df[cat_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d033515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>EMP_DATE</th>\n",
       "      <th>constant</th>\n",
       "      <th>allnan</th>\n",
       "      <th>report_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>327024.0</td>\n",
       "      <td>15372.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1967-02-08</td>\n",
       "      <td>2017-05-20</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>319656</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108000.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>19737.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1962-05-19</td>\n",
       "      <td>2007-07-16</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207678</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1991-11-14</td>\n",
       "      <td>2015-01-21</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>381593</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>142200.0</td>\n",
       "      <td>9630.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1986-09-25</td>\n",
       "      <td>2011-10-13</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>258153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>337500.0</td>\n",
       "      <td>1483231.5</td>\n",
       "      <td>46570.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1981-11-08</td>\n",
       "      <td>2013-02-21</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET  NAME_CONTRACT_TYPE  CODE_GENDER  FLAG_OWN_CAR  \\\n",
       "0      313802       0                   0            1             0   \n",
       "1      319656       0                   0            0             0   \n",
       "2      207678       0                   1            0             1   \n",
       "3      381593       0                   0            0             0   \n",
       "4      258153       0                   0            0             1   \n",
       "\n",
       "   FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0                1             0          270000.0    327024.0      15372.0   \n",
       "1                0             0          108000.0    675000.0      19737.0   \n",
       "2                1             2          112500.0    270000.0      13500.0   \n",
       "3                0             1           67500.0    142200.0       9630.0   \n",
       "4                1             0          337500.0   1483231.5      46570.5   \n",
       "\n",
       "   ...  AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
       "0  ...                        0.0                         0.0   \n",
       "1  ...                        0.0                         0.0   \n",
       "2  ...                        0.0                         0.0   \n",
       "3  ...                        0.0                         0.0   \n",
       "4  ...                        0.0                         0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        2.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_YEAR  BIRTH_DATE    EMP_DATE  constant  allnan  \\\n",
       "0                         1.0  1967-02-08  2017-05-20         1     NaN   \n",
       "1                         0.0  1962-05-19  2007-07-16         1     NaN   \n",
       "2                         1.0  1991-11-14  2015-01-21         1     NaN   \n",
       "3                         4.0  1986-09-25  2011-10-13         1     NaN   \n",
       "4                         0.0  1981-11-08  2013-02-21         1     NaN   \n",
       "\n",
       "   report_dt  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea6a7d8",
   "metadata": {},
   "source": [
    "#### One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dbb460c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_col in categorycal_columns:\n",
    "    le = OneHotEncoder(handle_unknown='error', drop='if_binary')\n",
    "    a = le.fit_transform(df[[cat_col]]).toarray()\n",
    "    shift = df.columns[-1]\n",
    "    if not isinstance(shift, int):\n",
    "        shift = 0\n",
    "    end_col = pd.DataFrame(data=a, columns=np.arange(a.shape[1]) + shift + 1)\n",
    "    df = df.join(end_col)\n",
    "    df.drop(axis=1, inplace=True, columns=[cat_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3676d429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>...</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>327024.0</td>\n",
       "      <td>15372.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>0.072508</td>\n",
       "      <td>-2432.0</td>\n",
       "      <td>-2137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>319656</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108000.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>19737.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>0.035792</td>\n",
       "      <td>-13156.0</td>\n",
       "      <td>-3758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207678</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>0.031329</td>\n",
       "      <td>-4077.0</td>\n",
       "      <td>-1058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>381593</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>142200.0</td>\n",
       "      <td>9630.0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>0.008474</td>\n",
       "      <td>-5106.0</td>\n",
       "      <td>-1556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>258153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>337500.0</td>\n",
       "      <td>1483231.5</td>\n",
       "      <td>46570.5</td>\n",
       "      <td>1354500.0</td>\n",
       "      <td>0.008474</td>\n",
       "      <td>-5743.0</td>\n",
       "      <td>-4256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
       "0      313802       0             0          270000.0    327024.0   \n",
       "1      319656       0             0          108000.0    675000.0   \n",
       "2      207678       0             2          112500.0    270000.0   \n",
       "3      381593       0             1           67500.0    142200.0   \n",
       "4      258153       0             0          337500.0   1483231.5   \n",
       "\n",
       "   AMT_ANNUITY  AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  \\\n",
       "0      15372.0         270000.0                    0.072508   \n",
       "1      19737.0         675000.0                    0.035792   \n",
       "2      13500.0         270000.0                    0.031329   \n",
       "3       9630.0         112500.0                    0.008474   \n",
       "4      46570.5        1354500.0                    0.008474   \n",
       "\n",
       "   DAYS_REGISTRATION  DAYS_ID_PUBLISH  ...  129  130  131  132  133  134  135  \\\n",
       "0            -2432.0            -2137  ...  0.0  0.0  1.0  0.0  1.0  0.0  0.0   \n",
       "1           -13156.0            -3758  ...  0.0  0.0  1.0  0.0  1.0  0.0  0.0   \n",
       "2            -4077.0            -1058  ...  0.0  0.0  1.0  0.0  0.0  1.0  0.0   \n",
       "3            -5106.0            -1556  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "4            -5743.0            -4256  ...  0.0  0.0  1.0  0.0  1.0  0.0  0.0   \n",
       "\n",
       "   136  137  138  \n",
       "0  0.0  0.0  1.0  \n",
       "1  0.0  0.0  1.0  \n",
       "2  0.0  0.0  1.0  \n",
       "3  0.0  1.0  1.0  \n",
       "4  0.0  0.0  1.0  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c5f5c2",
   "metadata": {},
   "source": [
    "#### Datetime to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1fa72bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_time = '2020-01-01'\n",
    "basic_interval = 'D'\n",
    "\n",
    "for date_col in date_columns:\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df[date_col] = ((df[date_col] - np.datetime64(basic_time)) / np.timedelta64(1, basic_interval)).values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5570ab42",
   "metadata": {},
   "source": [
    "# ------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90632ad",
   "metadata": {},
   "source": [
    "### ImportanceBasedFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d67bd171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels = df['TARGET']\n",
    "df.drop(columns=['TARGET'], axis=1, inplace=True)\n",
    "train = df\n",
    "num_feats = len(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ce28ffa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 selected features\n"
     ]
    }
   ],
   "source": [
    "lgbc=LGBMClassifier(learning_rate=0.05, num_leaves=64)\n",
    "\n",
    "embeded_lgb_selector = SelectFromModel(lgbc, max_features=num_feats)\n",
    "embeded_lgb_selector.fit(train, train_labels)\n",
    "\n",
    "embeded_lgb_support = embeded_lgb_selector.get_support()\n",
    "embeded_lgb_feature = train.loc[:,embeded_lgb_support].columns.tolist()\n",
    "print(str(len(embeded_lgb_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "14d28954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>OWN_CAR_AGE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>...</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>EMP_DATE</th>\n",
       "      <th>29</th>\n",
       "      <th>41</th>\n",
       "      <th>91</th>\n",
       "      <th>102</th>\n",
       "      <th>119</th>\n",
       "      <th>131</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313802</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>327024.0</td>\n",
       "      <td>15372.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>0.072508</td>\n",
       "      <td>-2432.0</td>\n",
       "      <td>-2137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-19320.0</td>\n",
       "      <td>-956.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>319656</td>\n",
       "      <td>108000.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>19737.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>0.035792</td>\n",
       "      <td>-13156.0</td>\n",
       "      <td>-3758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21046.0</td>\n",
       "      <td>-4552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207678</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>0.031329</td>\n",
       "      <td>-4077.0</td>\n",
       "      <td>-1058</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-10275.0</td>\n",
       "      <td>-1806.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>381593</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>142200.0</td>\n",
       "      <td>9630.0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>0.008474</td>\n",
       "      <td>-5106.0</td>\n",
       "      <td>-1556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-12151.0</td>\n",
       "      <td>-3002.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>258153</td>\n",
       "      <td>337500.0</td>\n",
       "      <td>1483231.5</td>\n",
       "      <td>46570.5</td>\n",
       "      <td>1354500.0</td>\n",
       "      <td>0.008474</td>\n",
       "      <td>-5743.0</td>\n",
       "      <td>-4256</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13933.0</td>\n",
       "      <td>-2505.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0      313802          270000.0    327024.0      15372.0         270000.0   \n",
       "1      319656          108000.0    675000.0      19737.0         675000.0   \n",
       "2      207678          112500.0    270000.0      13500.0         270000.0   \n",
       "3      381593           67500.0    142200.0       9630.0         112500.0   \n",
       "4      258153          337500.0   1483231.5      46570.5        1354500.0   \n",
       "\n",
       "   REGION_POPULATION_RELATIVE  DAYS_REGISTRATION  DAYS_ID_PUBLISH  \\\n",
       "0                    0.072508            -2432.0            -2137   \n",
       "1                    0.035792           -13156.0            -3758   \n",
       "2                    0.031329            -4077.0            -1058   \n",
       "3                    0.008474            -5106.0            -1556   \n",
       "4                    0.008474            -5743.0            -4256   \n",
       "\n",
       "   OWN_CAR_AGE  CNT_FAM_MEMBERS  ...  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "0          NaN              2.0  ...                        0.0   \n",
       "1          NaN              2.0  ...                        0.0   \n",
       "2         18.0              4.0  ...                        0.0   \n",
       "3          NaN              3.0  ...                        0.0   \n",
       "4          9.0              2.0  ...                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_YEAR  BIRTH_DATE  EMP_DATE   29   41   91  102  119  \\\n",
       "0                         1.0    -19320.0    -956.0  0.0  1.0  0.0  1.0  0.0   \n",
       "1                         0.0    -21046.0   -4552.0  0.0  1.0  0.0  0.0  1.0   \n",
       "2                         1.0    -10275.0   -1806.0  1.0  1.0  0.0  0.0  0.0   \n",
       "3                         4.0    -12151.0   -3002.0  0.0  1.0  0.0  0.0  0.0   \n",
       "4                         0.0    -13933.0   -2505.0  0.0  1.0  0.0  0.0  0.0   \n",
       "\n",
       "   131  \n",
       "0  1.0  \n",
       "1  1.0  \n",
       "2  1.0  \n",
       "3  1.0  \n",
       "4  1.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[embeded_lgb_feature]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eea96e",
   "metadata": {},
   "source": [
    "#### First level models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c69e86e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>OWN_CAR_AGE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>...</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>EMP_DATE</th>\n",
       "      <th>29</th>\n",
       "      <th>41</th>\n",
       "      <th>91</th>\n",
       "      <th>102</th>\n",
       "      <th>119</th>\n",
       "      <th>131</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2182</th>\n",
       "      <td>315992</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>545040.0</td>\n",
       "      <td>25537.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>-2344.0</td>\n",
       "      <td>-551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-16552.0</td>\n",
       "      <td>-730.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5766</th>\n",
       "      <td>284326</td>\n",
       "      <td>130500.0</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>38133.0</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>-5122.0</td>\n",
       "      <td>-690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-12278.0</td>\n",
       "      <td>-3554.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>155276</td>\n",
       "      <td>382500.0</td>\n",
       "      <td>1532565.0</td>\n",
       "      <td>65061.0</td>\n",
       "      <td>1323000.0</td>\n",
       "      <td>0.020713</td>\n",
       "      <td>-10348.0</td>\n",
       "      <td>-4291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-17139.0</td>\n",
       "      <td>-3486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>419231</td>\n",
       "      <td>85500.0</td>\n",
       "      <td>1288350.0</td>\n",
       "      <td>37800.0</td>\n",
       "      <td>1125000.0</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>-4109.0</td>\n",
       "      <td>-4522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-22250.0</td>\n",
       "      <td>-730.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7426</th>\n",
       "      <td>289793</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>659610.0</td>\n",
       "      <td>25686.0</td>\n",
       "      <td>472500.0</td>\n",
       "      <td>0.020246</td>\n",
       "      <td>-881.0</td>\n",
       "      <td>-4432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-22359.0</td>\n",
       "      <td>-730.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>395317</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>227520.0</td>\n",
       "      <td>8707.5</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-859.0</td>\n",
       "      <td>-817</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-18015.0</td>\n",
       "      <td>-1064.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>287864</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-2184.0</td>\n",
       "      <td>-2184</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-10749.0</td>\n",
       "      <td>-1926.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>101371</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>1024636.5</td>\n",
       "      <td>33993.0</td>\n",
       "      <td>918000.0</td>\n",
       "      <td>0.035792</td>\n",
       "      <td>-6085.0</td>\n",
       "      <td>-1974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-19191.0</td>\n",
       "      <td>-1562.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4517</th>\n",
       "      <td>275047</td>\n",
       "      <td>120339.0</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>28593.0</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>0.030755</td>\n",
       "      <td>-3982.0</td>\n",
       "      <td>-4281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-14204.0</td>\n",
       "      <td>-1398.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5925</th>\n",
       "      <td>429771</td>\n",
       "      <td>160515.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>32697.0</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>0.014520</td>\n",
       "      <td>-2591.0</td>\n",
       "      <td>-347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8422.0</td>\n",
       "      <td>-1099.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SK_ID_CURR  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "2182      315992          180000.0    545040.0      25537.5         450000.0   \n",
       "5766      284326          130500.0    900000.0      38133.0         900000.0   \n",
       "2439      155276          382500.0   1532565.0      65061.0        1323000.0   \n",
       "993       419231           85500.0   1288350.0      37800.0        1125000.0   \n",
       "7426      289793           67500.0    659610.0      25686.0         472500.0   \n",
       "...          ...               ...         ...          ...              ...   \n",
       "4859      395317          180000.0    227520.0       8707.5         180000.0   \n",
       "919       287864          202500.0    270000.0      13500.0         270000.0   \n",
       "500       101371          315000.0   1024636.5      33993.0         918000.0   \n",
       "4517      275047          120339.0   1035000.0      28593.0        1035000.0   \n",
       "5925      429771          160515.0   1293502.5      32697.0        1129500.0   \n",
       "\n",
       "      REGION_POPULATION_RELATIVE  DAYS_REGISTRATION  DAYS_ID_PUBLISH  \\\n",
       "2182                    0.003069            -2344.0             -551   \n",
       "5766                    0.003069            -5122.0             -690   \n",
       "2439                    0.020713           -10348.0            -4291   \n",
       "993                     0.003813            -4109.0            -4522   \n",
       "7426                    0.020246             -881.0            -4432   \n",
       "...                          ...                ...              ...   \n",
       "4859                    0.018801             -859.0             -817   \n",
       "919                     0.028663            -2184.0            -2184   \n",
       "500                     0.035792            -6085.0            -1974   \n",
       "4517                    0.030755            -3982.0            -4281   \n",
       "5925                    0.014520            -2591.0             -347   \n",
       "\n",
       "      OWN_CAR_AGE  CNT_FAM_MEMBERS  ...  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "2182          NaN              2.0  ...                        0.0   \n",
       "5766          NaN              3.0  ...                        0.0   \n",
       "2439          NaN              2.0  ...                        1.0   \n",
       "993           NaN              2.0  ...                        1.0   \n",
       "7426          NaN              2.0  ...                        0.0   \n",
       "...           ...              ...  ...                        ...   \n",
       "4859         15.0              2.0  ...                        0.0   \n",
       "919           3.0              2.0  ...                        0.0   \n",
       "500           NaN              3.0  ...                        0.0   \n",
       "4517          NaN              3.0  ...                        0.0   \n",
       "5925          NaN              2.0  ...                        0.0   \n",
       "\n",
       "      AMT_REQ_CREDIT_BUREAU_YEAR  BIRTH_DATE  EMP_DATE   29   41   91  102  \\\n",
       "2182                         3.0    -16552.0    -730.0  0.0  1.0  0.0  0.0   \n",
       "5766                         1.0    -12278.0   -3554.0  0.0  1.0  0.0  0.0   \n",
       "2439                         1.0    -17139.0   -3486.0  0.0  1.0  0.0  0.0   \n",
       "993                          2.0    -22250.0    -730.0  0.0  1.0  0.0  0.0   \n",
       "7426                         2.0    -22359.0    -730.0  0.0  1.0  0.0  0.0   \n",
       "...                          ...         ...       ...  ...  ...  ...  ...   \n",
       "4859                         2.0    -18015.0   -1064.0  0.0  1.0  0.0  0.0   \n",
       "919                          4.0    -10749.0   -1926.0  0.0  1.0  0.0  1.0   \n",
       "500                          2.0    -19191.0   -1562.0  0.0  1.0  0.0  1.0   \n",
       "4517                         1.0    -14204.0   -1398.0  0.0  0.0  0.0  1.0   \n",
       "5925                         0.0     -8422.0   -1099.0  0.0  0.0  1.0  1.0   \n",
       "\n",
       "      119  131  \n",
       "2182  0.0  0.0  \n",
       "5766  1.0  0.0  \n",
       "2439  0.0  0.0  \n",
       "993   0.0  0.0  \n",
       "7426  0.0  0.0  \n",
       "...   ...  ...  \n",
       "4859  0.0  0.0  \n",
       "919   1.0  0.0  \n",
       "500   0.0  0.0  \n",
       "4517  0.0  0.0  \n",
       "5925  0.0  0.0  \n",
       "\n",
       "[8000 rows x 51 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features, test_features, train_target, test_target = train_test_split(df, train_labels, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "train_full_features, test_full_features = train_test_split(train, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "17ead74d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.663553\tvalid_0's binary_logloss: 0.272233\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[2]\tvalid_0's auc: 0.67162\tvalid_0's binary_logloss: 0.271883\n",
      "[3]\tvalid_0's auc: 0.677531\tvalid_0's binary_logloss: 0.271495\n",
      "[4]\tvalid_0's auc: 0.682374\tvalid_0's binary_logloss: 0.27115\n",
      "[5]\tvalid_0's auc: 0.683985\tvalid_0's binary_logloss: 0.270604\n",
      "[6]\tvalid_0's auc: 0.688464\tvalid_0's binary_logloss: 0.270174\n",
      "[7]\tvalid_0's auc: 0.689013\tvalid_0's binary_logloss: 0.269769\n",
      "[8]\tvalid_0's auc: 0.694298\tvalid_0's binary_logloss: 0.269431\n",
      "[9]\tvalid_0's auc: 0.692134\tvalid_0's binary_logloss: 0.269187\n",
      "[10]\tvalid_0's auc: 0.69409\tvalid_0's binary_logloss: 0.268747\n",
      "[11]\tvalid_0's auc: 0.697619\tvalid_0's binary_logloss: 0.268266\n",
      "[12]\tvalid_0's auc: 0.697619\tvalid_0's binary_logloss: 0.267934\n",
      "[13]\tvalid_0's auc: 0.698278\tvalid_0's binary_logloss: 0.26766\n",
      "[14]\tvalid_0's auc: 0.700745\tvalid_0's binary_logloss: 0.267489\n",
      "[15]\tvalid_0's auc: 0.699414\tvalid_0's binary_logloss: 0.267144\n",
      "[16]\tvalid_0's auc: 0.699236\tvalid_0's binary_logloss: 0.26684\n",
      "[17]\tvalid_0's auc: 0.699392\tvalid_0's binary_logloss: 0.266601\n",
      "[18]\tvalid_0's auc: 0.697895\tvalid_0's binary_logloss: 0.266329\n",
      "[19]\tvalid_0's auc: 0.69879\tvalid_0's binary_logloss: 0.266015\n",
      "[20]\tvalid_0's auc: 0.6979\tvalid_0's binary_logloss: 0.265787\n",
      "[21]\tvalid_0's auc: 0.700729\tvalid_0's binary_logloss: 0.265363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22]\tvalid_0's auc: 0.701425\tvalid_0's binary_logloss: 0.265071\n",
      "[23]\tvalid_0's auc: 0.700467\tvalid_0's binary_logloss: 0.264858\n",
      "[24]\tvalid_0's auc: 0.702628\tvalid_0's binary_logloss: 0.264526\n",
      "[25]\tvalid_0's auc: 0.703457\tvalid_0's binary_logloss: 0.264222\n",
      "[26]\tvalid_0's auc: 0.70905\tvalid_0's binary_logloss: 0.26393\n",
      "[27]\tvalid_0's auc: 0.712506\tvalid_0's binary_logloss: 0.263569\n",
      "[28]\tvalid_0's auc: 0.71315\tvalid_0's binary_logloss: 0.263384\n",
      "[29]\tvalid_0's auc: 0.713178\tvalid_0's binary_logloss: 0.263198\n",
      "[30]\tvalid_0's auc: 0.713456\tvalid_0's binary_logloss: 0.262855\n",
      "[31]\tvalid_0's auc: 0.711546\tvalid_0's binary_logloss: 0.2627\n",
      "[32]\tvalid_0's auc: 0.711242\tvalid_0's binary_logloss: 0.262519\n",
      "[33]\tvalid_0's auc: 0.714167\tvalid_0's binary_logloss: 0.26224\n",
      "[34]\tvalid_0's auc: 0.714153\tvalid_0's binary_logloss: 0.262088\n",
      "[35]\tvalid_0's auc: 0.71443\tvalid_0's binary_logloss: 0.261937\n",
      "[36]\tvalid_0's auc: 0.714256\tvalid_0's binary_logloss: 0.261828\n",
      "[37]\tvalid_0's auc: 0.713837\tvalid_0's binary_logloss: 0.26157\n",
      "[38]\tvalid_0's auc: 0.713823\tvalid_0's binary_logloss: 0.261342\n",
      "[39]\tvalid_0's auc: 0.713882\tvalid_0's binary_logloss: 0.261054\n",
      "[40]\tvalid_0's auc: 0.714713\tvalid_0's binary_logloss: 0.26097\n",
      "[41]\tvalid_0's auc: 0.715657\tvalid_0's binary_logloss: 0.260667\n",
      "[42]\tvalid_0's auc: 0.71623\tvalid_0's binary_logloss: 0.260505\n",
      "[43]\tvalid_0's auc: 0.716367\tvalid_0's binary_logloss: 0.260294\n",
      "[44]\tvalid_0's auc: 0.716297\tvalid_0's binary_logloss: 0.260078\n",
      "[45]\tvalid_0's auc: 0.71658\tvalid_0's binary_logloss: 0.259845\n",
      "[46]\tvalid_0's auc: 0.715835\tvalid_0's binary_logloss: 0.259789\n",
      "[47]\tvalid_0's auc: 0.71487\tvalid_0's binary_logloss: 0.259719\n",
      "[48]\tvalid_0's auc: 0.715473\tvalid_0's binary_logloss: 0.259537\n",
      "[49]\tvalid_0's auc: 0.714903\tvalid_0's binary_logloss: 0.259353\n",
      "[50]\tvalid_0's auc: 0.714494\tvalid_0's binary_logloss: 0.259197\n",
      "[51]\tvalid_0's auc: 0.713557\tvalid_0's binary_logloss: 0.259066\n",
      "[52]\tvalid_0's auc: 0.713057\tvalid_0's binary_logloss: 0.258909\n",
      "[53]\tvalid_0's auc: 0.713596\tvalid_0's binary_logloss: 0.258766\n",
      "[54]\tvalid_0's auc: 0.714236\tvalid_0's binary_logloss: 0.258604\n",
      "[55]\tvalid_0's auc: 0.713452\tvalid_0's binary_logloss: 0.25856\n",
      "[56]\tvalid_0's auc: 0.713179\tvalid_0's binary_logloss: 0.258437\n",
      "[57]\tvalid_0's auc: 0.712501\tvalid_0's binary_logloss: 0.258282\n",
      "[58]\tvalid_0's auc: 0.713075\tvalid_0's binary_logloss: 0.258142\n",
      "[59]\tvalid_0's auc: 0.713949\tvalid_0's binary_logloss: 0.257956\n",
      "[60]\tvalid_0's auc: 0.714159\tvalid_0's binary_logloss: 0.257809\n",
      "[61]\tvalid_0's auc: 0.714547\tvalid_0's binary_logloss: 0.25761\n",
      "[62]\tvalid_0's auc: 0.715491\tvalid_0's binary_logloss: 0.257397\n",
      "[63]\tvalid_0's auc: 0.715466\tvalid_0's binary_logloss: 0.257241\n",
      "[64]\tvalid_0's auc: 0.714608\tvalid_0's binary_logloss: 0.257214\n",
      "[65]\tvalid_0's auc: 0.714757\tvalid_0's binary_logloss: 0.256988\n",
      "[66]\tvalid_0's auc: 0.713847\tvalid_0's binary_logloss: 0.256966\n",
      "[67]\tvalid_0's auc: 0.713571\tvalid_0's binary_logloss: 0.256869\n",
      "[68]\tvalid_0's auc: 0.713389\tvalid_0's binary_logloss: 0.25669\n",
      "[69]\tvalid_0's auc: 0.713487\tvalid_0's binary_logloss: 0.256578\n",
      "[70]\tvalid_0's auc: 0.71355\tvalid_0's binary_logloss: 0.256434\n",
      "[71]\tvalid_0's auc: 0.713379\tvalid_0's binary_logloss: 0.256385\n",
      "[72]\tvalid_0's auc: 0.713739\tvalid_0's binary_logloss: 0.256318\n",
      "[73]\tvalid_0's auc: 0.713875\tvalid_0's binary_logloss: 0.256177\n",
      "[74]\tvalid_0's auc: 0.713492\tvalid_0's binary_logloss: 0.25609\n",
      "[75]\tvalid_0's auc: 0.713835\tvalid_0's binary_logloss: 0.255998\n",
      "[76]\tvalid_0's auc: 0.71386\tvalid_0's binary_logloss: 0.255878\n",
      "[77]\tvalid_0's auc: 0.714426\tvalid_0's binary_logloss: 0.255699\n",
      "[78]\tvalid_0's auc: 0.714454\tvalid_0's binary_logloss: 0.255579\n",
      "[79]\tvalid_0's auc: 0.713783\tvalid_0's binary_logloss: 0.255547\n",
      "[80]\tvalid_0's auc: 0.713412\tvalid_0's binary_logloss: 0.255452\n",
      "[81]\tvalid_0's auc: 0.713751\tvalid_0's binary_logloss: 0.25528\n",
      "[82]\tvalid_0's auc: 0.714797\tvalid_0's binary_logloss: 0.255179\n",
      "[83]\tvalid_0's auc: 0.714923\tvalid_0's binary_logloss: 0.255025\n",
      "[84]\tvalid_0's auc: 0.714597\tvalid_0's binary_logloss: 0.254973\n",
      "[85]\tvalid_0's auc: 0.714671\tvalid_0's binary_logloss: 0.254882\n",
      "[86]\tvalid_0's auc: 0.714923\tvalid_0's binary_logloss: 0.254734\n",
      "[87]\tvalid_0's auc: 0.715374\tvalid_0's binary_logloss: 0.254653\n",
      "[88]\tvalid_0's auc: 0.71509\tvalid_0's binary_logloss: 0.254566\n",
      "[89]\tvalid_0's auc: 0.715381\tvalid_0's binary_logloss: 0.254443\n",
      "[90]\tvalid_0's auc: 0.71479\tvalid_0's binary_logloss: 0.254399\n",
      "[91]\tvalid_0's auc: 0.713884\tvalid_0's binary_logloss: 0.254394\n",
      "[92]\tvalid_0's auc: 0.714587\tvalid_0's binary_logloss: 0.254248\n",
      "[93]\tvalid_0's auc: 0.714356\tvalid_0's binary_logloss: 0.254222\n",
      "[94]\tvalid_0's auc: 0.713968\tvalid_0's binary_logloss: 0.254192\n",
      "[95]\tvalid_0's auc: 0.713416\tvalid_0's binary_logloss: 0.254169\n",
      "[96]\tvalid_0's auc: 0.713307\tvalid_0's binary_logloss: 0.254109\n",
      "[97]\tvalid_0's auc: 0.713443\tvalid_0's binary_logloss: 0.254031\n",
      "[98]\tvalid_0's auc: 0.713552\tvalid_0's binary_logloss: 0.253959\n",
      "[99]\tvalid_0's auc: 0.713947\tvalid_0's binary_logloss: 0.253828\n",
      "[100]\tvalid_0's auc: 0.714206\tvalid_0's binary_logloss: 0.253711\n",
      "[101]\tvalid_0's auc: 0.713916\tvalid_0's binary_logloss: 0.253647\n",
      "[102]\tvalid_0's auc: 0.714108\tvalid_0's binary_logloss: 0.253477\n",
      "[103]\tvalid_0's auc: 0.713863\tvalid_0's binary_logloss: 0.253455\n",
      "[104]\tvalid_0's auc: 0.713867\tvalid_0's binary_logloss: 0.253374\n",
      "[105]\tvalid_0's auc: 0.714279\tvalid_0's binary_logloss: 0.253289\n",
      "[106]\tvalid_0's auc: 0.714346\tvalid_0's binary_logloss: 0.253187\n",
      "[107]\tvalid_0's auc: 0.714583\tvalid_0's binary_logloss: 0.253048\n",
      "[108]\tvalid_0's auc: 0.714653\tvalid_0's binary_logloss: 0.252991\n",
      "[109]\tvalid_0's auc: 0.71473\tvalid_0's binary_logloss: 0.25294\n",
      "[110]\tvalid_0's auc: 0.715\tvalid_0's binary_logloss: 0.252885\n",
      "[111]\tvalid_0's auc: 0.715174\tvalid_0's binary_logloss: 0.252764\n",
      "[112]\tvalid_0's auc: 0.715395\tvalid_0's binary_logloss: 0.252733\n",
      "[113]\tvalid_0's auc: 0.714989\tvalid_0's binary_logloss: 0.252685\n",
      "[114]\tvalid_0's auc: 0.714639\tvalid_0's binary_logloss: 0.252638\n",
      "[115]\tvalid_0's auc: 0.714552\tvalid_0's binary_logloss: 0.252581\n",
      "[116]\tvalid_0's auc: 0.71487\tvalid_0's binary_logloss: 0.252464\n",
      "[117]\tvalid_0's auc: 0.715104\tvalid_0's binary_logloss: 0.252376\n",
      "[118]\tvalid_0's auc: 0.715479\tvalid_0's binary_logloss: 0.252271\n",
      "[119]\tvalid_0's auc: 0.715384\tvalid_0's binary_logloss: 0.252219\n",
      "[120]\tvalid_0's auc: 0.71516\tvalid_0's binary_logloss: 0.252171\n",
      "[121]\tvalid_0's auc: 0.715069\tvalid_0's binary_logloss: 0.252083\n",
      "[122]\tvalid_0's auc: 0.714618\tvalid_0's binary_logloss: 0.252087\n",
      "[123]\tvalid_0's auc: 0.714926\tvalid_0's binary_logloss: 0.252008\n",
      "[124]\tvalid_0's auc: 0.714884\tvalid_0's binary_logloss: 0.25194\n",
      "[125]\tvalid_0's auc: 0.71436\tvalid_0's binary_logloss: 0.251945\n",
      "[126]\tvalid_0's auc: 0.71458\tvalid_0's binary_logloss: 0.251866\n",
      "[127]\tvalid_0's auc: 0.715405\tvalid_0's binary_logloss: 0.251756\n",
      "[128]\tvalid_0's auc: 0.715433\tvalid_0's binary_logloss: 0.251692\n",
      "[129]\tvalid_0's auc: 0.714562\tvalid_0's binary_logloss: 0.251735\n",
      "[130]\tvalid_0's auc: 0.713975\tvalid_0's binary_logloss: 0.251785\n",
      "[131]\tvalid_0's auc: 0.714769\tvalid_0's binary_logloss: 0.251692\n",
      "[132]\tvalid_0's auc: 0.714122\tvalid_0's binary_logloss: 0.25172\n",
      "[133]\tvalid_0's auc: 0.713975\tvalid_0's binary_logloss: 0.251694\n",
      "[134]\tvalid_0's auc: 0.714398\tvalid_0's binary_logloss: 0.251657\n",
      "[135]\tvalid_0's auc: 0.714024\tvalid_0's binary_logloss: 0.251653\n",
      "[136]\tvalid_0's auc: 0.71393\tvalid_0's binary_logloss: 0.251656\n",
      "[137]\tvalid_0's auc: 0.714167\tvalid_0's binary_logloss: 0.251575\n",
      "[138]\tvalid_0's auc: 0.713912\tvalid_0's binary_logloss: 0.251544\n",
      "[139]\tvalid_0's auc: 0.713807\tvalid_0's binary_logloss: 0.251501\n",
      "[140]\tvalid_0's auc: 0.714017\tvalid_0's binary_logloss: 0.251413\n",
      "[141]\tvalid_0's auc: 0.714335\tvalid_0's binary_logloss: 0.251314\n",
      "[142]\tvalid_0's auc: 0.714545\tvalid_0's binary_logloss: 0.251259\n",
      "[143]\tvalid_0's auc: 0.714751\tvalid_0's binary_logloss: 0.251213\n",
      "[144]\tvalid_0's auc: 0.715021\tvalid_0's binary_logloss: 0.251153\n",
      "[145]\tvalid_0's auc: 0.715573\tvalid_0's binary_logloss: 0.251078\n",
      "[146]\tvalid_0's auc: 0.715618\tvalid_0's binary_logloss: 0.251019\n",
      "[147]\tvalid_0's auc: 0.715454\tvalid_0's binary_logloss: 0.251049\n",
      "[148]\tvalid_0's auc: 0.715937\tvalid_0's binary_logloss: 0.250959\n",
      "[149]\tvalid_0's auc: 0.716126\tvalid_0's binary_logloss: 0.250881\n",
      "[150]\tvalid_0's auc: 0.715755\tvalid_0's binary_logloss: 0.250894\n",
      "[151]\tvalid_0's auc: 0.715486\tvalid_0's binary_logloss: 0.250889\n",
      "[152]\tvalid_0's auc: 0.715605\tvalid_0's binary_logloss: 0.250819\n",
      "[153]\tvalid_0's auc: 0.715818\tvalid_0's binary_logloss: 0.250783\n",
      "[154]\tvalid_0's auc: 0.71557\tvalid_0's binary_logloss: 0.250806\n",
      "[155]\tvalid_0's auc: 0.715472\tvalid_0's binary_logloss: 0.250801\n",
      "[156]\tvalid_0's auc: 0.715286\tvalid_0's binary_logloss: 0.250811\n",
      "[157]\tvalid_0's auc: 0.715472\tvalid_0's binary_logloss: 0.250749\n",
      "[158]\tvalid_0's auc: 0.715258\tvalid_0's binary_logloss: 0.250731\n",
      "[159]\tvalid_0's auc: 0.715395\tvalid_0's binary_logloss: 0.250741\n",
      "[160]\tvalid_0's auc: 0.716101\tvalid_0's binary_logloss: 0.250642\n",
      "[161]\tvalid_0's auc: 0.715902\tvalid_0's binary_logloss: 0.250636\n",
      "[162]\tvalid_0's auc: 0.715895\tvalid_0's binary_logloss: 0.250585\n",
      "[163]\tvalid_0's auc: 0.715653\tvalid_0's binary_logloss: 0.250576\n",
      "[164]\tvalid_0's auc: 0.716028\tvalid_0's binary_logloss: 0.250521\n",
      "[165]\tvalid_0's auc: 0.715765\tvalid_0's binary_logloss: 0.25051\n",
      "[166]\tvalid_0's auc: 0.715587\tvalid_0's binary_logloss: 0.250449\n",
      "[167]\tvalid_0's auc: 0.715685\tvalid_0's binary_logloss: 0.250408\n",
      "[168]\tvalid_0's auc: 0.716311\tvalid_0's binary_logloss: 0.250332\n",
      "[169]\tvalid_0's auc: 0.716577\tvalid_0's binary_logloss: 0.250279\n",
      "[170]\tvalid_0's auc: 0.716832\tvalid_0's binary_logloss: 0.250209\n",
      "[171]\tvalid_0's auc: 0.716762\tvalid_0's binary_logloss: 0.250206\n",
      "[172]\tvalid_0's auc: 0.716909\tvalid_0's binary_logloss: 0.250166\n",
      "[173]\tvalid_0's auc: 0.716678\tvalid_0's binary_logloss: 0.25019\n",
      "[174]\tvalid_0's auc: 0.717056\tvalid_0's binary_logloss: 0.250155\n",
      "[175]\tvalid_0's auc: 0.717196\tvalid_0's binary_logloss: 0.250084\n",
      "[176]\tvalid_0's auc: 0.717063\tvalid_0's binary_logloss: 0.25012\n",
      "[177]\tvalid_0's auc: 0.716772\tvalid_0's binary_logloss: 0.2501\n",
      "[178]\tvalid_0's auc: 0.717178\tvalid_0's binary_logloss: 0.250022\n",
      "[179]\tvalid_0's auc: 0.717133\tvalid_0's binary_logloss: 0.24999\n",
      "[180]\tvalid_0's auc: 0.717087\tvalid_0's binary_logloss: 0.249955\n",
      "[181]\tvalid_0's auc: 0.71701\tvalid_0's binary_logloss: 0.249953\n",
      "[182]\tvalid_0's auc: 0.717185\tvalid_0's binary_logloss: 0.24989\n",
      "[183]\tvalid_0's auc: 0.717231\tvalid_0's binary_logloss: 0.249862\n",
      "[184]\tvalid_0's auc: 0.717098\tvalid_0's binary_logloss: 0.249869\n",
      "[185]\tvalid_0's auc: 0.717259\tvalid_0's binary_logloss: 0.249839\n",
      "[186]\tvalid_0's auc: 0.717458\tvalid_0's binary_logloss: 0.24979\n",
      "[187]\tvalid_0's auc: 0.717661\tvalid_0's binary_logloss: 0.249728\n",
      "[188]\tvalid_0's auc: 0.718042\tvalid_0's binary_logloss: 0.249644\n",
      "[189]\tvalid_0's auc: 0.717787\tvalid_0's binary_logloss: 0.249681\n",
      "[190]\tvalid_0's auc: 0.717671\tvalid_0's binary_logloss: 0.249685\n",
      "[191]\tvalid_0's auc: 0.717996\tvalid_0's binary_logloss: 0.249611\n",
      "[192]\tvalid_0's auc: 0.717996\tvalid_0's binary_logloss: 0.249581\n",
      "[193]\tvalid_0's auc: 0.717612\tvalid_0's binary_logloss: 0.249592\n",
      "[194]\tvalid_0's auc: 0.7173\tvalid_0's binary_logloss: 0.249617\n",
      "[195]\tvalid_0's auc: 0.717311\tvalid_0's binary_logloss: 0.249591\n",
      "[196]\tvalid_0's auc: 0.717314\tvalid_0's binary_logloss: 0.249604\n",
      "[197]\tvalid_0's auc: 0.717388\tvalid_0's binary_logloss: 0.249604\n",
      "[198]\tvalid_0's auc: 0.717381\tvalid_0's binary_logloss: 0.249565\n",
      "[199]\tvalid_0's auc: 0.717297\tvalid_0's binary_logloss: 0.249531\n",
      "[200]\tvalid_0's auc: 0.717318\tvalid_0's binary_logloss: 0.2495\n",
      "[201]\tvalid_0's auc: 0.717451\tvalid_0's binary_logloss: 0.249451\n",
      "[202]\tvalid_0's auc: 0.717328\tvalid_0's binary_logloss: 0.249449\n",
      "[203]\tvalid_0's auc: 0.717409\tvalid_0's binary_logloss: 0.249468\n",
      "[204]\tvalid_0's auc: 0.717262\tvalid_0's binary_logloss: 0.249515\n",
      "[205]\tvalid_0's auc: 0.717528\tvalid_0's binary_logloss: 0.249455\n",
      "[206]\tvalid_0's auc: 0.717468\tvalid_0's binary_logloss: 0.24945\n",
      "[207]\tvalid_0's auc: 0.71751\tvalid_0's binary_logloss: 0.2494\n",
      "[208]\tvalid_0's auc: 0.717692\tvalid_0's binary_logloss: 0.249371\n",
      "[209]\tvalid_0's auc: 0.717814\tvalid_0's binary_logloss: 0.249351\n",
      "[210]\tvalid_0's auc: 0.717738\tvalid_0's binary_logloss: 0.249351\n",
      "[211]\tvalid_0's auc: 0.717811\tvalid_0's binary_logloss: 0.249307\n",
      "[212]\tvalid_0's auc: 0.717916\tvalid_0's binary_logloss: 0.249298\n",
      "[213]\tvalid_0's auc: 0.717542\tvalid_0's binary_logloss: 0.249347\n",
      "[214]\tvalid_0's auc: 0.717731\tvalid_0's binary_logloss: 0.249301\n",
      "[215]\tvalid_0's auc: 0.717835\tvalid_0's binary_logloss: 0.249265\n",
      "[216]\tvalid_0's auc: 0.718157\tvalid_0's binary_logloss: 0.24916\n",
      "[217]\tvalid_0's auc: 0.71808\tvalid_0's binary_logloss: 0.249159\n",
      "[218]\tvalid_0's auc: 0.718426\tvalid_0's binary_logloss: 0.249118\n",
      "[219]\tvalid_0's auc: 0.718458\tvalid_0's binary_logloss: 0.249091\n",
      "[220]\tvalid_0's auc: 0.718608\tvalid_0's binary_logloss: 0.249071\n",
      "[221]\tvalid_0's auc: 0.718867\tvalid_0's binary_logloss: 0.248988\n",
      "[222]\tvalid_0's auc: 0.718706\tvalid_0's binary_logloss: 0.248971\n",
      "[223]\tvalid_0's auc: 0.718822\tvalid_0's binary_logloss: 0.248954\n",
      "[224]\tvalid_0's auc: 0.718902\tvalid_0's binary_logloss: 0.248927\n",
      "[225]\tvalid_0's auc: 0.718811\tvalid_0's binary_logloss: 0.24891\n",
      "[226]\tvalid_0's auc: 0.71894\tvalid_0's binary_logloss: 0.248847\n",
      "[227]\tvalid_0's auc: 0.719133\tvalid_0's binary_logloss: 0.24882\n",
      "[228]\tvalid_0's auc: 0.719266\tvalid_0's binary_logloss: 0.248784\n",
      "[229]\tvalid_0's auc: 0.719846\tvalid_0's binary_logloss: 0.248692\n",
      "[230]\tvalid_0's auc: 0.72014\tvalid_0's binary_logloss: 0.248603\n",
      "[231]\tvalid_0's auc: 0.720178\tvalid_0's binary_logloss: 0.248608\n",
      "[232]\tvalid_0's auc: 0.719909\tvalid_0's binary_logloss: 0.248604\n",
      "[233]\tvalid_0's auc: 0.719958\tvalid_0's binary_logloss: 0.248611\n",
      "[234]\tvalid_0's auc: 0.719986\tvalid_0's binary_logloss: 0.24855\n",
      "[235]\tvalid_0's auc: 0.719797\tvalid_0's binary_logloss: 0.248564\n",
      "[236]\tvalid_0's auc: 0.719804\tvalid_0's binary_logloss: 0.248564\n",
      "[237]\tvalid_0's auc: 0.720101\tvalid_0's binary_logloss: 0.248491\n",
      "[238]\tvalid_0's auc: 0.720143\tvalid_0's binary_logloss: 0.248449\n",
      "[239]\tvalid_0's auc: 0.720038\tvalid_0's binary_logloss: 0.248489\n",
      "[240]\tvalid_0's auc: 0.719916\tvalid_0's binary_logloss: 0.248508\n",
      "[241]\tvalid_0's auc: 0.71992\tvalid_0's binary_logloss: 0.248505\n",
      "[242]\tvalid_0's auc: 0.72007\tvalid_0's binary_logloss: 0.248509\n",
      "[243]\tvalid_0's auc: 0.720129\tvalid_0's binary_logloss: 0.24849\n",
      "[244]\tvalid_0's auc: 0.720203\tvalid_0's binary_logloss: 0.248482\n",
      "[245]\tvalid_0's auc: 0.720154\tvalid_0's binary_logloss: 0.248474\n",
      "[246]\tvalid_0's auc: 0.720073\tvalid_0's binary_logloss: 0.248474\n",
      "[247]\tvalid_0's auc: 0.719895\tvalid_0's binary_logloss: 0.248488\n",
      "[248]\tvalid_0's auc: 0.720168\tvalid_0's binary_logloss: 0.248476\n",
      "[249]\tvalid_0's auc: 0.719951\tvalid_0's binary_logloss: 0.248481\n",
      "[250]\tvalid_0's auc: 0.720164\tvalid_0's binary_logloss: 0.248451\n",
      "[251]\tvalid_0's auc: 0.719892\tvalid_0's binary_logloss: 0.248459\n",
      "[252]\tvalid_0's auc: 0.720052\tvalid_0's binary_logloss: 0.248443\n",
      "[253]\tvalid_0's auc: 0.719972\tvalid_0's binary_logloss: 0.248472\n",
      "[254]\tvalid_0's auc: 0.719832\tvalid_0's binary_logloss: 0.24851\n",
      "[255]\tvalid_0's auc: 0.719755\tvalid_0's binary_logloss: 0.248507\n",
      "[256]\tvalid_0's auc: 0.719622\tvalid_0's binary_logloss: 0.248525\n",
      "[257]\tvalid_0's auc: 0.719556\tvalid_0's binary_logloss: 0.248542\n",
      "[258]\tvalid_0's auc: 0.719238\tvalid_0's binary_logloss: 0.248593\n",
      "[259]\tvalid_0's auc: 0.719021\tvalid_0's binary_logloss: 0.248625\n",
      "[260]\tvalid_0's auc: 0.718947\tvalid_0's binary_logloss: 0.248638\n",
      "[261]\tvalid_0's auc: 0.718748\tvalid_0's binary_logloss: 0.248667\n",
      "[262]\tvalid_0's auc: 0.718409\tvalid_0's binary_logloss: 0.248726\n",
      "[263]\tvalid_0's auc: 0.718517\tvalid_0's binary_logloss: 0.2487\n",
      "[264]\tvalid_0's auc: 0.718577\tvalid_0's binary_logloss: 0.248676\n",
      "[265]\tvalid_0's auc: 0.718521\tvalid_0's binary_logloss: 0.248676\n",
      "[266]\tvalid_0's auc: 0.718594\tvalid_0's binary_logloss: 0.248674\n",
      "[267]\tvalid_0's auc: 0.718815\tvalid_0's binary_logloss: 0.248642\n",
      "[268]\tvalid_0's auc: 0.718836\tvalid_0's binary_logloss: 0.248639\n",
      "[269]\tvalid_0's auc: 0.718647\tvalid_0's binary_logloss: 0.248686\n",
      "[270]\tvalid_0's auc: 0.718465\tvalid_0's binary_logloss: 0.248699\n",
      "[271]\tvalid_0's auc: 0.718433\tvalid_0's binary_logloss: 0.248685\n",
      "[272]\tvalid_0's auc: 0.718591\tvalid_0's binary_logloss: 0.248684\n",
      "[273]\tvalid_0's auc: 0.718696\tvalid_0's binary_logloss: 0.248661\n",
      "[274]\tvalid_0's auc: 0.718479\tvalid_0's binary_logloss: 0.248702\n",
      "[275]\tvalid_0's auc: 0.718468\tvalid_0's binary_logloss: 0.248705\n",
      "[276]\tvalid_0's auc: 0.718703\tvalid_0's binary_logloss: 0.248683\n",
      "[277]\tvalid_0's auc: 0.718542\tvalid_0's binary_logloss: 0.248718\n",
      "[278]\tvalid_0's auc: 0.718752\tvalid_0's binary_logloss: 0.248685\n",
      "[279]\tvalid_0's auc: 0.718808\tvalid_0's binary_logloss: 0.248689\n",
      "[280]\tvalid_0's auc: 0.719056\tvalid_0's binary_logloss: 0.248661\n",
      "[281]\tvalid_0's auc: 0.719206\tvalid_0's binary_logloss: 0.248642\n",
      "[282]\tvalid_0's auc: 0.719224\tvalid_0's binary_logloss: 0.248644\n",
      "[283]\tvalid_0's auc: 0.718986\tvalid_0's binary_logloss: 0.248665\n",
      "[284]\tvalid_0's auc: 0.71878\tvalid_0's binary_logloss: 0.248704\n",
      "[285]\tvalid_0's auc: 0.718975\tvalid_0's binary_logloss: 0.248702\n",
      "[286]\tvalid_0's auc: 0.718933\tvalid_0's binary_logloss: 0.248739\n",
      "[287]\tvalid_0's auc: 0.718871\tvalid_0's binary_logloss: 0.248761\n",
      "[288]\tvalid_0's auc: 0.719098\tvalid_0's binary_logloss: 0.24873\n",
      "[289]\tvalid_0's auc: 0.719143\tvalid_0's binary_logloss: 0.248722\n",
      "[290]\tvalid_0's auc: 0.71936\tvalid_0's binary_logloss: 0.248689\n",
      "[291]\tvalid_0's auc: 0.719454\tvalid_0's binary_logloss: 0.24868\n",
      "[292]\tvalid_0's auc: 0.719388\tvalid_0's binary_logloss: 0.248658\n",
      "[293]\tvalid_0's auc: 0.719385\tvalid_0's binary_logloss: 0.248653\n",
      "[294]\tvalid_0's auc: 0.719322\tvalid_0's binary_logloss: 0.248681\n",
      "[295]\tvalid_0's auc: 0.719329\tvalid_0's binary_logloss: 0.24869\n",
      "[296]\tvalid_0's auc: 0.718895\tvalid_0's binary_logloss: 0.248756\n",
      "[297]\tvalid_0's auc: 0.718521\tvalid_0's binary_logloss: 0.248809\n",
      "[298]\tvalid_0's auc: 0.718773\tvalid_0's binary_logloss: 0.248802\n",
      "[299]\tvalid_0's auc: 0.718888\tvalid_0's binary_logloss: 0.248761\n",
      "[300]\tvalid_0's auc: 0.718521\tvalid_0's binary_logloss: 0.24884\n",
      "[301]\tvalid_0's auc: 0.718454\tvalid_0's binary_logloss: 0.248857\n",
      "[302]\tvalid_0's auc: 0.718398\tvalid_0's binary_logloss: 0.248835\n",
      "[303]\tvalid_0's auc: 0.718493\tvalid_0's binary_logloss: 0.248819\n",
      "[304]\tvalid_0's auc: 0.718227\tvalid_0's binary_logloss: 0.24885\n",
      "[305]\tvalid_0's auc: 0.717989\tvalid_0's binary_logloss: 0.248886\n",
      "[306]\tvalid_0's auc: 0.718045\tvalid_0's binary_logloss: 0.248856\n",
      "[307]\tvalid_0's auc: 0.718273\tvalid_0's binary_logloss: 0.248844\n",
      "[308]\tvalid_0's auc: 0.718136\tvalid_0's binary_logloss: 0.248863\n",
      "[309]\tvalid_0's auc: 0.718168\tvalid_0's binary_logloss: 0.248836\n",
      "[310]\tvalid_0's auc: 0.718066\tvalid_0's binary_logloss: 0.248862\n",
      "[311]\tvalid_0's auc: 0.71822\tvalid_0's binary_logloss: 0.248851\n",
      "[312]\tvalid_0's auc: 0.718262\tvalid_0's binary_logloss: 0.248844\n",
      "[313]\tvalid_0's auc: 0.718346\tvalid_0's binary_logloss: 0.248847\n",
      "[314]\tvalid_0's auc: 0.718315\tvalid_0's binary_logloss: 0.248865\n",
      "[315]\tvalid_0's auc: 0.71814\tvalid_0's binary_logloss: 0.248888\n",
      "[316]\tvalid_0's auc: 0.718112\tvalid_0's binary_logloss: 0.248888\n",
      "[317]\tvalid_0's auc: 0.718094\tvalid_0's binary_logloss: 0.248923\n",
      "[318]\tvalid_0's auc: 0.718031\tvalid_0's binary_logloss: 0.24892\n",
      "[319]\tvalid_0's auc: 0.71814\tvalid_0's binary_logloss: 0.248912\n",
      "[320]\tvalid_0's auc: 0.718601\tvalid_0's binary_logloss: 0.248822\n",
      "[321]\tvalid_0's auc: 0.718902\tvalid_0's binary_logloss: 0.248814\n",
      "[322]\tvalid_0's auc: 0.718727\tvalid_0's binary_logloss: 0.24883\n",
      "[323]\tvalid_0's auc: 0.718787\tvalid_0's binary_logloss: 0.248836\n",
      "[324]\tvalid_0's auc: 0.71908\tvalid_0's binary_logloss: 0.248793\n",
      "[325]\tvalid_0's auc: 0.719052\tvalid_0's binary_logloss: 0.248782\n",
      "[326]\tvalid_0's auc: 0.719087\tvalid_0's binary_logloss: 0.248817\n",
      "[327]\tvalid_0's auc: 0.718888\tvalid_0's binary_logloss: 0.248841\n",
      "[328]\tvalid_0's auc: 0.719161\tvalid_0's binary_logloss: 0.248834\n",
      "[329]\tvalid_0's auc: 0.719245\tvalid_0's binary_logloss: 0.248822\n",
      "[330]\tvalid_0's auc: 0.719241\tvalid_0's binary_logloss: 0.248789\n",
      "[331]\tvalid_0's auc: 0.719164\tvalid_0's binary_logloss: 0.248806\n",
      "[332]\tvalid_0's auc: 0.719458\tvalid_0's binary_logloss: 0.248741\n",
      "[333]\tvalid_0's auc: 0.71965\tvalid_0's binary_logloss: 0.248678\n",
      "[334]\tvalid_0's auc: 0.719773\tvalid_0's binary_logloss: 0.248648\n",
      "[335]\tvalid_0's auc: 0.71972\tvalid_0's binary_logloss: 0.248656\n",
      "[336]\tvalid_0's auc: 0.719629\tvalid_0's binary_logloss: 0.248703\n",
      "[337]\tvalid_0's auc: 0.71964\tvalid_0's binary_logloss: 0.248675\n",
      "[338]\tvalid_0's auc: 0.719493\tvalid_0's binary_logloss: 0.24873\n",
      "[339]\tvalid_0's auc: 0.719531\tvalid_0's binary_logloss: 0.248731\n",
      "[340]\tvalid_0's auc: 0.719664\tvalid_0's binary_logloss: 0.248728\n",
      "[341]\tvalid_0's auc: 0.719633\tvalid_0's binary_logloss: 0.248748\n",
      "[342]\tvalid_0's auc: 0.719489\tvalid_0's binary_logloss: 0.248806\n",
      "[343]\tvalid_0's auc: 0.71935\tvalid_0's binary_logloss: 0.248821\n",
      "[344]\tvalid_0's auc: 0.719441\tvalid_0's binary_logloss: 0.248839\n",
      "[345]\tvalid_0's auc: 0.719416\tvalid_0's binary_logloss: 0.248849\n",
      "[346]\tvalid_0's auc: 0.719395\tvalid_0's binary_logloss: 0.248874\n",
      "[347]\tvalid_0's auc: 0.719266\tvalid_0's binary_logloss: 0.248941\n",
      "[348]\tvalid_0's auc: 0.719213\tvalid_0's binary_logloss: 0.248955\n",
      "[349]\tvalid_0's auc: 0.719175\tvalid_0's binary_logloss: 0.248967\n",
      "[350]\tvalid_0's auc: 0.719063\tvalid_0's binary_logloss: 0.248938\n",
      "[351]\tvalid_0's auc: 0.718902\tvalid_0's binary_logloss: 0.248977\n",
      "[352]\tvalid_0's auc: 0.718905\tvalid_0's binary_logloss: 0.24894\n",
      "[353]\tvalid_0's auc: 0.718944\tvalid_0's binary_logloss: 0.248961\n",
      "[354]\tvalid_0's auc: 0.718947\tvalid_0's binary_logloss: 0.24896\n",
      "[355]\tvalid_0's auc: 0.718811\tvalid_0's binary_logloss: 0.248978\n",
      "[356]\tvalid_0's auc: 0.718699\tvalid_0's binary_logloss: 0.248974\n",
      "[357]\tvalid_0's auc: 0.718535\tvalid_0's binary_logloss: 0.248993\n",
      "[358]\tvalid_0's auc: 0.718524\tvalid_0's binary_logloss: 0.249056\n",
      "[359]\tvalid_0's auc: 0.718412\tvalid_0's binary_logloss: 0.249066\n",
      "[360]\tvalid_0's auc: 0.718493\tvalid_0's binary_logloss: 0.24905\n",
      "[361]\tvalid_0's auc: 0.718318\tvalid_0's binary_logloss: 0.249066\n",
      "[362]\tvalid_0's auc: 0.718356\tvalid_0's binary_logloss: 0.249086\n",
      "[363]\tvalid_0's auc: 0.718245\tvalid_0's binary_logloss: 0.249126\n",
      "[364]\tvalid_0's auc: 0.718315\tvalid_0's binary_logloss: 0.249149\n",
      "[365]\tvalid_0's auc: 0.718322\tvalid_0's binary_logloss: 0.249126\n",
      "[366]\tvalid_0's auc: 0.718346\tvalid_0's binary_logloss: 0.249132\n",
      "[367]\tvalid_0's auc: 0.718353\tvalid_0's binary_logloss: 0.249142\n",
      "[368]\tvalid_0's auc: 0.718472\tvalid_0's binary_logloss: 0.249156\n",
      "[369]\tvalid_0's auc: 0.718433\tvalid_0's binary_logloss: 0.249177\n",
      "[370]\tvalid_0's auc: 0.718262\tvalid_0's binary_logloss: 0.249213\n",
      "[371]\tvalid_0's auc: 0.718024\tvalid_0's binary_logloss: 0.249268\n",
      "[372]\tvalid_0's auc: 0.717762\tvalid_0's binary_logloss: 0.24932\n",
      "[373]\tvalid_0's auc: 0.717898\tvalid_0's binary_logloss: 0.249315\n",
      "[374]\tvalid_0's auc: 0.717902\tvalid_0's binary_logloss: 0.249308\n",
      "[375]\tvalid_0's auc: 0.717741\tvalid_0's binary_logloss: 0.249365\n",
      "[376]\tvalid_0's auc: 0.717982\tvalid_0's binary_logloss: 0.249305\n",
      "[377]\tvalid_0's auc: 0.718024\tvalid_0's binary_logloss: 0.249308\n",
      "[378]\tvalid_0's auc: 0.718164\tvalid_0's binary_logloss: 0.249289\n",
      "[379]\tvalid_0's auc: 0.718129\tvalid_0's binary_logloss: 0.249315\n",
      "[380]\tvalid_0's auc: 0.71822\tvalid_0's binary_logloss: 0.249311\n",
      "[381]\tvalid_0's auc: 0.718115\tvalid_0's binary_logloss: 0.249323\n",
      "[382]\tvalid_0's auc: 0.718168\tvalid_0's binary_logloss: 0.249336\n",
      "[383]\tvalid_0's auc: 0.717909\tvalid_0's binary_logloss: 0.249387\n",
      "[384]\tvalid_0's auc: 0.71787\tvalid_0's binary_logloss: 0.249421\n",
      "[385]\tvalid_0's auc: 0.718161\tvalid_0's binary_logloss: 0.249335\n",
      "[386]\tvalid_0's auc: 0.718045\tvalid_0's binary_logloss: 0.249353\n",
      "[387]\tvalid_0's auc: 0.718178\tvalid_0's binary_logloss: 0.249345\n",
      "[388]\tvalid_0's auc: 0.718175\tvalid_0's binary_logloss: 0.24934\n",
      "[389]\tvalid_0's auc: 0.718185\tvalid_0's binary_logloss: 0.249347\n",
      "[390]\tvalid_0's auc: 0.71835\tvalid_0's binary_logloss: 0.249345\n",
      "[391]\tvalid_0's auc: 0.718269\tvalid_0's binary_logloss: 0.24938\n",
      "[392]\tvalid_0's auc: 0.718056\tvalid_0's binary_logloss: 0.249447\n",
      "[393]\tvalid_0's auc: 0.717685\tvalid_0's binary_logloss: 0.249494\n",
      "[394]\tvalid_0's auc: 0.717797\tvalid_0's binary_logloss: 0.249492\n",
      "[395]\tvalid_0's auc: 0.717636\tvalid_0's binary_logloss: 0.249521\n",
      "[396]\tvalid_0's auc: 0.717675\tvalid_0's binary_logloss: 0.249537\n",
      "[397]\tvalid_0's auc: 0.717975\tvalid_0's binary_logloss: 0.249508\n",
      "[398]\tvalid_0's auc: 0.718066\tvalid_0's binary_logloss: 0.249493\n",
      "[399]\tvalid_0's auc: 0.718028\tvalid_0's binary_logloss: 0.249498\n",
      "[400]\tvalid_0's auc: 0.71801\tvalid_0's binary_logloss: 0.249506\n",
      "[401]\tvalid_0's auc: 0.717912\tvalid_0's binary_logloss: 0.24955\n",
      "[402]\tvalid_0's auc: 0.718077\tvalid_0's binary_logloss: 0.249527\n",
      "[403]\tvalid_0's auc: 0.718136\tvalid_0's binary_logloss: 0.24951\n",
      "[404]\tvalid_0's auc: 0.718049\tvalid_0's binary_logloss: 0.249561\n",
      "[405]\tvalid_0's auc: 0.717766\tvalid_0's binary_logloss: 0.249625\n",
      "[406]\tvalid_0's auc: 0.717877\tvalid_0's binary_logloss: 0.249654\n",
      "[407]\tvalid_0's auc: 0.717968\tvalid_0's binary_logloss: 0.249627\n",
      "[408]\tvalid_0's auc: 0.717755\tvalid_0's binary_logloss: 0.249653\n",
      "[409]\tvalid_0's auc: 0.718105\tvalid_0's binary_logloss: 0.249588\n",
      "[410]\tvalid_0's auc: 0.71793\tvalid_0's binary_logloss: 0.249638\n",
      "[411]\tvalid_0's auc: 0.718042\tvalid_0's binary_logloss: 0.249638\n",
      "[412]\tvalid_0's auc: 0.717849\tvalid_0's binary_logloss: 0.249654\n",
      "[413]\tvalid_0's auc: 0.717821\tvalid_0's binary_logloss: 0.24966\n",
      "[414]\tvalid_0's auc: 0.71778\tvalid_0's binary_logloss: 0.249651\n",
      "[415]\tvalid_0's auc: 0.717808\tvalid_0's binary_logloss: 0.249649\n",
      "[416]\tvalid_0's auc: 0.717881\tvalid_0's binary_logloss: 0.249629\n",
      "[417]\tvalid_0's auc: 0.717944\tvalid_0's binary_logloss: 0.249633\n",
      "[418]\tvalid_0's auc: 0.717762\tvalid_0's binary_logloss: 0.249644\n",
      "[419]\tvalid_0's auc: 0.71772\tvalid_0's binary_logloss: 0.249708\n",
      "[420]\tvalid_0's auc: 0.717818\tvalid_0's binary_logloss: 0.249697\n",
      "[421]\tvalid_0's auc: 0.717902\tvalid_0's binary_logloss: 0.249645\n",
      "[422]\tvalid_0's auc: 0.717947\tvalid_0's binary_logloss: 0.249645\n",
      "[423]\tvalid_0's auc: 0.718\tvalid_0's binary_logloss: 0.249662\n",
      "[424]\tvalid_0's auc: 0.718192\tvalid_0's binary_logloss: 0.249653\n",
      "[425]\tvalid_0's auc: 0.718129\tvalid_0's binary_logloss: 0.249663\n",
      "[426]\tvalid_0's auc: 0.718196\tvalid_0's binary_logloss: 0.249658\n",
      "[427]\tvalid_0's auc: 0.718133\tvalid_0's binary_logloss: 0.249681\n",
      "[428]\tvalid_0's auc: 0.718175\tvalid_0's binary_logloss: 0.249699\n",
      "[429]\tvalid_0's auc: 0.718059\tvalid_0's binary_logloss: 0.249695\n",
      "[430]\tvalid_0's auc: 0.717801\tvalid_0's binary_logloss: 0.249736\n",
      "[431]\tvalid_0's auc: 0.717909\tvalid_0's binary_logloss: 0.249726\n",
      "[432]\tvalid_0's auc: 0.717933\tvalid_0's binary_logloss: 0.249724\n",
      "[433]\tvalid_0's auc: 0.717846\tvalid_0's binary_logloss: 0.24977\n",
      "[434]\tvalid_0's auc: 0.717759\tvalid_0's binary_logloss: 0.249774\n",
      "[435]\tvalid_0's auc: 0.717629\tvalid_0's binary_logloss: 0.24982\n",
      "[436]\tvalid_0's auc: 0.717766\tvalid_0's binary_logloss: 0.249825\n",
      "[437]\tvalid_0's auc: 0.717755\tvalid_0's binary_logloss: 0.249848\n",
      "[438]\tvalid_0's auc: 0.717601\tvalid_0's binary_logloss: 0.249887\n",
      "[439]\tvalid_0's auc: 0.71764\tvalid_0's binary_logloss: 0.249913\n",
      "[440]\tvalid_0's auc: 0.717556\tvalid_0's binary_logloss: 0.24993\n",
      "[441]\tvalid_0's auc: 0.717528\tvalid_0's binary_logloss: 0.24995\n",
      "[442]\tvalid_0's auc: 0.717587\tvalid_0's binary_logloss: 0.249968\n",
      "[443]\tvalid_0's auc: 0.717297\tvalid_0's binary_logloss: 0.250021\n",
      "[444]\tvalid_0's auc: 0.717454\tvalid_0's binary_logloss: 0.250005\n",
      "Early stopping, best iteration is:\n",
      "[244]\tvalid_0's auc: 0.720203\tvalid_0's binary_logloss: 0.248482\n"
     ]
    }
   ],
   "source": [
    "default_params = {\n",
    "    'task': 'train',\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_leaves\": 24,\n",
    "    \"feature_fraction\": 0.7,\n",
    "    \"bagging_fraction\": 0.7,\n",
    "    'bagging_freq': 1,\n",
    "    \"max_depth\": -1,\n",
    "    \"verbosity\": -1,\n",
    "    \"reg_alpha\": 0.5,\n",
    "    \"reg_lambda\": 0.0,\n",
    "    \"min_split_gain\": 0.0,\n",
    "    'zero_as_missing': False,\n",
    "    'num_threads': 4,\n",
    "    'max_bin': 255,\n",
    "    'min_data_in_bin': 3,\n",
    "    'num_trees': 3000,\n",
    "    'random_state': 42,\n",
    "    'early_stopping_rounds': 200\n",
    "}\n",
    "# **default_params\n",
    "lgbc=LGBMClassifier(**default_params)\n",
    "lgbc.fit(train_features, train_target, eval_set=(test_features, test_target), eval_metric = 'auc')\n",
    "LGBM_predicted_train = lgbc.predict_proba(train_features)\n",
    "LGBM_predicted_test = lgbc.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "09857e60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:04,459]\u001b[0m A new study created in memory with name: no-name-1dfbd5ca-9c81-4060-8690-eda696ef4390\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.711293\n",
      "[40]\tvalid_0's auc: 0.719259\n",
      "[60]\tvalid_0's auc: 0.71537\n",
      "[80]\tvalid_0's auc: 0.718982\n",
      "[100]\tvalid_0's auc: 0.714321\n",
      "[120]\tvalid_0's auc: 0.714982\n",
      "[140]\tvalid_0's auc: 0.713706\n",
      "[160]\tvalid_0's auc: 0.716671\n",
      "[180]\tvalid_0's auc: 0.716594\n",
      "[200]\tvalid_0's auc: 0.717346\n",
      "[220]\tvalid_0's auc: 0.715709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:05,960]\u001b[0m Trial 0 finished with value: 0.6867041546612138 and parameters: {'num_leaves': 136, 'feature_fraction': 0.7837492060993628, 'bagging_fraction': 0.515249706475084, 'min_sum_hessian_in_leaf': 0.040589600031277887}. Best is trial 0 with value: 0.6867041546612138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[240]\tvalid_0's auc: 0.716919\n",
      "[260]\tvalid_0's auc: 0.717748\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.721108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.701163\n",
      "[40]\tvalid_0's auc: 0.710747\n",
      "[60]\tvalid_0's auc: 0.70827\n",
      "[80]\tvalid_0's auc: 0.711034\n",
      "[100]\tvalid_0's auc: 0.712618\n",
      "[120]\tvalid_0's auc: 0.708457\n",
      "[140]\tvalid_0's auc: 0.709366\n",
      "[160]\tvalid_0's auc: 0.710803\n",
      "[180]\tvalid_0's auc: 0.711398\n",
      "[200]\tvalid_0's auc: 0.714597\n",
      "[220]\tvalid_0's auc: 0.71352\n",
      "[240]\tvalid_0's auc: 0.715014\n",
      "[260]\tvalid_0's auc: 0.716944\n",
      "[280]\tvalid_0's auc: 0.717105\n",
      "[300]\tvalid_0's auc: 0.716835\n",
      "[320]\tvalid_0's auc: 0.717007\n",
      "[340]\tvalid_0's auc: 0.717598\n",
      "[360]\tvalid_0's auc: 0.716818\n",
      "[380]\tvalid_0's auc: 0.715042\n",
      "[400]\tvalid_0's auc: 0.712667\n",
      "[420]\tvalid_0's auc: 0.711482\n",
      "[440]\tvalid_0's auc: 0.712783\n",
      "[460]\tvalid_0's auc: 0.713381\n",
      "[480]\tvalid_0's auc: 0.713013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:07,213]\u001b[0m Trial 1 finished with value: 0.702859234129566 and parameters: {'num_leaves': 24, 'feature_fraction': 0.817582501282925, 'bagging_fraction': 0.5203740344614768, 'min_sum_hessian_in_leaf': 0.0038892424289111672}. Best is trial 1 with value: 0.702859234129566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\tvalid_0's auc: 0.713003\n",
      "[520]\tvalid_0's auc: 0.713395\n",
      "Early stopping, best iteration is:\n",
      "[328]\tvalid_0's auc: 0.718881\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\tvalid_0's auc: 0.703464\n",
      "[40]\tvalid_0's auc: 0.710108\n",
      "[60]\tvalid_0's auc: 0.710712\n",
      "[80]\tvalid_0's auc: 0.710272\n",
      "[100]\tvalid_0's auc: 0.709513\n",
      "[120]\tvalid_0's auc: 0.710226\n",
      "[140]\tvalid_0's auc: 0.711741\n",
      "[160]\tvalid_0's auc: 0.712468\n",
      "[180]\tvalid_0's auc: 0.712118\n",
      "[200]\tvalid_0's auc: 0.714961\n",
      "[220]\tvalid_0's auc: 0.714545\n",
      "[240]\tvalid_0's auc: 0.717171\n",
      "[260]\tvalid_0's auc: 0.718119\n",
      "[280]\tvalid_0's auc: 0.718391\n",
      "[300]\tvalid_0's auc: 0.71715\n",
      "[320]\tvalid_0's auc: 0.716647\n",
      "[340]\tvalid_0's auc: 0.716115\n",
      "[360]\tvalid_0's auc: 0.713734\n",
      "[380]\tvalid_0's auc: 0.713395\n",
      "[400]\tvalid_0's auc: 0.713122\n",
      "[420]\tvalid_0's auc: 0.711541\n",
      "[440]\tvalid_0's auc: 0.710296\n",
      "[460]\tvalid_0's auc: 0.708761\n",
      "Early stopping, best iteration is:\n",
      "[279]\tvalid_0's auc: 0.718626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:10,395]\u001b[0m Trial 2 finished with value: 0.6841772004833162 and parameters: {'num_leaves': 137, 'feature_fraction': 0.8961917999252501, 'bagging_fraction': 0.6151852408239966, 'min_sum_hessian_in_leaf': 0.2000169611638482}. Best is trial 1 with value: 0.702859234129566.\u001b[0m\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.705523\n",
      "[40]\tvalid_0's auc: 0.711912\n",
      "[60]\tvalid_0's auc: 0.713961\n",
      "[80]\tvalid_0's auc: 0.719549\n",
      "[100]\tvalid_0's auc: 0.721171\n",
      "[120]\tvalid_0's auc: 0.719133\n",
      "[140]\tvalid_0's auc: 0.716846\n",
      "[160]\tvalid_0's auc: 0.716779\n",
      "[180]\tvalid_0's auc: 0.719493\n",
      "[200]\tvalid_0's auc: 0.719811\n",
      "[220]\tvalid_0's auc: 0.721325\n",
      "[240]\tvalid_0's auc: 0.720629\n",
      "[260]\tvalid_0's auc: 0.722783\n",
      "[280]\tvalid_0's auc: 0.723039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:11,723]\u001b[0m Trial 3 finished with value: 0.6847174458592805 and parameters: {'num_leaves': 69, 'feature_fraction': 0.6048560609308598, 'bagging_fraction': 0.6056059821958459, 'min_sum_hessian_in_leaf': 0.02543324778844792}. Best is trial 1 with value: 0.702859234129566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's auc: 0.724004\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.697215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40]\tvalid_0's auc: 0.705852\n",
      "[60]\tvalid_0's auc: 0.705313\n",
      "[80]\tvalid_0's auc: 0.709212\n",
      "[100]\tvalid_0's auc: 0.711398\n",
      "[120]\tvalid_0's auc: 0.71151\n",
      "[140]\tvalid_0's auc: 0.711293\n",
      "[160]\tvalid_0's auc: 0.712615\n",
      "[180]\tvalid_0's auc: 0.712464\n",
      "[200]\tvalid_0's auc: 0.711615\n",
      "[220]\tvalid_0's auc: 0.709828\n",
      "[240]\tvalid_0's auc: 0.710583\n",
      "[260]\tvalid_0's auc: 0.710513\n",
      "[280]\tvalid_0's auc: 0.709017\n",
      "[300]\tvalid_0's auc: 0.708286\n",
      "[320]\tvalid_0's auc: 0.70502\n",
      "[340]\tvalid_0's auc: 0.704964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:14,186]\u001b[0m Trial 4 finished with value: 0.6956617715401059 and parameters: {'num_leaves': 214, 'feature_fraction': 0.7402865293456133, 'bagging_fraction': 0.7392294916022062, 'min_sum_hessian_in_leaf': 0.9239491654361944}. Best is trial 1 with value: 0.702859234129566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[360]\tvalid_0's auc: 0.704387\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's auc: 0.71444\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2021-07-15 13:23:14,273]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:14,351]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:14,478]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 29.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.705049\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.712908\n",
      "[40]\tvalid_0's auc: 0.719934\n",
      "[60]\tvalid_0's auc: 0.721647\n",
      "[80]\tvalid_0's auc: 0.719073\n",
      "[100]\tvalid_0's auc: 0.716363\n",
      "[120]\tvalid_0's auc: 0.715181\n",
      "[140]\tvalid_0's auc: 0.71472\n",
      "[160]\tvalid_0's auc: 0.714374\n",
      "[180]\tvalid_0's auc: 0.713853\n",
      "[200]\tvalid_0's auc: 0.712908\n",
      "[220]\tvalid_0's auc: 0.710912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:16,279]\u001b[0m Trial 8 finished with value: 0.6874012454689098 and parameters: {'num_leaves': 193, 'feature_fraction': 0.7983810645168279, 'bagging_fraction': 0.7909290232832364, 'min_sum_hessian_in_leaf': 0.026054939744929364}. Best is trial 1 with value: 0.702859234129566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[240]\tvalid_0's auc: 0.709024\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.72336\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.706639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40]\tvalid_0's auc: 0.708807\n",
      "[60]\tvalid_0's auc: 0.703806\n",
      "[80]\tvalid_0's auc: 0.707244\n",
      "[100]\tvalid_0's auc: 0.705222\n",
      "[120]\tvalid_0's auc: 0.706125\n",
      "[140]\tvalid_0's auc: 0.707359\n",
      "[160]\tvalid_0's auc: 0.710191\n",
      "[180]\tvalid_0's auc: 0.709076\n",
      "[200]\tvalid_0's auc: 0.708922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:17,308]\u001b[0m Trial 9 finished with value: 0.6351281485268148 and parameters: {'num_leaves': 236, 'feature_fraction': 0.7213696624929316, 'bagging_fraction': 0.5152483151794973, 'min_sum_hessian_in_leaf': 1.580409021965545}. Best is trial 1 with value: 0.702859234129566.\u001b[0m\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2021-07-15 13:23:17,400]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.721525\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.711338\n",
      "[40]\tvalid_0's auc: 0.716786\n",
      "[60]\tvalid_0's auc: 0.712055\n",
      "[80]\tvalid_0's auc: 0.708135\n",
      "[100]\tvalid_0's auc: 0.706128\n",
      "[120]\tvalid_0's auc: 0.70375\n",
      "[140]\tvalid_0's auc: 0.701152\n",
      "[160]\tvalid_0's auc: 0.699537\n",
      "[180]\tvalid_0's auc: 0.699477\n",
      "[200]\tvalid_0's auc: 0.701925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:19,225]\u001b[0m Trial 11 finished with value: 0.6569209499024072 and parameters: {'num_leaves': 255, 'feature_fraction': 0.6919851844313625, 'bagging_fraction': 0.9916522483472168, 'min_sum_hessian_in_leaf': 7.743935014933286}. Best is trial 1 with value: 0.702859234129566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[220]\tvalid_0's auc: 0.702355\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's auc: 0.71878\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2021-07-15 13:23:19,340]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:19,449]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:19,528]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:19,598]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.708062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:19,884]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 30.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:19,971]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.704282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:20,155]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 30.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:20,221]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:20,335]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.714748\n",
      "[40]\tvalid_0's auc: 0.722175\n",
      "[60]\tvalid_0's auc: 0.718577\n",
      "[80]\tvalid_0's auc: 0.719322\n",
      "[100]\tvalid_0's auc: 0.715657\n",
      "[120]\tvalid_0's auc: 0.71372\n",
      "[140]\tvalid_0's auc: 0.714339\n",
      "[160]\tvalid_0's auc: 0.713475\n",
      "[180]\tvalid_0's auc: 0.71295\n",
      "[200]\tvalid_0's auc: 0.714489\n",
      "[220]\tvalid_0's auc: 0.713692\n",
      "[240]\tvalid_0's auc: 0.710971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:22,157]\u001b[0m Trial 21 finished with value: 0.6831606097220931 and parameters: {'num_leaves': 200, 'feature_fraction': 0.8075375822159309, 'bagging_fraction': 0.791945451492757, 'min_sum_hessian_in_leaf': 0.010891747635489226}. Best is trial 1 with value: 0.702859234129566.\u001b[0m\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2021-07-15 13:23:22,262]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.723193\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:22,370]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:22,500]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:22,622]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:22,787]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:22,916]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:23,018]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:23,127]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:23,249]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.705768\n",
      "[40]\tvalid_0's auc: 0.709328\n",
      "[60]\tvalid_0's auc: 0.713101\n",
      "[80]\tvalid_0's auc: 0.711136\n",
      "[100]\tvalid_0's auc: 0.710719\n",
      "[120]\tvalid_0's auc: 0.713192\n",
      "[140]\tvalid_0's auc: 0.713482\n",
      "[160]\tvalid_0's auc: 0.715164\n",
      "[180]\tvalid_0's auc: 0.712846\n",
      "[200]\tvalid_0's auc: 0.713195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:24,273]\u001b[0m Trial 31 finished with value: 0.661120922018775 and parameters: {'num_leaves': 136, 'feature_fraction': 0.8174440041177965, 'bagging_fraction': 0.505193475175558, 'min_sum_hessian_in_leaf': 0.11314236767309696}. Best is trial 1 with value: 0.702859234129566.\u001b[0m\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2021-07-15 13:23:24,363]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.716239\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.708048\n",
      "[40]\tvalid_0's auc: 0.705278\n",
      "[60]\tvalid_0's auc: 0.7096\n",
      "[80]\tvalid_0's auc: 0.712241\n",
      "[100]\tvalid_0's auc: 0.714286\n",
      "[120]\tvalid_0's auc: 0.715681\n",
      "[140]\tvalid_0's auc: 0.715727\n",
      "[160]\tvalid_0's auc: 0.716884\n",
      "[180]\tvalid_0's auc: 0.716227\n",
      "[200]\tvalid_0's auc: 0.716786\n",
      "[220]\tvalid_0's auc: 0.717318\n",
      "[240]\tvalid_0's auc: 0.717594\n",
      "[260]\tvalid_0's auc: 0.714545\n",
      "[280]\tvalid_0's auc: 0.714395\n",
      "[300]\tvalid_0's auc: 0.712272\n",
      "[320]\tvalid_0's auc: 0.714716\n",
      "[340]\tvalid_0's auc: 0.712111\n",
      "[360]\tvalid_0's auc: 0.712758\n",
      "[380]\tvalid_0's auc: 0.711384\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid_0's auc: 0.718052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:26,887]\u001b[0m Trial 33 finished with value: 0.6932219537131704 and parameters: {'num_leaves': 81, 'feature_fraction': 0.8598563562612795, 'bagging_fraction': 0.5409484220052688, 'min_sum_hessian_in_leaf': 0.01810525188876901}. Best is trial 1 with value: 0.702859234129566.\u001b[0m\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2021-07-15 13:23:26,977]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:27,069]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:27,158]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:27,260]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.70856\n",
      "[40]\tvalid_0's auc: 0.716825\n",
      "[60]\tvalid_0's auc: 0.716199\n",
      "[80]\tvalid_0's auc: 0.71778\n",
      "[100]\tvalid_0's auc: 0.717825\n",
      "[120]\tvalid_0's auc: 0.717724\n",
      "[140]\tvalid_0's auc: 0.717143\n",
      "[160]\tvalid_0's auc: 0.71643\n",
      "[180]\tvalid_0's auc: 0.716209\n",
      "[200]\tvalid_0's auc: 0.716129\n",
      "[220]\tvalid_0's auc: 0.715279\n",
      "[240]\tvalid_0's auc: 0.715412\n",
      "[260]\tvalid_0's auc: 0.714709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:28,583]\u001b[0m Trial 38 finished with value: 0.6869829909842922 and parameters: {'num_leaves': 46, 'feature_fraction': 0.79450611149552, 'bagging_fraction': 0.500660877922895, 'min_sum_hessian_in_leaf': 0.5622574027420617}. Best is trial 1 with value: 0.702859234129566.\u001b[0m\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2021-07-15 13:23:28,692]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[280]\tvalid_0's auc: 0.715618\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's auc: 0.719105\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.711789\n",
      "[40]\tvalid_0's auc: 0.70796\n",
      "[60]\tvalid_0's auc: 0.712908\n",
      "[80]\tvalid_0's auc: 0.715909\n",
      "[100]\tvalid_0's auc: 0.714538\n",
      "[120]\tvalid_0's auc: 0.715255\n",
      "[140]\tvalid_0's auc: 0.713367\n",
      "[160]\tvalid_0's auc: 0.713395\n",
      "[180]\tvalid_0's auc: 0.711894\n",
      "[200]\tvalid_0's auc: 0.715517\n",
      "[220]\tvalid_0's auc: 0.715549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:30,174]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 261.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[240]\tvalid_0's auc: 0.716678\n",
      "[260]\tvalid_0's auc: 0.714555\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:30,265]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.714783\n",
      "[40]\tvalid_0's auc: 0.715423\n",
      "[60]\tvalid_0's auc: 0.718458\n",
      "[80]\tvalid_0's auc: 0.715993\n",
      "[100]\tvalid_0's auc: 0.719955\n",
      "[120]\tvalid_0's auc: 0.722179\n",
      "[140]\tvalid_0's auc: 0.718794\n",
      "[160]\tvalid_0's auc: 0.721409\n",
      "[180]\tvalid_0's auc: 0.717699\n",
      "[200]\tvalid_0's auc: 0.718454\n",
      "[220]\tvalid_0's auc: 0.717888\n",
      "[240]\tvalid_0's auc: 0.72199\n",
      "[260]\tvalid_0's auc: 0.724801\n",
      "[280]\tvalid_0's auc: 0.723067\n",
      "[300]\tvalid_0's auc: 0.723878\n",
      "[320]\tvalid_0's auc: 0.724284\n",
      "[340]\tvalid_0's auc: 0.723465\n",
      "[360]\tvalid_0's auc: 0.722374\n",
      "[380]\tvalid_0's auc: 0.719605\n",
      "[400]\tvalid_0's auc: 0.719881\n",
      "[420]\tvalid_0's auc: 0.719906\n",
      "[440]\tvalid_0's auc: 0.720927\n",
      "Early stopping, best iteration is:\n",
      "[257]\tvalid_0's auc: 0.725452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:32,301]\u001b[0m Trial 42 finished with value: 0.7005936890045544 and parameters: {'num_leaves': 52, 'feature_fraction': 0.7969140062549217, 'bagging_fraction': 0.5100160772406682, 'min_sum_hessian_in_leaf': 1.341262609641882}. Best is trial 1 with value: 0.702859234129566.\u001b[0m\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2021-07-15 13:23:32,391]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:32,454]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:32,536]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:32,630]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:32,714]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:32,787]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:32,868]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:32,970]\u001b[0m Trial 50 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.713125\n",
      "[40]\tvalid_0's auc: 0.718727\n",
      "[60]\tvalid_0's auc: 0.718419\n",
      "[80]\tvalid_0's auc: 0.71922\n",
      "[100]\tvalid_0's auc: 0.719343\n",
      "[120]\tvalid_0's auc: 0.719811\n",
      "[140]\tvalid_0's auc: 0.719136\n",
      "[160]\tvalid_0's auc: 0.719969\n",
      "[180]\tvalid_0's auc: 0.718871\n",
      "[200]\tvalid_0's auc: 0.720731\n",
      "[220]\tvalid_0's auc: 0.719538\n",
      "[240]\tvalid_0's auc: 0.719524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:34,291]\u001b[0m Trial 51 finished with value: 0.6940294172320848 and parameters: {'num_leaves': 48, 'feature_fraction': 0.7995992977348549, 'bagging_fraction': 0.5021894910675195, 'min_sum_hessian_in_leaf': 0.8784017380765475}. Best is trial 1 with value: 0.702859234129566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[260]\tvalid_0's auc: 0.720955\n",
      "[280]\tvalid_0's auc: 0.719727\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's auc: 0.722329\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2021-07-15 13:23:34,353]\u001b[0m Trial 52 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:34,446]\u001b[0m Trial 53 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:34,528]\u001b[0m Trial 54 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:34,603]\u001b[0m Trial 55 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:34,688]\u001b[0m Trial 56 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:34,790]\u001b[0m Trial 57 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:34,895]\u001b[0m Trial 58 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:34,999]\u001b[0m Trial 59 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:35,116]\u001b[0m Trial 60 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.710559\n",
      "[40]\tvalid_0's auc: 0.715223\n",
      "[60]\tvalid_0's auc: 0.715\n",
      "[80]\tvalid_0's auc: 0.718416\n",
      "[100]\tvalid_0's auc: 0.718276\n",
      "[120]\tvalid_0's auc: 0.715629\n",
      "[140]\tvalid_0's auc: 0.715549\n",
      "[160]\tvalid_0's auc: 0.716531\n",
      "[180]\tvalid_0's auc: 0.71423\n",
      "[200]\tvalid_0's auc: 0.717601\n",
      "[220]\tvalid_0's auc: 0.716734\n",
      "[240]\tvalid_0's auc: 0.714395\n",
      "[260]\tvalid_0's auc: 0.71465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:36,644]\u001b[0m Trial 61 finished with value: 0.6843340459150479 and parameters: {'num_leaves': 48, 'feature_fraction': 0.7908570368175998, 'bagging_fraction': 0.5014887896677019, 'min_sum_hessian_in_leaf': 0.461968020030451}. Best is trial 1 with value: 0.702859234129566.\u001b[0m\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2021-07-15 13:23:36,711]\u001b[0m Trial 62 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[280]\tvalid_0's auc: 0.714527\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's auc: 0.719182\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:36,782]\u001b[0m Trial 63 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:36,870]\u001b[0m Trial 64 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:36,948]\u001b[0m Trial 65 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.701418\n",
      "[40]\tvalid_0's auc: 0.711989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:37,379]\u001b[0m Trial 66 pruned. Trial was pruned at iteration 76.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:37,439]\u001b[0m Trial 67 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60]\tvalid_0's auc: 0.714125\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:37,509]\u001b[0m Trial 68 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:37,624]\u001b[0m Trial 69 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:37,714]\u001b[0m Trial 70 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:37,819]\u001b[0m Trial 71 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:37,906]\u001b[0m Trial 72 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:38,003]\u001b[0m Trial 73 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:38,110]\u001b[0m Trial 74 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:38,202]\u001b[0m Trial 75 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:38,318]\u001b[0m Trial 76 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:38,426]\u001b[0m Trial 77 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:38,514]\u001b[0m Trial 78 pruned. Trial was pruned at iteration 11.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:38,608]\u001b[0m Trial 79 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:38,702]\u001b[0m Trial 80 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:38,773]\u001b[0m Trial 81 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:38,878]\u001b[0m Trial 82 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:38,995]\u001b[0m Trial 83 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:39,086]\u001b[0m Trial 84 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:39,176]\u001b[0m Trial 85 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:39,296]\u001b[0m Trial 86 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:39,394]\u001b[0m Trial 87 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:39,492]\u001b[0m Trial 88 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:39,592]\u001b[0m Trial 89 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:39,676]\u001b[0m Trial 90 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.713611\n",
      "[40]\tvalid_0's auc: 0.713671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:40,026]\u001b[0m Trial 91 pruned. Trial was pruned at iteration 75.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:40,110]\u001b[0m Trial 92 pruned. Trial was pruned at iteration 13.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60]\tvalid_0's auc: 0.715122\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:40,216]\u001b[0m Trial 93 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.7165\n",
      "[40]\tvalid_0's auc: 0.719388\n",
      "[60]\tvalid_0's auc: 0.719815\n",
      "[80]\tvalid_0's auc: 0.718675\n",
      "[100]\tvalid_0's auc: 0.716706\n",
      "[120]\tvalid_0's auc: 0.716769\n",
      "[140]\tvalid_0's auc: 0.715744\n",
      "[160]\tvalid_0's auc: 0.715346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:41,181]\u001b[0m Trial 94 finished with value: 0.685042754902872 and parameters: {'num_leaves': 48, 'feature_fraction': 0.7836963300488013, 'bagging_fraction': 0.5412002758237987, 'min_sum_hessian_in_leaf': 1.0396542342248882}. Best is trial 1 with value: 0.702859234129566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[180]\tvalid_0's auc: 0.716024\n",
      "[200]\tvalid_0's auc: 0.717353\n",
      "[220]\tvalid_0's auc: 0.717842\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.722722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.718028\n",
      "[40]\tvalid_0's auc: 0.712464\n",
      "[60]\tvalid_0's auc: 0.711108\n",
      "[80]\tvalid_0's auc: 0.711894\n",
      "[100]\tvalid_0's auc: 0.712926\n",
      "[120]\tvalid_0's auc: 0.714629\n",
      "[140]\tvalid_0's auc: 0.713849\n",
      "[160]\tvalid_0's auc: 0.712797\n",
      "[180]\tvalid_0's auc: 0.713076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:42,452]\u001b[0m Trial 95 finished with value: 0.692635235616693 and parameters: {'num_leaves': 69, 'feature_fraction': 0.8350283003817034, 'bagging_fraction': 0.5406763588355933, 'min_sum_hessian_in_leaf': 0.9807415028365318}. Best is trial 1 with value: 0.702859234129566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's auc: 0.714367\n",
      "[220]\tvalid_0's auc: 0.714846\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.722374\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2021-07-15 13:23:42,533]\u001b[0m Trial 96 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:42,612]\u001b[0m Trial 97 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2021-07-15 13:23:42,713]\u001b[0m Trial 98 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[20]\tvalid_0's auc: 0.711293\n",
      "[40]\tvalid_0's auc: 0.719259\n",
      "[60]\tvalid_0's auc: 0.71537\n",
      "[80]\tvalid_0's auc: 0.718982\n",
      "[100]\tvalid_0's auc: 0.714321\n",
      "[120]\tvalid_0's auc: 0.714982\n",
      "[140]\tvalid_0's auc: 0.713706\n",
      "[160]\tvalid_0's auc: 0.716671\n",
      "[180]\tvalid_0's auc: 0.716594\n",
      "[200]\tvalid_0's auc: 0.717346\n",
      "[220]\tvalid_0's auc: 0.715709\n",
      "[240]\tvalid_0's auc: 0.716919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-15 13:23:44,261]\u001b[0m Trial 99 finished with value: 0.6867041546612138 and parameters: {'num_leaves': 110, 'feature_fraction': 0.7827312829585444, 'bagging_fraction': 0.515335399959634, 'min_sum_hessian_in_leaf': 0.699339576008495}. Best is trial 1 with value: 0.702859234129566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[260]\tvalid_0's auc: 0.717748\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.721108\n",
      "Number of finished trials: 100\n",
      "Best trial:\n",
      "  Value: 0.702859234129566\n",
      "  Params: \n",
      "    num_leaves: 24\n",
      "    feature_fraction: 0.817582501282925\n",
      "    bagging_fraction: 0.5203740344614768\n",
      "    min_sum_hessian_in_leaf: 0.0038892424289111672\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    train_fea, valid_fea, train_tar, valid_tar = train_test_split(train_features, train_target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    dtrain = lgb.Dataset(train_fea, label = train_tar, free_raw_data = False)\n",
    "    dtest  = lgb.Dataset(test_features, label = test_target, free_raw_data = False)\n",
    "    dvalid  = lgb.Dataset(valid_fea, label = valid_tar, free_raw_data = False)\n",
    "    \n",
    "    param = {\n",
    "        'task': 'train',\n",
    "        \"learning_rate\": 0.01,\n",
    "        'bagging_freq': 1,\n",
    "        \"max_depth\": -1,\n",
    "        \"verbosity\": -1,\n",
    "        \"reg_alpha\": 0.5,\n",
    "        \"reg_lambda\": 0.0,\n",
    "        \"min_split_gain\": 0.0,\n",
    "        'zero_as_missing': False,\n",
    "        'num_threads': 4,\n",
    "        'max_bin': 255,\n",
    "        'min_data_in_bin': 3,\n",
    "        'num_trees': 3000,\n",
    "        'random_state': 42,\n",
    "        'early_stopping_rounds': 200,\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 16, 256),\n",
    "        'metric': 'auc',\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.5, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.5, 1.0),\n",
    "        'min_sum_hessian_in_leaf': trial.suggest_loguniform('min_sum_hessian_in_leaf', 1e-3, 10.0)\n",
    "    }\n",
    "    \n",
    "    # Add a callback for pruning\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'auc')\n",
    "    \n",
    "    gbm = lgb.train(\n",
    "        param, \n",
    "        dtrain, \n",
    "        verbose_eval = 20,\n",
    "        valid_sets = [dtest],\n",
    "        callbacks = [pruning_callback]\n",
    "        )\n",
    "    \n",
    "    preds = gbm.predict(valid_fea)\n",
    "#     accuracy = np.sqrt(mean_squared_error(test_target, preds))\n",
    "    accuracy = roc_auc_score(valid_tar, preds)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize', pruner = optuna.pruners.MedianPruner(n_warmup_steps = 10))\n",
    "study.optimize(objective, n_trials = 100)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "84f79d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    num_leaves: 24\n",
      "    feature_fraction: 0.817582501282925\n",
      "    bagging_fraction: 0.5203740344614768\n",
      "    min_sum_hessian_in_leaf: 0.0038892424289111672\n"
     ]
    }
   ],
   "source": [
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cc7831e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.660341\tvalid_0's binary_logloss: 0.272196\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[2]\tvalid_0's auc: 0.660932\tvalid_0's binary_logloss: 0.271907\n",
      "[3]\tvalid_0's auc: 0.681325\tvalid_0's binary_logloss: 0.271586\n",
      "[4]\tvalid_0's auc: 0.685088\tvalid_0's binary_logloss: 0.271139\n",
      "[5]\tvalid_0's auc: 0.691732\tvalid_0's binary_logloss: 0.270676\n",
      "[6]\tvalid_0's auc: 0.693478\tvalid_0's binary_logloss: 0.270365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\tvalid_0's auc: 0.691534\tvalid_0's binary_logloss: 0.269949\n",
      "[8]\tvalid_0's auc: 0.696164\tvalid_0's binary_logloss: 0.269592\n",
      "[9]\tvalid_0's auc: 0.695571\tvalid_0's binary_logloss: 0.269256\n",
      "[10]\tvalid_0's auc: 0.697797\tvalid_0's binary_logloss: 0.268744\n",
      "[11]\tvalid_0's auc: 0.701939\tvalid_0's binary_logloss: 0.268284\n",
      "[12]\tvalid_0's auc: 0.705897\tvalid_0's binary_logloss: 0.26783\n",
      "[13]\tvalid_0's auc: 0.705329\tvalid_0's binary_logloss: 0.267471\n",
      "[14]\tvalid_0's auc: 0.702065\tvalid_0's binary_logloss: 0.267452\n",
      "[15]\tvalid_0's auc: 0.700689\tvalid_0's binary_logloss: 0.267168\n",
      "[16]\tvalid_0's auc: 0.699427\tvalid_0's binary_logloss: 0.266793\n",
      "[17]\tvalid_0's auc: 0.699698\tvalid_0's binary_logloss: 0.266478\n",
      "[18]\tvalid_0's auc: 0.699386\tvalid_0's binary_logloss: 0.266163\n",
      "[19]\tvalid_0's auc: 0.70147\tvalid_0's binary_logloss: 0.265918\n",
      "[20]\tvalid_0's auc: 0.703194\tvalid_0's binary_logloss: 0.265578\n",
      "[21]\tvalid_0's auc: 0.702617\tvalid_0's binary_logloss: 0.265269\n",
      "[22]\tvalid_0's auc: 0.70409\tvalid_0's binary_logloss: 0.264867\n",
      "[23]\tvalid_0's auc: 0.702133\tvalid_0's binary_logloss: 0.264583\n",
      "[24]\tvalid_0's auc: 0.703266\tvalid_0's binary_logloss: 0.26423\n",
      "[25]\tvalid_0's auc: 0.704126\tvalid_0's binary_logloss: 0.263916\n",
      "[26]\tvalid_0's auc: 0.703801\tvalid_0's binary_logloss: 0.263635\n",
      "[27]\tvalid_0's auc: 0.705025\tvalid_0's binary_logloss: 0.263213\n",
      "[28]\tvalid_0's auc: 0.70573\tvalid_0's binary_logloss: 0.262946\n",
      "[29]\tvalid_0's auc: 0.705156\tvalid_0's binary_logloss: 0.262734\n",
      "[30]\tvalid_0's auc: 0.705632\tvalid_0's binary_logloss: 0.262447\n",
      "[31]\tvalid_0's auc: 0.704359\tvalid_0's binary_logloss: 0.26223\n",
      "[32]\tvalid_0's auc: 0.70417\tvalid_0's binary_logloss: 0.262028\n",
      "[33]\tvalid_0's auc: 0.704124\tvalid_0's binary_logloss: 0.261937\n",
      "[34]\tvalid_0's auc: 0.70403\tvalid_0's binary_logloss: 0.261794\n",
      "[35]\tvalid_0's auc: 0.704887\tvalid_0's binary_logloss: 0.261526\n",
      "[36]\tvalid_0's auc: 0.707516\tvalid_0's binary_logloss: 0.261143\n",
      "[37]\tvalid_0's auc: 0.707307\tvalid_0's binary_logloss: 0.260918\n",
      "[38]\tvalid_0's auc: 0.707635\tvalid_0's binary_logloss: 0.260705\n",
      "[39]\tvalid_0's auc: 0.707058\tvalid_0's binary_logloss: 0.260516\n",
      "[40]\tvalid_0's auc: 0.707555\tvalid_0's binary_logloss: 0.260391\n",
      "[41]\tvalid_0's auc: 0.7086\tvalid_0's binary_logloss: 0.260128\n",
      "[42]\tvalid_0's auc: 0.709274\tvalid_0's binary_logloss: 0.259937\n",
      "[43]\tvalid_0's auc: 0.710945\tvalid_0's binary_logloss: 0.25966\n",
      "[44]\tvalid_0's auc: 0.710733\tvalid_0's binary_logloss: 0.259445\n",
      "[45]\tvalid_0's auc: 0.711468\tvalid_0's binary_logloss: 0.259243\n",
      "[46]\tvalid_0's auc: 0.711894\tvalid_0's binary_logloss: 0.259033\n",
      "[47]\tvalid_0's auc: 0.711714\tvalid_0's binary_logloss: 0.258805\n",
      "[48]\tvalid_0's auc: 0.711298\tvalid_0's binary_logloss: 0.258711\n",
      "[49]\tvalid_0's auc: 0.712924\tvalid_0's binary_logloss: 0.258461\n",
      "[50]\tvalid_0's auc: 0.712748\tvalid_0's binary_logloss: 0.258258\n",
      "[51]\tvalid_0's auc: 0.712853\tvalid_0's binary_logloss: 0.258099\n",
      "[52]\tvalid_0's auc: 0.713335\tvalid_0's binary_logloss: 0.257898\n",
      "[53]\tvalid_0's auc: 0.71301\tvalid_0's binary_logloss: 0.257766\n",
      "[54]\tvalid_0's auc: 0.7133\tvalid_0's binary_logloss: 0.25755\n",
      "[55]\tvalid_0's auc: 0.712552\tvalid_0's binary_logloss: 0.257415\n",
      "[56]\tvalid_0's auc: 0.711751\tvalid_0's binary_logloss: 0.257243\n",
      "[57]\tvalid_0's auc: 0.711821\tvalid_0's binary_logloss: 0.257125\n",
      "[58]\tvalid_0's auc: 0.712825\tvalid_0's binary_logloss: 0.256994\n",
      "[59]\tvalid_0's auc: 0.712723\tvalid_0's binary_logloss: 0.256831\n",
      "[60]\tvalid_0's auc: 0.712017\tvalid_0's binary_logloss: 0.256727\n",
      "[61]\tvalid_0's auc: 0.712195\tvalid_0's binary_logloss: 0.256596\n",
      "[62]\tvalid_0's auc: 0.712136\tvalid_0's binary_logloss: 0.256394\n",
      "[63]\tvalid_0's auc: 0.711975\tvalid_0's binary_logloss: 0.256289\n",
      "[64]\tvalid_0's auc: 0.711964\tvalid_0's binary_logloss: 0.256125\n",
      "[65]\tvalid_0's auc: 0.712293\tvalid_0's binary_logloss: 0.255963\n",
      "[66]\tvalid_0's auc: 0.711706\tvalid_0's binary_logloss: 0.255921\n",
      "[67]\tvalid_0's auc: 0.712926\tvalid_0's binary_logloss: 0.255748\n",
      "[68]\tvalid_0's auc: 0.712178\tvalid_0's binary_logloss: 0.255679\n",
      "[69]\tvalid_0's auc: 0.712213\tvalid_0's binary_logloss: 0.25557\n",
      "[70]\tvalid_0's auc: 0.712391\tvalid_0's binary_logloss: 0.255384\n",
      "[71]\tvalid_0's auc: 0.712464\tvalid_0's binary_logloss: 0.255343\n",
      "[72]\tvalid_0's auc: 0.712975\tvalid_0's binary_logloss: 0.255282\n",
      "[73]\tvalid_0's auc: 0.712692\tvalid_0's binary_logloss: 0.255216\n",
      "[74]\tvalid_0's auc: 0.712431\tvalid_0's binary_logloss: 0.255102\n",
      "[75]\tvalid_0's auc: 0.713089\tvalid_0's binary_logloss: 0.254951\n",
      "[76]\tvalid_0's auc: 0.713186\tvalid_0's binary_logloss: 0.254849\n",
      "[77]\tvalid_0's auc: 0.713924\tvalid_0's binary_logloss: 0.254615\n",
      "[78]\tvalid_0's auc: 0.714225\tvalid_0's binary_logloss: 0.25445\n",
      "[79]\tvalid_0's auc: 0.713868\tvalid_0's binary_logloss: 0.254409\n",
      "[80]\tvalid_0's auc: 0.713753\tvalid_0's binary_logloss: 0.254304\n",
      "[81]\tvalid_0's auc: 0.715089\tvalid_0's binary_logloss: 0.254143\n",
      "[82]\tvalid_0's auc: 0.715176\tvalid_0's binary_logloss: 0.254074\n",
      "[83]\tvalid_0's auc: 0.715711\tvalid_0's binary_logloss: 0.253909\n",
      "[84]\tvalid_0's auc: 0.71532\tvalid_0's binary_logloss: 0.253874\n",
      "[85]\tvalid_0's auc: 0.715257\tvalid_0's binary_logloss: 0.253785\n",
      "[86]\tvalid_0's auc: 0.716061\tvalid_0's binary_logloss: 0.253567\n",
      "[87]\tvalid_0's auc: 0.716788\tvalid_0's binary_logloss: 0.253445\n",
      "[88]\tvalid_0's auc: 0.716162\tvalid_0's binary_logloss: 0.253427\n",
      "[89]\tvalid_0's auc: 0.716592\tvalid_0's binary_logloss: 0.253284\n",
      "[90]\tvalid_0's auc: 0.716418\tvalid_0's binary_logloss: 0.253214\n",
      "[91]\tvalid_0's auc: 0.71676\tvalid_0's binary_logloss: 0.253061\n",
      "[92]\tvalid_0's auc: 0.716299\tvalid_0's binary_logloss: 0.252984\n",
      "[93]\tvalid_0's auc: 0.715571\tvalid_0's binary_logloss: 0.25299\n",
      "[94]\tvalid_0's auc: 0.716295\tvalid_0's binary_logloss: 0.252789\n",
      "[95]\tvalid_0's auc: 0.715452\tvalid_0's binary_logloss: 0.2528\n",
      "[96]\tvalid_0's auc: 0.715701\tvalid_0's binary_logloss: 0.252637\n",
      "[97]\tvalid_0's auc: 0.715748\tvalid_0's binary_logloss: 0.252558\n",
      "[98]\tvalid_0's auc: 0.716286\tvalid_0's binary_logloss: 0.252453\n",
      "[99]\tvalid_0's auc: 0.71672\tvalid_0's binary_logloss: 0.252361\n",
      "[100]\tvalid_0's auc: 0.716793\tvalid_0's binary_logloss: 0.252307\n",
      "[101]\tvalid_0's auc: 0.717685\tvalid_0's binary_logloss: 0.252173\n",
      "[102]\tvalid_0's auc: 0.717381\tvalid_0's binary_logloss: 0.252086\n",
      "[103]\tvalid_0's auc: 0.717066\tvalid_0's binary_logloss: 0.2521\n",
      "[104]\tvalid_0's auc: 0.716668\tvalid_0's binary_logloss: 0.252053\n",
      "[105]\tvalid_0's auc: 0.715912\tvalid_0's binary_logloss: 0.252054\n",
      "[106]\tvalid_0's auc: 0.715916\tvalid_0's binary_logloss: 0.251956\n",
      "[107]\tvalid_0's auc: 0.716447\tvalid_0's binary_logloss: 0.251807\n",
      "[108]\tvalid_0's auc: 0.716216\tvalid_0's binary_logloss: 0.2518\n",
      "[109]\tvalid_0's auc: 0.716363\tvalid_0's binary_logloss: 0.251722\n",
      "[110]\tvalid_0's auc: 0.716622\tvalid_0's binary_logloss: 0.251694\n",
      "[111]\tvalid_0's auc: 0.716633\tvalid_0's binary_logloss: 0.251596\n",
      "[112]\tvalid_0's auc: 0.716877\tvalid_0's binary_logloss: 0.251603\n",
      "[113]\tvalid_0's auc: 0.71693\tvalid_0's binary_logloss: 0.251578\n",
      "[114]\tvalid_0's auc: 0.716657\tvalid_0's binary_logloss: 0.251567\n",
      "[115]\tvalid_0's auc: 0.71601\tvalid_0's binary_logloss: 0.251564\n",
      "[116]\tvalid_0's auc: 0.71601\tvalid_0's binary_logloss: 0.251504\n",
      "[117]\tvalid_0's auc: 0.71644\tvalid_0's binary_logloss: 0.251356\n",
      "[118]\tvalid_0's auc: 0.71594\tvalid_0's binary_logloss: 0.25132\n",
      "[119]\tvalid_0's auc: 0.715979\tvalid_0's binary_logloss: 0.251278\n",
      "[120]\tvalid_0's auc: 0.71643\tvalid_0's binary_logloss: 0.251192\n",
      "[121]\tvalid_0's auc: 0.716147\tvalid_0's binary_logloss: 0.251201\n",
      "[122]\tvalid_0's auc: 0.716489\tvalid_0's binary_logloss: 0.251108\n",
      "[123]\tvalid_0's auc: 0.715804\tvalid_0's binary_logloss: 0.251128\n",
      "[124]\tvalid_0's auc: 0.71593\tvalid_0's binary_logloss: 0.251074\n",
      "[125]\tvalid_0's auc: 0.716\tvalid_0's binary_logloss: 0.25102\n",
      "[126]\tvalid_0's auc: 0.716633\tvalid_0's binary_logloss: 0.250903\n",
      "[127]\tvalid_0's auc: 0.716905\tvalid_0's binary_logloss: 0.250858\n",
      "[128]\tvalid_0's auc: 0.716828\tvalid_0's binary_logloss: 0.250792\n",
      "[129]\tvalid_0's auc: 0.716605\tvalid_0's binary_logloss: 0.250792\n",
      "[130]\tvalid_0's auc: 0.716622\tvalid_0's binary_logloss: 0.25074\n",
      "[131]\tvalid_0's auc: 0.716521\tvalid_0's binary_logloss: 0.25071\n",
      "[132]\tvalid_0's auc: 0.716129\tvalid_0's binary_logloss: 0.250739\n",
      "[133]\tvalid_0's auc: 0.716164\tvalid_0's binary_logloss: 0.250754\n",
      "[134]\tvalid_0's auc: 0.716241\tvalid_0's binary_logloss: 0.250743\n",
      "[135]\tvalid_0's auc: 0.71694\tvalid_0's binary_logloss: 0.25064\n",
      "[136]\tvalid_0's auc: 0.716895\tvalid_0's binary_logloss: 0.250622\n",
      "[137]\tvalid_0's auc: 0.716839\tvalid_0's binary_logloss: 0.250612\n",
      "[138]\tvalid_0's auc: 0.716482\tvalid_0's binary_logloss: 0.25064\n",
      "[139]\tvalid_0's auc: 0.716346\tvalid_0's binary_logloss: 0.25064\n",
      "[140]\tvalid_0's auc: 0.716664\tvalid_0's binary_logloss: 0.250532\n",
      "[141]\tvalid_0's auc: 0.717049\tvalid_0's binary_logloss: 0.250432\n",
      "[142]\tvalid_0's auc: 0.716769\tvalid_0's binary_logloss: 0.250428\n",
      "[143]\tvalid_0's auc: 0.716643\tvalid_0's binary_logloss: 0.250391\n",
      "[144]\tvalid_0's auc: 0.716174\tvalid_0's binary_logloss: 0.250381\n",
      "[145]\tvalid_0's auc: 0.716744\tvalid_0's binary_logloss: 0.250242\n",
      "[146]\tvalid_0's auc: 0.717409\tvalid_0's binary_logloss: 0.250201\n",
      "[147]\tvalid_0's auc: 0.7168\tvalid_0's binary_logloss: 0.250255\n",
      "[148]\tvalid_0's auc: 0.717241\tvalid_0's binary_logloss: 0.250208\n",
      "[149]\tvalid_0's auc: 0.71715\tvalid_0's binary_logloss: 0.250202\n",
      "[150]\tvalid_0's auc: 0.71786\tvalid_0's binary_logloss: 0.250121\n",
      "[151]\tvalid_0's auc: 0.717727\tvalid_0's binary_logloss: 0.250105\n",
      "[152]\tvalid_0's auc: 0.717933\tvalid_0's binary_logloss: 0.249988\n",
      "[153]\tvalid_0's auc: 0.717762\tvalid_0's binary_logloss: 0.249959\n",
      "[154]\tvalid_0's auc: 0.717769\tvalid_0's binary_logloss: 0.249953\n",
      "[155]\tvalid_0's auc: 0.718325\tvalid_0's binary_logloss: 0.249782\n",
      "[156]\tvalid_0's auc: 0.718794\tvalid_0's binary_logloss: 0.249747\n",
      "[157]\tvalid_0's auc: 0.718493\tvalid_0's binary_logloss: 0.249742\n",
      "[158]\tvalid_0's auc: 0.718542\tvalid_0's binary_logloss: 0.249677\n",
      "[159]\tvalid_0's auc: 0.718409\tvalid_0's binary_logloss: 0.249657\n",
      "[160]\tvalid_0's auc: 0.718926\tvalid_0's binary_logloss: 0.249578\n",
      "[161]\tvalid_0's auc: 0.718486\tvalid_0's binary_logloss: 0.249631\n",
      "[162]\tvalid_0's auc: 0.718496\tvalid_0's binary_logloss: 0.249649\n",
      "[163]\tvalid_0's auc: 0.718398\tvalid_0's binary_logloss: 0.249648\n",
      "[164]\tvalid_0's auc: 0.718147\tvalid_0's binary_logloss: 0.249652\n",
      "[165]\tvalid_0's auc: 0.71778\tvalid_0's binary_logloss: 0.249636\n",
      "[166]\tvalid_0's auc: 0.717895\tvalid_0's binary_logloss: 0.249578\n",
      "[167]\tvalid_0's auc: 0.718542\tvalid_0's binary_logloss: 0.249515\n",
      "[168]\tvalid_0's auc: 0.718126\tvalid_0's binary_logloss: 0.249531\n",
      "[169]\tvalid_0's auc: 0.718549\tvalid_0's binary_logloss: 0.249471\n",
      "[170]\tvalid_0's auc: 0.71858\tvalid_0's binary_logloss: 0.249444\n",
      "[171]\tvalid_0's auc: 0.718668\tvalid_0's binary_logloss: 0.249401\n",
      "[172]\tvalid_0's auc: 0.718409\tvalid_0's binary_logloss: 0.249403\n",
      "[173]\tvalid_0's auc: 0.718398\tvalid_0's binary_logloss: 0.249362\n",
      "[174]\tvalid_0's auc: 0.718346\tvalid_0's binary_logloss: 0.249375\n",
      "[175]\tvalid_0's auc: 0.718612\tvalid_0's binary_logloss: 0.249319\n",
      "[176]\tvalid_0's auc: 0.718801\tvalid_0's binary_logloss: 0.24929\n",
      "[177]\tvalid_0's auc: 0.718717\tvalid_0's binary_logloss: 0.24926\n",
      "[178]\tvalid_0's auc: 0.718965\tvalid_0's binary_logloss: 0.249218\n",
      "[179]\tvalid_0's auc: 0.718986\tvalid_0's binary_logloss: 0.249196\n",
      "[180]\tvalid_0's auc: 0.719486\tvalid_0's binary_logloss: 0.24913\n",
      "[181]\tvalid_0's auc: 0.71929\tvalid_0's binary_logloss: 0.249134\n",
      "[182]\tvalid_0's auc: 0.719234\tvalid_0's binary_logloss: 0.24909\n",
      "[183]\tvalid_0's auc: 0.719087\tvalid_0's binary_logloss: 0.249088\n",
      "[184]\tvalid_0's auc: 0.718874\tvalid_0's binary_logloss: 0.24909\n",
      "[185]\tvalid_0's auc: 0.71844\tvalid_0's binary_logloss: 0.249179\n",
      "[186]\tvalid_0's auc: 0.718126\tvalid_0's binary_logloss: 0.249199\n",
      "[187]\tvalid_0's auc: 0.717818\tvalid_0's binary_logloss: 0.249224\n",
      "[188]\tvalid_0's auc: 0.718147\tvalid_0's binary_logloss: 0.249192\n",
      "[189]\tvalid_0's auc: 0.717801\tvalid_0's binary_logloss: 0.249233\n",
      "[190]\tvalid_0's auc: 0.71765\tvalid_0's binary_logloss: 0.249277\n",
      "[191]\tvalid_0's auc: 0.717867\tvalid_0's binary_logloss: 0.249222\n",
      "[192]\tvalid_0's auc: 0.717759\tvalid_0's binary_logloss: 0.249215\n",
      "[193]\tvalid_0's auc: 0.717776\tvalid_0's binary_logloss: 0.249225\n",
      "[194]\tvalid_0's auc: 0.717342\tvalid_0's binary_logloss: 0.249259\n",
      "[195]\tvalid_0's auc: 0.71721\tvalid_0's binary_logloss: 0.249251\n",
      "[196]\tvalid_0's auc: 0.717098\tvalid_0's binary_logloss: 0.249233\n",
      "[197]\tvalid_0's auc: 0.716839\tvalid_0's binary_logloss: 0.24931\n",
      "[198]\tvalid_0's auc: 0.717311\tvalid_0's binary_logloss: 0.249209\n",
      "[199]\tvalid_0's auc: 0.717678\tvalid_0's binary_logloss: 0.249119\n",
      "[200]\tvalid_0's auc: 0.71829\tvalid_0's binary_logloss: 0.249071\n",
      "[201]\tvalid_0's auc: 0.718643\tvalid_0's binary_logloss: 0.248997\n",
      "[202]\tvalid_0's auc: 0.718696\tvalid_0's binary_logloss: 0.248946\n",
      "[203]\tvalid_0's auc: 0.718804\tvalid_0's binary_logloss: 0.2489\n",
      "[204]\tvalid_0's auc: 0.718552\tvalid_0's binary_logloss: 0.248955\n",
      "[205]\tvalid_0's auc: 0.718409\tvalid_0's binary_logloss: 0.248954\n",
      "[206]\tvalid_0's auc: 0.718794\tvalid_0's binary_logloss: 0.248854\n",
      "[207]\tvalid_0's auc: 0.718538\tvalid_0's binary_logloss: 0.248849\n",
      "[208]\tvalid_0's auc: 0.718629\tvalid_0's binary_logloss: 0.248848\n",
      "[209]\tvalid_0's auc: 0.718612\tvalid_0's binary_logloss: 0.248872\n",
      "[210]\tvalid_0's auc: 0.718881\tvalid_0's binary_logloss: 0.248857\n",
      "[211]\tvalid_0's auc: 0.719059\tvalid_0's binary_logloss: 0.248841\n",
      "[212]\tvalid_0's auc: 0.719528\tvalid_0's binary_logloss: 0.248774\n",
      "[213]\tvalid_0's auc: 0.719241\tvalid_0's binary_logloss: 0.248779\n",
      "[214]\tvalid_0's auc: 0.719615\tvalid_0's binary_logloss: 0.248729\n",
      "[215]\tvalid_0's auc: 0.71986\tvalid_0's binary_logloss: 0.248696\n",
      "[216]\tvalid_0's auc: 0.719388\tvalid_0's binary_logloss: 0.248776\n",
      "[217]\tvalid_0's auc: 0.719472\tvalid_0's binary_logloss: 0.248769\n",
      "[218]\tvalid_0's auc: 0.719273\tvalid_0's binary_logloss: 0.248791\n",
      "[219]\tvalid_0's auc: 0.719227\tvalid_0's binary_logloss: 0.248773\n",
      "[220]\tvalid_0's auc: 0.718982\tvalid_0's binary_logloss: 0.248817\n",
      "[221]\tvalid_0's auc: 0.719045\tvalid_0's binary_logloss: 0.248802\n",
      "[222]\tvalid_0's auc: 0.718937\tvalid_0's binary_logloss: 0.24877\n",
      "[223]\tvalid_0's auc: 0.718682\tvalid_0's binary_logloss: 0.248805\n",
      "[224]\tvalid_0's auc: 0.718594\tvalid_0's binary_logloss: 0.248784\n",
      "[225]\tvalid_0's auc: 0.719283\tvalid_0's binary_logloss: 0.248701\n",
      "[226]\tvalid_0's auc: 0.719084\tvalid_0's binary_logloss: 0.248733\n",
      "[227]\tvalid_0's auc: 0.718475\tvalid_0's binary_logloss: 0.248832\n",
      "[228]\tvalid_0's auc: 0.718864\tvalid_0's binary_logloss: 0.248794\n",
      "[229]\tvalid_0's auc: 0.718591\tvalid_0's binary_logloss: 0.248851\n",
      "[230]\tvalid_0's auc: 0.718885\tvalid_0's binary_logloss: 0.248802\n",
      "[231]\tvalid_0's auc: 0.718909\tvalid_0's binary_logloss: 0.248827\n",
      "[232]\tvalid_0's auc: 0.718905\tvalid_0's binary_logloss: 0.248793\n",
      "[233]\tvalid_0's auc: 0.718836\tvalid_0's binary_logloss: 0.248801\n",
      "[234]\tvalid_0's auc: 0.718636\tvalid_0's binary_logloss: 0.248798\n",
      "[235]\tvalid_0's auc: 0.71844\tvalid_0's binary_logloss: 0.248843\n",
      "[236]\tvalid_0's auc: 0.718252\tvalid_0's binary_logloss: 0.248858\n",
      "[237]\tvalid_0's auc: 0.718052\tvalid_0's binary_logloss: 0.24888\n",
      "[238]\tvalid_0's auc: 0.718262\tvalid_0's binary_logloss: 0.248872\n",
      "[239]\tvalid_0's auc: 0.718007\tvalid_0's binary_logloss: 0.248938\n",
      "[240]\tvalid_0's auc: 0.717479\tvalid_0's binary_logloss: 0.248999\n",
      "[241]\tvalid_0's auc: 0.717842\tvalid_0's binary_logloss: 0.248969\n",
      "[242]\tvalid_0's auc: 0.718147\tvalid_0's binary_logloss: 0.248912\n",
      "[243]\tvalid_0's auc: 0.718266\tvalid_0's binary_logloss: 0.24889\n",
      "[244]\tvalid_0's auc: 0.717965\tvalid_0's binary_logloss: 0.248938\n",
      "[245]\tvalid_0's auc: 0.717989\tvalid_0's binary_logloss: 0.248983\n",
      "[246]\tvalid_0's auc: 0.718129\tvalid_0's binary_logloss: 0.248942\n",
      "[247]\tvalid_0's auc: 0.718248\tvalid_0's binary_logloss: 0.248931\n",
      "[248]\tvalid_0's auc: 0.718468\tvalid_0's binary_logloss: 0.24892\n",
      "[249]\tvalid_0's auc: 0.718217\tvalid_0's binary_logloss: 0.248952\n",
      "[250]\tvalid_0's auc: 0.718329\tvalid_0's binary_logloss: 0.248959\n",
      "[251]\tvalid_0's auc: 0.718112\tvalid_0's binary_logloss: 0.248975\n",
      "[252]\tvalid_0's auc: 0.717863\tvalid_0's binary_logloss: 0.248986\n",
      "[253]\tvalid_0's auc: 0.718056\tvalid_0's binary_logloss: 0.248994\n",
      "[254]\tvalid_0's auc: 0.717905\tvalid_0's binary_logloss: 0.249025\n",
      "[255]\tvalid_0's auc: 0.718063\tvalid_0's binary_logloss: 0.249048\n",
      "[256]\tvalid_0's auc: 0.717731\tvalid_0's binary_logloss: 0.249102\n",
      "[257]\tvalid_0's auc: 0.717465\tvalid_0's binary_logloss: 0.249147\n",
      "[258]\tvalid_0's auc: 0.717283\tvalid_0's binary_logloss: 0.249201\n",
      "[259]\tvalid_0's auc: 0.717157\tvalid_0's binary_logloss: 0.249214\n",
      "[260]\tvalid_0's auc: 0.717556\tvalid_0's binary_logloss: 0.249132\n",
      "[261]\tvalid_0's auc: 0.717626\tvalid_0's binary_logloss: 0.249089\n",
      "[262]\tvalid_0's auc: 0.717217\tvalid_0's binary_logloss: 0.249135\n",
      "[263]\tvalid_0's auc: 0.717248\tvalid_0's binary_logloss: 0.249137\n",
      "[264]\tvalid_0's auc: 0.71772\tvalid_0's binary_logloss: 0.249062\n",
      "[265]\tvalid_0's auc: 0.717801\tvalid_0's binary_logloss: 0.24908\n",
      "[266]\tvalid_0's auc: 0.717877\tvalid_0's binary_logloss: 0.249071\n",
      "[267]\tvalid_0's auc: 0.717717\tvalid_0's binary_logloss: 0.249105\n",
      "[268]\tvalid_0's auc: 0.717412\tvalid_0's binary_logloss: 0.24917\n",
      "[269]\tvalid_0's auc: 0.717538\tvalid_0's binary_logloss: 0.249156\n",
      "[270]\tvalid_0's auc: 0.717629\tvalid_0's binary_logloss: 0.249092\n",
      "[271]\tvalid_0's auc: 0.717832\tvalid_0's binary_logloss: 0.249094\n",
      "[272]\tvalid_0's auc: 0.717678\tvalid_0's binary_logloss: 0.249131\n",
      "[273]\tvalid_0's auc: 0.717965\tvalid_0's binary_logloss: 0.249029\n",
      "[274]\tvalid_0's auc: 0.717933\tvalid_0's binary_logloss: 0.249057\n",
      "[275]\tvalid_0's auc: 0.717835\tvalid_0's binary_logloss: 0.24907\n",
      "[276]\tvalid_0's auc: 0.71771\tvalid_0's binary_logloss: 0.249082\n",
      "[277]\tvalid_0's auc: 0.717454\tvalid_0's binary_logloss: 0.249112\n",
      "[278]\tvalid_0's auc: 0.717545\tvalid_0's binary_logloss: 0.249111\n",
      "[279]\tvalid_0's auc: 0.717356\tvalid_0's binary_logloss: 0.249162\n",
      "[280]\tvalid_0's auc: 0.717668\tvalid_0's binary_logloss: 0.249136\n",
      "[281]\tvalid_0's auc: 0.717524\tvalid_0's binary_logloss: 0.249158\n",
      "[282]\tvalid_0's auc: 0.717248\tvalid_0's binary_logloss: 0.249227\n",
      "[283]\tvalid_0's auc: 0.717161\tvalid_0's binary_logloss: 0.249235\n",
      "[284]\tvalid_0's auc: 0.717189\tvalid_0's binary_logloss: 0.249252\n",
      "[285]\tvalid_0's auc: 0.716898\tvalid_0's binary_logloss: 0.249329\n",
      "[286]\tvalid_0's auc: 0.716723\tvalid_0's binary_logloss: 0.249331\n",
      "[287]\tvalid_0's auc: 0.716727\tvalid_0's binary_logloss: 0.249281\n",
      "[288]\tvalid_0's auc: 0.716412\tvalid_0's binary_logloss: 0.24936\n",
      "[289]\tvalid_0's auc: 0.716769\tvalid_0's binary_logloss: 0.249304\n",
      "[290]\tvalid_0's auc: 0.717692\tvalid_0's binary_logloss: 0.249175\n",
      "[291]\tvalid_0's auc: 0.717783\tvalid_0's binary_logloss: 0.249177\n",
      "[292]\tvalid_0's auc: 0.717884\tvalid_0's binary_logloss: 0.249173\n",
      "[293]\tvalid_0's auc: 0.717982\tvalid_0's binary_logloss: 0.249158\n",
      "[294]\tvalid_0's auc: 0.717804\tvalid_0's binary_logloss: 0.249189\n",
      "[295]\tvalid_0's auc: 0.718147\tvalid_0's binary_logloss: 0.249153\n",
      "[296]\tvalid_0's auc: 0.71793\tvalid_0's binary_logloss: 0.249234\n",
      "[297]\tvalid_0's auc: 0.717776\tvalid_0's binary_logloss: 0.249245\n",
      "[298]\tvalid_0's auc: 0.717776\tvalid_0's binary_logloss: 0.249254\n",
      "[299]\tvalid_0's auc: 0.718052\tvalid_0's binary_logloss: 0.249227\n",
      "[300]\tvalid_0's auc: 0.718031\tvalid_0's binary_logloss: 0.249242\n",
      "[301]\tvalid_0's auc: 0.71821\tvalid_0's binary_logloss: 0.249218\n",
      "[302]\tvalid_0's auc: 0.718108\tvalid_0's binary_logloss: 0.249276\n",
      "[303]\tvalid_0's auc: 0.718168\tvalid_0's binary_logloss: 0.249256\n",
      "[304]\tvalid_0's auc: 0.718346\tvalid_0's binary_logloss: 0.249244\n",
      "[305]\tvalid_0's auc: 0.718294\tvalid_0's binary_logloss: 0.249232\n",
      "[306]\tvalid_0's auc: 0.718552\tvalid_0's binary_logloss: 0.249201\n",
      "[307]\tvalid_0's auc: 0.718664\tvalid_0's binary_logloss: 0.249182\n",
      "[308]\tvalid_0's auc: 0.718619\tvalid_0's binary_logloss: 0.249224\n",
      "[309]\tvalid_0's auc: 0.71907\tvalid_0's binary_logloss: 0.249137\n",
      "[310]\tvalid_0's auc: 0.719325\tvalid_0's binary_logloss: 0.249064\n",
      "[311]\tvalid_0's auc: 0.719535\tvalid_0's binary_logloss: 0.249019\n",
      "[312]\tvalid_0's auc: 0.719311\tvalid_0's binary_logloss: 0.249062\n",
      "[313]\tvalid_0's auc: 0.719224\tvalid_0's binary_logloss: 0.249065\n",
      "[314]\tvalid_0's auc: 0.719322\tvalid_0's binary_logloss: 0.249072\n",
      "[315]\tvalid_0's auc: 0.719308\tvalid_0's binary_logloss: 0.249083\n",
      "[316]\tvalid_0's auc: 0.719192\tvalid_0's binary_logloss: 0.249151\n",
      "[317]\tvalid_0's auc: 0.719276\tvalid_0's binary_logloss: 0.249125\n",
      "[318]\tvalid_0's auc: 0.719287\tvalid_0's binary_logloss: 0.249131\n",
      "[319]\tvalid_0's auc: 0.719154\tvalid_0's binary_logloss: 0.249145\n",
      "[320]\tvalid_0's auc: 0.719126\tvalid_0's binary_logloss: 0.249187\n",
      "[321]\tvalid_0's auc: 0.719434\tvalid_0's binary_logloss: 0.249125\n",
      "[322]\tvalid_0's auc: 0.719444\tvalid_0's binary_logloss: 0.249079\n",
      "[323]\tvalid_0's auc: 0.719024\tvalid_0's binary_logloss: 0.249202\n",
      "[324]\tvalid_0's auc: 0.719042\tvalid_0's binary_logloss: 0.249212\n",
      "[325]\tvalid_0's auc: 0.719332\tvalid_0's binary_logloss: 0.249196\n",
      "[326]\tvalid_0's auc: 0.719353\tvalid_0's binary_logloss: 0.249137\n",
      "[327]\tvalid_0's auc: 0.7195\tvalid_0's binary_logloss: 0.249122\n",
      "[328]\tvalid_0's auc: 0.719853\tvalid_0's binary_logloss: 0.249056\n",
      "[329]\tvalid_0's auc: 0.719853\tvalid_0's binary_logloss: 0.249065\n",
      "[330]\tvalid_0's auc: 0.720122\tvalid_0's binary_logloss: 0.249018\n",
      "[331]\tvalid_0's auc: 0.720465\tvalid_0's binary_logloss: 0.248975\n",
      "[332]\tvalid_0's auc: 0.72043\tvalid_0's binary_logloss: 0.249007\n",
      "[333]\tvalid_0's auc: 0.720395\tvalid_0's binary_logloss: 0.249042\n",
      "[334]\tvalid_0's auc: 0.720493\tvalid_0's binary_logloss: 0.249023\n",
      "[335]\tvalid_0's auc: 0.72043\tvalid_0's binary_logloss: 0.24903\n",
      "[336]\tvalid_0's auc: 0.720395\tvalid_0's binary_logloss: 0.249046\n",
      "[337]\tvalid_0's auc: 0.720559\tvalid_0's binary_logloss: 0.249001\n",
      "[338]\tvalid_0's auc: 0.720294\tvalid_0's binary_logloss: 0.249055\n",
      "[339]\tvalid_0's auc: 0.72028\tvalid_0's binary_logloss: 0.249056\n",
      "[340]\tvalid_0's auc: 0.720388\tvalid_0's binary_logloss: 0.249023\n",
      "[341]\tvalid_0's auc: 0.720622\tvalid_0's binary_logloss: 0.249019\n",
      "[342]\tvalid_0's auc: 0.720507\tvalid_0's binary_logloss: 0.24907\n",
      "[343]\tvalid_0's auc: 0.720458\tvalid_0's binary_logloss: 0.249063\n",
      "[344]\tvalid_0's auc: 0.720535\tvalid_0's binary_logloss: 0.249037\n",
      "[345]\tvalid_0's auc: 0.720483\tvalid_0's binary_logloss: 0.249046\n",
      "[346]\tvalid_0's auc: 0.720539\tvalid_0's binary_logloss: 0.249072\n",
      "[347]\tvalid_0's auc: 0.720339\tvalid_0's binary_logloss: 0.249114\n",
      "[348]\tvalid_0's auc: 0.72036\tvalid_0's binary_logloss: 0.249141\n",
      "[349]\tvalid_0's auc: 0.720539\tvalid_0's binary_logloss: 0.249121\n",
      "[350]\tvalid_0's auc: 0.720287\tvalid_0's binary_logloss: 0.249189\n",
      "[351]\tvalid_0's auc: 0.720511\tvalid_0's binary_logloss: 0.249177\n",
      "[352]\tvalid_0's auc: 0.720311\tvalid_0's binary_logloss: 0.249185\n",
      "[353]\tvalid_0's auc: 0.720311\tvalid_0's binary_logloss: 0.24922\n",
      "[354]\tvalid_0's auc: 0.720448\tvalid_0's binary_logloss: 0.249212\n",
      "[355]\tvalid_0's auc: 0.720283\tvalid_0's binary_logloss: 0.249236\n",
      "[356]\tvalid_0's auc: 0.72028\tvalid_0's binary_logloss: 0.249242\n",
      "[357]\tvalid_0's auc: 0.720164\tvalid_0's binary_logloss: 0.249277\n",
      "[358]\tvalid_0's auc: 0.720329\tvalid_0's binary_logloss: 0.249274\n",
      "[359]\tvalid_0's auc: 0.720504\tvalid_0's binary_logloss: 0.249286\n",
      "[360]\tvalid_0's auc: 0.720465\tvalid_0's binary_logloss: 0.2493\n",
      "[361]\tvalid_0's auc: 0.720692\tvalid_0's binary_logloss: 0.24932\n",
      "[362]\tvalid_0's auc: 0.720661\tvalid_0's binary_logloss: 0.249341\n",
      "[363]\tvalid_0's auc: 0.720675\tvalid_0's binary_logloss: 0.24936\n",
      "[364]\tvalid_0's auc: 0.720836\tvalid_0's binary_logloss: 0.249323\n",
      "[365]\tvalid_0's auc: 0.720762\tvalid_0's binary_logloss: 0.249344\n",
      "[366]\tvalid_0's auc: 0.720832\tvalid_0's binary_logloss: 0.249368\n",
      "[367]\tvalid_0's auc: 0.72079\tvalid_0's binary_logloss: 0.249405\n",
      "[368]\tvalid_0's auc: 0.720797\tvalid_0's binary_logloss: 0.249416\n",
      "[369]\tvalid_0's auc: 0.720552\tvalid_0's binary_logloss: 0.24946\n",
      "[370]\tvalid_0's auc: 0.720476\tvalid_0's binary_logloss: 0.249513\n",
      "[371]\tvalid_0's auc: 0.720059\tvalid_0's binary_logloss: 0.249597\n",
      "[372]\tvalid_0's auc: 0.720308\tvalid_0's binary_logloss: 0.249571\n",
      "[373]\tvalid_0's auc: 0.72022\tvalid_0's binary_logloss: 0.249592\n",
      "[374]\tvalid_0's auc: 0.720154\tvalid_0's binary_logloss: 0.249606\n",
      "[375]\tvalid_0's auc: 0.720308\tvalid_0's binary_logloss: 0.249575\n",
      "[376]\tvalid_0's auc: 0.71979\tvalid_0's binary_logloss: 0.249648\n",
      "[377]\tvalid_0's auc: 0.71992\tvalid_0's binary_logloss: 0.24963\n",
      "[378]\tvalid_0's auc: 0.720196\tvalid_0's binary_logloss: 0.249613\n",
      "[379]\tvalid_0's auc: 0.720276\tvalid_0's binary_logloss: 0.249552\n",
      "[380]\tvalid_0's auc: 0.720332\tvalid_0's binary_logloss: 0.249554\n",
      "[381]\tvalid_0's auc: 0.720259\tvalid_0's binary_logloss: 0.249585\n",
      "[382]\tvalid_0's auc: 0.720133\tvalid_0's binary_logloss: 0.249581\n",
      "[383]\tvalid_0's auc: 0.720346\tvalid_0's binary_logloss: 0.249578\n",
      "[384]\tvalid_0's auc: 0.720427\tvalid_0's binary_logloss: 0.249594\n",
      "[385]\tvalid_0's auc: 0.720318\tvalid_0's binary_logloss: 0.249579\n",
      "[386]\tvalid_0's auc: 0.720098\tvalid_0's binary_logloss: 0.249624\n",
      "[387]\tvalid_0's auc: 0.719969\tvalid_0's binary_logloss: 0.249686\n",
      "[388]\tvalid_0's auc: 0.720339\tvalid_0's binary_logloss: 0.249603\n",
      "[389]\tvalid_0's auc: 0.720601\tvalid_0's binary_logloss: 0.249552\n",
      "[390]\tvalid_0's auc: 0.720301\tvalid_0's binary_logloss: 0.24962\n",
      "[391]\tvalid_0's auc: 0.720133\tvalid_0's binary_logloss: 0.249648\n",
      "[392]\tvalid_0's auc: 0.720563\tvalid_0's binary_logloss: 0.249581\n",
      "[393]\tvalid_0's auc: 0.720713\tvalid_0's binary_logloss: 0.24955\n",
      "[394]\tvalid_0's auc: 0.720483\tvalid_0's binary_logloss: 0.249603\n",
      "[395]\tvalid_0's auc: 0.720605\tvalid_0's binary_logloss: 0.249605\n",
      "[396]\tvalid_0's auc: 0.720717\tvalid_0's binary_logloss: 0.249594\n",
      "[397]\tvalid_0's auc: 0.720587\tvalid_0's binary_logloss: 0.249625\n",
      "[398]\tvalid_0's auc: 0.720486\tvalid_0's binary_logloss: 0.249656\n",
      "[399]\tvalid_0's auc: 0.720301\tvalid_0's binary_logloss: 0.249713\n",
      "[400]\tvalid_0's auc: 0.720234\tvalid_0's binary_logloss: 0.249716\n",
      "[401]\tvalid_0's auc: 0.71999\tvalid_0's binary_logloss: 0.249761\n",
      "[402]\tvalid_0's auc: 0.719895\tvalid_0's binary_logloss: 0.249794\n",
      "[403]\tvalid_0's auc: 0.719969\tvalid_0's binary_logloss: 0.249798\n",
      "[404]\tvalid_0's auc: 0.719703\tvalid_0's binary_logloss: 0.249849\n",
      "[405]\tvalid_0's auc: 0.719794\tvalid_0's binary_logloss: 0.249846\n",
      "[406]\tvalid_0's auc: 0.719766\tvalid_0's binary_logloss: 0.249847\n",
      "[407]\tvalid_0's auc: 0.719811\tvalid_0's binary_logloss: 0.249842\n",
      "[408]\tvalid_0's auc: 0.71986\tvalid_0's binary_logloss: 0.249854\n",
      "[409]\tvalid_0's auc: 0.719724\tvalid_0's binary_logloss: 0.249838\n",
      "[410]\tvalid_0's auc: 0.719787\tvalid_0's binary_logloss: 0.249839\n",
      "[411]\tvalid_0's auc: 0.71993\tvalid_0's binary_logloss: 0.249833\n",
      "[412]\tvalid_0's auc: 0.720136\tvalid_0's binary_logloss: 0.249787\n",
      "[413]\tvalid_0's auc: 0.720028\tvalid_0's binary_logloss: 0.249797\n",
      "[414]\tvalid_0's auc: 0.720329\tvalid_0's binary_logloss: 0.24973\n",
      "[415]\tvalid_0's auc: 0.720395\tvalid_0's binary_logloss: 0.249711\n",
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's auc: 0.71986\tvalid_0's binary_logloss: 0.248696\n"
     ]
    }
   ],
   "source": [
    "lgbc=LGBMClassifier(**{**default_params, **dict(trial.params.items())})\n",
    "lgbc.fit(train_features, train_target, eval_set=(test_features, test_target), eval_metric = 'auc')\n",
    "LGBM_optuna_predicted_train = lgbc.predict_proba(train_features)\n",
    "LGBM_optuna_predicted_test = lgbc.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c66ac298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def convert_proba_to_class(probability, thereshold = 0.8):\n",
    "    return np.where(probability < thereshold, 1, 0)[:,0]\n",
    "\n",
    "sns.distplot(LGBM_optuna_predicted_test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d3619604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9297474238294509"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(train_target, LGBM_predicted_train[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5fc72204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7202028149313751"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_target, LGBM_predicted_test[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ee94bf59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9169218772692423"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(train_target, LGBM_optuna_predicted_train[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "db446e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7198601276335344"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_target, LGBM_optuna_predicted_test[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "933216f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM_predicted_train = LGBM_predicted_train[:, 1]\n",
    "LGBM_predicted_test = LGBM_predicted_test[:, 1]\n",
    "LGBM_optuna_predicted_train = LGBM_optuna_predicted_train[:, 1]\n",
    "LGBM_optuna_predicted_test = LGBM_optuna_predicted_test[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "71338e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LGBM</th>\n",
       "      <th>LGBM_optuna</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>...</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.221159</td>\n",
       "      <td>0.092567</td>\n",
       "      <td>315992</td>\n",
       "      <td>0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>545040.0</td>\n",
       "      <td>25537.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>-2344.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027759</td>\n",
       "      <td>0.026853</td>\n",
       "      <td>284326</td>\n",
       "      <td>1</td>\n",
       "      <td>130500.0</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>38133.0</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>-5122.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.144896</td>\n",
       "      <td>0.055389</td>\n",
       "      <td>155276</td>\n",
       "      <td>0</td>\n",
       "      <td>382500.0</td>\n",
       "      <td>1532565.0</td>\n",
       "      <td>65061.0</td>\n",
       "      <td>1323000.0</td>\n",
       "      <td>0.020713</td>\n",
       "      <td>-10348.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.046852</td>\n",
       "      <td>0.154463</td>\n",
       "      <td>419231</td>\n",
       "      <td>0</td>\n",
       "      <td>85500.0</td>\n",
       "      <td>1288350.0</td>\n",
       "      <td>37800.0</td>\n",
       "      <td>1125000.0</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>-4109.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.245430</td>\n",
       "      <td>0.035765</td>\n",
       "      <td>289793</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>659610.0</td>\n",
       "      <td>25686.0</td>\n",
       "      <td>472500.0</td>\n",
       "      <td>0.020246</td>\n",
       "      <td>-881.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>0.044912</td>\n",
       "      <td>0.060379</td>\n",
       "      <td>395317</td>\n",
       "      <td>0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>227520.0</td>\n",
       "      <td>8707.5</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-859.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>0.042270</td>\n",
       "      <td>0.039493</td>\n",
       "      <td>287864</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-2184.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>0.058817</td>\n",
       "      <td>0.049940</td>\n",
       "      <td>101371</td>\n",
       "      <td>1</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>1024636.5</td>\n",
       "      <td>33993.0</td>\n",
       "      <td>918000.0</td>\n",
       "      <td>0.035792</td>\n",
       "      <td>-6085.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>0.103143</td>\n",
       "      <td>0.130303</td>\n",
       "      <td>275047</td>\n",
       "      <td>1</td>\n",
       "      <td>120339.0</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>28593.0</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>0.030755</td>\n",
       "      <td>-3982.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>0.044318</td>\n",
       "      <td>0.192427</td>\n",
       "      <td>429771</td>\n",
       "      <td>0</td>\n",
       "      <td>160515.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>32697.0</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>0.014520</td>\n",
       "      <td>-2591.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 247 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          LGBM  LGBM_optuna  SK_ID_CURR  CNT_CHILDREN  AMT_INCOME_TOTAL  \\\n",
       "0     0.221159     0.092567      315992             0          180000.0   \n",
       "1     0.027759     0.026853      284326             1          130500.0   \n",
       "2     0.144896     0.055389      155276             0          382500.0   \n",
       "3     0.046852     0.154463      419231             0           85500.0   \n",
       "4     0.245430     0.035765      289793             0           67500.0   \n",
       "...        ...          ...         ...           ...               ...   \n",
       "7995  0.044912     0.060379      395317             0          180000.0   \n",
       "7996  0.042270     0.039493      287864             0          202500.0   \n",
       "7997  0.058817     0.049940      101371             1          315000.0   \n",
       "7998  0.103143     0.130303      275047             1          120339.0   \n",
       "7999  0.044318     0.192427      429771             0          160515.0   \n",
       "\n",
       "      AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  \\\n",
       "0       545040.0      25537.5         450000.0                    0.003069   \n",
       "1       900000.0      38133.0         900000.0                    0.003069   \n",
       "2      1532565.0      65061.0        1323000.0                    0.020713   \n",
       "3      1288350.0      37800.0        1125000.0                    0.003813   \n",
       "4       659610.0      25686.0         472500.0                    0.020246   \n",
       "...          ...          ...              ...                         ...   \n",
       "7995    227520.0       8707.5         180000.0                    0.018801   \n",
       "7996    270000.0      13500.0         270000.0                    0.028663   \n",
       "7997   1024636.5      33993.0         918000.0                    0.035792   \n",
       "7998   1035000.0      28593.0        1035000.0                    0.030755   \n",
       "7999   1293502.5      32697.0        1129500.0                    0.014520   \n",
       "\n",
       "      DAYS_REGISTRATION  ...  129  130  131  132  133  134  135  136  137  138  \n",
       "0               -2344.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "1               -5122.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "2              -10348.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "3               -4109.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "4                -881.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "...                 ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "7995             -859.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  \n",
       "7996            -2184.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "7997            -6085.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "7998            -3982.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "7999            -2591.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "\n",
       "[8000 rows x 247 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_level_output = pd.DataFrame(data=np.array([LGBM_predicted_train, LGBM_optuna_predicted_train]).reshape(len(LGBM_predicted_train), 2), columns=['LGBM', 'LGBM_optuna'])\n",
    "first_level_output = first_level_output.join(train_full_features.reset_index(drop=True))\n",
    "first_level_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "db375523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LGBM_test</th>\n",
       "      <th>LGBM_optuna_test</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>...</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031363</td>\n",
       "      <td>0.069390</td>\n",
       "      <td>302666</td>\n",
       "      <td>0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>133528.5</td>\n",
       "      <td>9495.0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>0.026392</td>\n",
       "      <td>-10186.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035949</td>\n",
       "      <td>0.060294</td>\n",
       "      <td>406978</td>\n",
       "      <td>0</td>\n",
       "      <td>256500.0</td>\n",
       "      <td>1288350.0</td>\n",
       "      <td>41692.5</td>\n",
       "      <td>1125000.0</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>-7101.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.081944</td>\n",
       "      <td>0.030554</td>\n",
       "      <td>286663</td>\n",
       "      <td>2</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>295776.0</td>\n",
       "      <td>17109.0</td>\n",
       "      <td>234000.0</td>\n",
       "      <td>0.018850</td>\n",
       "      <td>-1806.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.091834</td>\n",
       "      <td>418961</td>\n",
       "      <td>1</td>\n",
       "      <td>48600.0</td>\n",
       "      <td>918468.0</td>\n",
       "      <td>30352.5</td>\n",
       "      <td>697500.0</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>-6892.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.218356</td>\n",
       "      <td>0.031099</td>\n",
       "      <td>354514</td>\n",
       "      <td>2</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>10620.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>0.018850</td>\n",
       "      <td>-9319.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.053308</td>\n",
       "      <td>0.043025</td>\n",
       "      <td>137502</td>\n",
       "      <td>1</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>584766.0</td>\n",
       "      <td>24903.0</td>\n",
       "      <td>472500.0</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>-7013.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.051873</td>\n",
       "      <td>0.201082</td>\n",
       "      <td>254841</td>\n",
       "      <td>0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>956574.0</td>\n",
       "      <td>43357.5</td>\n",
       "      <td>855000.0</td>\n",
       "      <td>0.008866</td>\n",
       "      <td>-974.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.078780</td>\n",
       "      <td>0.084575</td>\n",
       "      <td>341015</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>364896.0</td>\n",
       "      <td>25524.0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>0.035792</td>\n",
       "      <td>-10655.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.096249</td>\n",
       "      <td>0.064213</td>\n",
       "      <td>137328</td>\n",
       "      <td>1</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>1288350.0</td>\n",
       "      <td>37669.5</td>\n",
       "      <td>1125000.0</td>\n",
       "      <td>0.031329</td>\n",
       "      <td>-718.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.056188</td>\n",
       "      <td>0.180092</td>\n",
       "      <td>376721</td>\n",
       "      <td>1</td>\n",
       "      <td>193500.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>22018.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>0.026392</td>\n",
       "      <td>-1589.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 247 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LGBM_test  LGBM_optuna_test  SK_ID_CURR  CNT_CHILDREN  AMT_INCOME_TOTAL  \\\n",
       "0      0.031363          0.069390      302666             0           45000.0   \n",
       "1      0.035949          0.060294      406978             0          256500.0   \n",
       "2      0.081944          0.030554      286663             2          112500.0   \n",
       "3      0.085106          0.091834      418961             1           48600.0   \n",
       "4      0.218356          0.031099      354514             2           67500.0   \n",
       "...         ...               ...         ...           ...               ...   \n",
       "1995   0.053308          0.043025      137502             1          135000.0   \n",
       "1996   0.051873          0.201082      254841             0          225000.0   \n",
       "1997   0.078780          0.084575      341015             0          112500.0   \n",
       "1998   0.096249          0.064213      137328             1          157500.0   \n",
       "1999   0.056188          0.180092      376721             1          193500.0   \n",
       "\n",
       "      AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  \\\n",
       "0       133528.5       9495.0         121500.0                    0.026392   \n",
       "1      1288350.0      41692.5        1125000.0                    0.008575   \n",
       "2       295776.0      17109.0         234000.0                    0.018850   \n",
       "3       918468.0      30352.5         697500.0                    0.008019   \n",
       "4       225000.0      10620.0         225000.0                    0.018850   \n",
       "...          ...          ...              ...                         ...   \n",
       "1995    584766.0      24903.0         472500.0                    0.004849   \n",
       "1996    956574.0      43357.5         855000.0                    0.008866   \n",
       "1997    364896.0      25524.0         315000.0                    0.035792   \n",
       "1998   1288350.0      37669.5        1125000.0                    0.031329   \n",
       "1999    450000.0      22018.5         450000.0                    0.026392   \n",
       "\n",
       "      DAYS_REGISTRATION  ...  129  130  131  132  133  134  135  136  137  138  \n",
       "0              -10186.0  ...  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "1               -7101.0  ...  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "2               -1806.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "3               -6892.0  ...  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "4               -9319.0  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  \n",
       "...                 ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "1995            -7013.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "1996             -974.0  ...  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "1997           -10655.0  ...  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "1998             -718.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "1999            -1589.0  ...  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "\n",
       "[2000 rows x 247 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_level_output_test = pd.DataFrame(data=np.array([LGBM_predicted_test, LGBM_optuna_predicted_test]).reshape(len(LGBM_predicted_test), 2), columns=['LGBM_test', 'LGBM_optuna_test'])\n",
    "first_level_output_test = first_level_output_test.join(test_full_features.reset_index(drop=True))\n",
    "first_level_output_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951f19da",
   "metadata": {},
   "source": [
    "#### Second Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e5943da7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/magleb/.local/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.640019\tvalid_0's binary_logloss: 0.27238\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[2]\tvalid_0's auc: 0.679509\tvalid_0's binary_logloss: 0.272041\n",
      "[3]\tvalid_0's auc: 0.68393\tvalid_0's binary_logloss: 0.271607\n",
      "[4]\tvalid_0's auc: 0.69305\tvalid_0's binary_logloss: 0.271236\n",
      "[5]\tvalid_0's auc: 0.694847\tvalid_0's binary_logloss: 0.270767\n",
      "[6]\tvalid_0's auc: 0.697299\tvalid_0's binary_logloss: 0.270513\n",
      "[7]\tvalid_0's auc: 0.702103\tvalid_0's binary_logloss: 0.270059\n",
      "[8]\tvalid_0's auc: 0.702255\tvalid_0's binary_logloss: 0.269659\n",
      "[9]\tvalid_0's auc: 0.702759\tvalid_0's binary_logloss: 0.269247\n",
      "[10]\tvalid_0's auc: 0.698035\tvalid_0's binary_logloss: 0.269001\n",
      "[11]\tvalid_0's auc: 0.697783\tvalid_0's binary_logloss: 0.268754\n",
      "[12]\tvalid_0's auc: 0.699084\tvalid_0's binary_logloss: 0.26839\n",
      "[13]\tvalid_0's auc: 0.698552\tvalid_0's binary_logloss: 0.268033\n",
      "[14]\tvalid_0's auc: 0.700888\tvalid_0's binary_logloss: 0.267895\n",
      "[15]\tvalid_0's auc: 0.700024\tvalid_0's binary_logloss: 0.267619\n",
      "[16]\tvalid_0's auc: 0.700657\tvalid_0's binary_logloss: 0.267348\n",
      "[17]\tvalid_0's auc: 0.701413\tvalid_0's binary_logloss: 0.267055\n",
      "[18]\tvalid_0's auc: 0.702771\tvalid_0's binary_logloss: 0.266744\n",
      "[19]\tvalid_0's auc: 0.702859\tvalid_0's binary_logloss: 0.26646\n",
      "[20]\tvalid_0's auc: 0.702418\tvalid_0's binary_logloss: 0.266273\n",
      "[21]\tvalid_0's auc: 0.704062\tvalid_0's binary_logloss: 0.266061\n",
      "[22]\tvalid_0's auc: 0.704254\tvalid_0's binary_logloss: 0.265645\n",
      "[23]\tvalid_0's auc: 0.707305\tvalid_0's binary_logloss: 0.265431\n",
      "[24]\tvalid_0's auc: 0.706945\tvalid_0's binary_logloss: 0.265182\n",
      "[25]\tvalid_0's auc: 0.70721\tvalid_0's binary_logloss: 0.264861\n",
      "[26]\tvalid_0's auc: 0.705981\tvalid_0's binary_logloss: 0.264582\n",
      "[27]\tvalid_0's auc: 0.705817\tvalid_0's binary_logloss: 0.264282\n",
      "[28]\tvalid_0's auc: 0.705306\tvalid_0's binary_logloss: 0.264102\n",
      "[29]\tvalid_0's auc: 0.704112\tvalid_0's binary_logloss: 0.263852\n",
      "[30]\tvalid_0's auc: 0.704597\tvalid_0's binary_logloss: 0.263499\n",
      "[31]\tvalid_0's auc: 0.703756\tvalid_0's binary_logloss: 0.263329\n",
      "[32]\tvalid_0's auc: 0.704203\tvalid_0's binary_logloss: 0.263058\n",
      "[33]\tvalid_0's auc: 0.703707\tvalid_0's binary_logloss: 0.262822\n",
      "[34]\tvalid_0's auc: 0.702843\tvalid_0's binary_logloss: 0.262655\n",
      "[35]\tvalid_0's auc: 0.702717\tvalid_0's binary_logloss: 0.262439\n",
      "[36]\tvalid_0's auc: 0.702282\tvalid_0's binary_logloss: 0.262283\n",
      "[37]\tvalid_0's auc: 0.701418\tvalid_0's binary_logloss: 0.262143\n",
      "[38]\tvalid_0's auc: 0.701392\tvalid_0's binary_logloss: 0.261878\n",
      "[39]\tvalid_0's auc: 0.702479\tvalid_0's binary_logloss: 0.261564\n",
      "[40]\tvalid_0's auc: 0.704102\tvalid_0's binary_logloss: 0.261263\n",
      "[41]\tvalid_0's auc: 0.703948\tvalid_0's binary_logloss: 0.261122\n",
      "[42]\tvalid_0's auc: 0.703714\tvalid_0's binary_logloss: 0.260914\n",
      "[43]\tvalid_0's auc: 0.703555\tvalid_0's binary_logloss: 0.26075\n",
      "[44]\tvalid_0's auc: 0.703464\tvalid_0's binary_logloss: 0.260579\n",
      "[45]\tvalid_0's auc: 0.702939\tvalid_0's binary_logloss: 0.260457\n",
      "[46]\tvalid_0's auc: 0.704855\tvalid_0's binary_logloss: 0.26018\n",
      "[47]\tvalid_0's auc: 0.703958\tvalid_0's binary_logloss: 0.260142\n",
      "[48]\tvalid_0's auc: 0.704448\tvalid_0's binary_logloss: 0.26\n",
      "[49]\tvalid_0's auc: 0.70414\tvalid_0's binary_logloss: 0.259809\n",
      "[50]\tvalid_0's auc: 0.704689\tvalid_0's binary_logloss: 0.259656\n",
      "[51]\tvalid_0's auc: 0.704997\tvalid_0's binary_logloss: 0.259485\n",
      "[52]\tvalid_0's auc: 0.705238\tvalid_0's binary_logloss: 0.259267\n",
      "[53]\tvalid_0's auc: 0.705277\tvalid_0's binary_logloss: 0.259096\n",
      "[54]\tvalid_0's auc: 0.705528\tvalid_0's binary_logloss: 0.25895\n",
      "[55]\tvalid_0's auc: 0.705707\tvalid_0's binary_logloss: 0.258763\n",
      "[56]\tvalid_0's auc: 0.705116\tvalid_0's binary_logloss: 0.258636\n",
      "[57]\tvalid_0's auc: 0.705892\tvalid_0's binary_logloss: 0.25855\n",
      "[58]\tvalid_0's auc: 0.705971\tvalid_0's binary_logloss: 0.258458\n",
      "[59]\tvalid_0's auc: 0.706387\tvalid_0's binary_logloss: 0.258239\n",
      "[60]\tvalid_0's auc: 0.706191\tvalid_0's binary_logloss: 0.258121\n",
      "[61]\tvalid_0's auc: 0.708004\tvalid_0's binary_logloss: 0.257861\n",
      "[62]\tvalid_0's auc: 0.708924\tvalid_0's binary_logloss: 0.257678\n",
      "[63]\tvalid_0's auc: 0.708329\tvalid_0's binary_logloss: 0.257591\n",
      "[64]\tvalid_0's auc: 0.708812\tvalid_0's binary_logloss: 0.257375\n",
      "[65]\tvalid_0's auc: 0.709235\tvalid_0's binary_logloss: 0.257281\n",
      "[66]\tvalid_0's auc: 0.708739\tvalid_0's binary_logloss: 0.257247\n",
      "[67]\tvalid_0's auc: 0.709329\tvalid_0's binary_logloss: 0.257079\n",
      "[68]\tvalid_0's auc: 0.708896\tvalid_0's binary_logloss: 0.256936\n",
      "[69]\tvalid_0's auc: 0.709088\tvalid_0's binary_logloss: 0.256832\n",
      "[70]\tvalid_0's auc: 0.708903\tvalid_0's binary_logloss: 0.256794\n",
      "[71]\tvalid_0's auc: 0.708732\tvalid_0's binary_logloss: 0.256636\n",
      "[72]\tvalid_0's auc: 0.709198\tvalid_0's binary_logloss: 0.256447\n",
      "[73]\tvalid_0's auc: 0.709286\tvalid_0's binary_logloss: 0.256347\n",
      "[74]\tvalid_0's auc: 0.7098\tvalid_0's binary_logloss: 0.256203\n",
      "[75]\tvalid_0's auc: 0.709737\tvalid_0's binary_logloss: 0.256059\n",
      "[76]\tvalid_0's auc: 0.709545\tvalid_0's binary_logloss: 0.255989\n",
      "[77]\tvalid_0's auc: 0.710083\tvalid_0's binary_logloss: 0.255848\n",
      "[78]\tvalid_0's auc: 0.709989\tvalid_0's binary_logloss: 0.255734\n",
      "[79]\tvalid_0's auc: 0.709712\tvalid_0's binary_logloss: 0.255685\n",
      "[80]\tvalid_0's auc: 0.709247\tvalid_0's binary_logloss: 0.255517\n",
      "[81]\tvalid_0's auc: 0.709517\tvalid_0's binary_logloss: 0.255399\n",
      "[82]\tvalid_0's auc: 0.709541\tvalid_0's binary_logloss: 0.255279\n",
      "[83]\tvalid_0's auc: 0.709517\tvalid_0's binary_logloss: 0.255241\n",
      "[84]\tvalid_0's auc: 0.71008\tvalid_0's binary_logloss: 0.255148\n",
      "[85]\tvalid_0's auc: 0.71009\tvalid_0's binary_logloss: 0.255075\n",
      "[86]\tvalid_0's auc: 0.70973\tvalid_0's binary_logloss: 0.254991\n",
      "[87]\tvalid_0's auc: 0.709824\tvalid_0's binary_logloss: 0.254866\n",
      "[88]\tvalid_0's auc: 0.71008\tvalid_0's binary_logloss: 0.254787\n",
      "[89]\tvalid_0's auc: 0.710118\tvalid_0's binary_logloss: 0.254695\n",
      "[90]\tvalid_0's auc: 0.710202\tvalid_0's binary_logloss: 0.254594\n",
      "[91]\tvalid_0's auc: 0.710237\tvalid_0's binary_logloss: 0.254458\n",
      "[92]\tvalid_0's auc: 0.709947\tvalid_0's binary_logloss: 0.254446\n",
      "[93]\tvalid_0's auc: 0.709548\tvalid_0's binary_logloss: 0.254445\n",
      "[94]\tvalid_0's auc: 0.710433\tvalid_0's binary_logloss: 0.254287\n",
      "[95]\tvalid_0's auc: 0.710394\tvalid_0's binary_logloss: 0.254218\n",
      "[96]\tvalid_0's auc: 0.710083\tvalid_0's binary_logloss: 0.254106\n",
      "[97]\tvalid_0's auc: 0.709772\tvalid_0's binary_logloss: 0.254064\n",
      "[98]\tvalid_0's auc: 0.710181\tvalid_0's binary_logloss: 0.253948\n",
      "[99]\tvalid_0's auc: 0.710828\tvalid_0's binary_logloss: 0.253775\n",
      "[100]\tvalid_0's auc: 0.711199\tvalid_0's binary_logloss: 0.253664\n",
      "[101]\tvalid_0's auc: 0.710478\tvalid_0's binary_logloss: 0.253658\n",
      "[102]\tvalid_0's auc: 0.710996\tvalid_0's binary_logloss: 0.253529\n",
      "[103]\tvalid_0's auc: 0.710814\tvalid_0's binary_logloss: 0.253491\n",
      "[104]\tvalid_0's auc: 0.711125\tvalid_0's binary_logloss: 0.253374\n",
      "[105]\tvalid_0's auc: 0.710576\tvalid_0's binary_logloss: 0.253381\n",
      "[106]\tvalid_0's auc: 0.710796\tvalid_0's binary_logloss: 0.253278\n",
      "[107]\tvalid_0's auc: 0.710793\tvalid_0's binary_logloss: 0.253128\n",
      "[108]\tvalid_0's auc: 0.711115\tvalid_0's binary_logloss: 0.25303\n",
      "[109]\tvalid_0's auc: 0.711387\tvalid_0's binary_logloss: 0.252949\n",
      "[110]\tvalid_0's auc: 0.711814\tvalid_0's binary_logloss: 0.252866\n",
      "[111]\tvalid_0's auc: 0.711901\tvalid_0's binary_logloss: 0.252751\n",
      "[112]\tvalid_0's auc: 0.712643\tvalid_0's binary_logloss: 0.252636\n",
      "[113]\tvalid_0's auc: 0.712398\tvalid_0's binary_logloss: 0.25259\n",
      "[114]\tvalid_0's auc: 0.712174\tvalid_0's binary_logloss: 0.252508\n",
      "[115]\tvalid_0's auc: 0.712066\tvalid_0's binary_logloss: 0.252488\n",
      "[116]\tvalid_0's auc: 0.711695\tvalid_0's binary_logloss: 0.252458\n",
      "[117]\tvalid_0's auc: 0.712234\tvalid_0's binary_logloss: 0.252419\n",
      "[118]\tvalid_0's auc: 0.712034\tvalid_0's binary_logloss: 0.25243\n",
      "[119]\tvalid_0's auc: 0.711772\tvalid_0's binary_logloss: 0.252415\n",
      "[120]\tvalid_0's auc: 0.711552\tvalid_0's binary_logloss: 0.252354\n",
      "[121]\tvalid_0's auc: 0.711597\tvalid_0's binary_logloss: 0.252308\n",
      "[122]\tvalid_0's auc: 0.710863\tvalid_0's binary_logloss: 0.25229\n",
      "[123]\tvalid_0's auc: 0.710814\tvalid_0's binary_logloss: 0.25225\n",
      "[124]\tvalid_0's auc: 0.711195\tvalid_0's binary_logloss: 0.252174\n",
      "[125]\tvalid_0's auc: 0.711258\tvalid_0's binary_logloss: 0.252114\n",
      "[126]\tvalid_0's auc: 0.71124\tvalid_0's binary_logloss: 0.252072\n",
      "[127]\tvalid_0's auc: 0.711296\tvalid_0's binary_logloss: 0.252071\n",
      "[128]\tvalid_0's auc: 0.711171\tvalid_0's binary_logloss: 0.252035\n",
      "[129]\tvalid_0's auc: 0.711331\tvalid_0's binary_logloss: 0.251988\n",
      "[130]\tvalid_0's auc: 0.711429\tvalid_0's binary_logloss: 0.251966\n",
      "[131]\tvalid_0's auc: 0.711968\tvalid_0's binary_logloss: 0.251872\n",
      "[132]\tvalid_0's auc: 0.711625\tvalid_0's binary_logloss: 0.251888\n",
      "[133]\tvalid_0's auc: 0.710905\tvalid_0's binary_logloss: 0.251946\n",
      "[134]\tvalid_0's auc: 0.711139\tvalid_0's binary_logloss: 0.251906\n",
      "[135]\tvalid_0's auc: 0.711667\tvalid_0's binary_logloss: 0.251826\n",
      "[136]\tvalid_0's auc: 0.7113\tvalid_0's binary_logloss: 0.251857\n",
      "[137]\tvalid_0's auc: 0.710989\tvalid_0's binary_logloss: 0.251907\n",
      "[138]\tvalid_0's auc: 0.71087\tvalid_0's binary_logloss: 0.251887\n",
      "[139]\tvalid_0's auc: 0.711307\tvalid_0's binary_logloss: 0.251837\n",
      "[140]\tvalid_0's auc: 0.711258\tvalid_0's binary_logloss: 0.251822\n",
      "[141]\tvalid_0's auc: 0.71172\tvalid_0's binary_logloss: 0.251737\n",
      "[142]\tvalid_0's auc: 0.711587\tvalid_0's binary_logloss: 0.251745\n",
      "[143]\tvalid_0's auc: 0.711828\tvalid_0's binary_logloss: 0.251705\n",
      "[144]\tvalid_0's auc: 0.711457\tvalid_0's binary_logloss: 0.251675\n",
      "[145]\tvalid_0's auc: 0.71158\tvalid_0's binary_logloss: 0.25167\n",
      "[146]\tvalid_0's auc: 0.711755\tvalid_0's binary_logloss: 0.25159\n",
      "[147]\tvalid_0's auc: 0.711999\tvalid_0's binary_logloss: 0.251555\n",
      "[148]\tvalid_0's auc: 0.712017\tvalid_0's binary_logloss: 0.251502\n",
      "[149]\tvalid_0's auc: 0.711517\tvalid_0's binary_logloss: 0.251516\n",
      "[150]\tvalid_0's auc: 0.711814\tvalid_0's binary_logloss: 0.251462\n",
      "[151]\tvalid_0's auc: 0.711426\tvalid_0's binary_logloss: 0.251497\n",
      "[152]\tvalid_0's auc: 0.711828\tvalid_0's binary_logloss: 0.251439\n",
      "[153]\tvalid_0's auc: 0.712818\tvalid_0's binary_logloss: 0.251368\n",
      "[154]\tvalid_0's auc: 0.712797\tvalid_0's binary_logloss: 0.251324\n",
      "[155]\tvalid_0's auc: 0.712874\tvalid_0's binary_logloss: 0.251288\n",
      "[156]\tvalid_0's auc: 0.713055\tvalid_0's binary_logloss: 0.25122\n",
      "[157]\tvalid_0's auc: 0.713097\tvalid_0's binary_logloss: 0.251175\n",
      "[158]\tvalid_0's auc: 0.713073\tvalid_0's binary_logloss: 0.251152\n",
      "[159]\tvalid_0's auc: 0.71272\tvalid_0's binary_logloss: 0.251173\n",
      "[160]\tvalid_0's auc: 0.713213\tvalid_0's binary_logloss: 0.251096\n",
      "[161]\tvalid_0's auc: 0.712954\tvalid_0's binary_logloss: 0.251119\n",
      "[162]\tvalid_0's auc: 0.712863\tvalid_0's binary_logloss: 0.251087\n",
      "[163]\tvalid_0's auc: 0.712992\tvalid_0's binary_logloss: 0.251064\n",
      "[164]\tvalid_0's auc: 0.712818\tvalid_0's binary_logloss: 0.251071\n",
      "[165]\tvalid_0's auc: 0.712709\tvalid_0's binary_logloss: 0.25105\n",
      "[166]\tvalid_0's auc: 0.713139\tvalid_0's binary_logloss: 0.250961\n",
      "[167]\tvalid_0's auc: 0.712877\tvalid_0's binary_logloss: 0.250974\n",
      "[168]\tvalid_0's auc: 0.712922\tvalid_0's binary_logloss: 0.250936\n",
      "[169]\tvalid_0's auc: 0.712545\tvalid_0's binary_logloss: 0.250955\n",
      "[170]\tvalid_0's auc: 0.712632\tvalid_0's binary_logloss: 0.250885\n",
      "[171]\tvalid_0's auc: 0.712314\tvalid_0's binary_logloss: 0.250913\n",
      "[172]\tvalid_0's auc: 0.712968\tvalid_0's binary_logloss: 0.250827\n",
      "[173]\tvalid_0's auc: 0.713083\tvalid_0's binary_logloss: 0.250762\n",
      "[174]\tvalid_0's auc: 0.712762\tvalid_0's binary_logloss: 0.250749\n",
      "[175]\tvalid_0's auc: 0.713167\tvalid_0's binary_logloss: 0.250639\n",
      "[176]\tvalid_0's auc: 0.712989\tvalid_0's binary_logloss: 0.250696\n",
      "[177]\tvalid_0's auc: 0.71309\tvalid_0's binary_logloss: 0.250698\n",
      "[178]\tvalid_0's auc: 0.713276\tvalid_0's binary_logloss: 0.25064\n",
      "[179]\tvalid_0's auc: 0.713388\tvalid_0's binary_logloss: 0.250617\n",
      "[180]\tvalid_0's auc: 0.7133\tvalid_0's binary_logloss: 0.250557\n",
      "[181]\tvalid_0's auc: 0.713409\tvalid_0's binary_logloss: 0.250542\n",
      "[182]\tvalid_0's auc: 0.713293\tvalid_0's binary_logloss: 0.250593\n",
      "[183]\tvalid_0's auc: 0.713181\tvalid_0's binary_logloss: 0.250564\n",
      "[184]\tvalid_0's auc: 0.713122\tvalid_0's binary_logloss: 0.250541\n",
      "[185]\tvalid_0's auc: 0.712919\tvalid_0's binary_logloss: 0.250523\n",
      "[186]\tvalid_0's auc: 0.712989\tvalid_0's binary_logloss: 0.250521\n",
      "[187]\tvalid_0's auc: 0.713304\tvalid_0's binary_logloss: 0.250488\n",
      "[188]\tvalid_0's auc: 0.712936\tvalid_0's binary_logloss: 0.250541\n",
      "[189]\tvalid_0's auc: 0.712982\tvalid_0's binary_logloss: 0.250551\n",
      "[190]\tvalid_0's auc: 0.712821\tvalid_0's binary_logloss: 0.250524\n",
      "[191]\tvalid_0's auc: 0.713094\tvalid_0's binary_logloss: 0.250495\n",
      "[192]\tvalid_0's auc: 0.713146\tvalid_0's binary_logloss: 0.250487\n",
      "[193]\tvalid_0's auc: 0.713048\tvalid_0's binary_logloss: 0.250508\n",
      "[194]\tvalid_0's auc: 0.712957\tvalid_0's binary_logloss: 0.250488\n",
      "[195]\tvalid_0's auc: 0.713412\tvalid_0's binary_logloss: 0.250405\n",
      "[196]\tvalid_0's auc: 0.713314\tvalid_0's binary_logloss: 0.250403\n",
      "[197]\tvalid_0's auc: 0.713269\tvalid_0's binary_logloss: 0.250394\n",
      "[198]\tvalid_0's auc: 0.713097\tvalid_0's binary_logloss: 0.250448\n",
      "[199]\tvalid_0's auc: 0.713094\tvalid_0's binary_logloss: 0.250442\n",
      "[200]\tvalid_0's auc: 0.712758\tvalid_0's binary_logloss: 0.250496\n",
      "[201]\tvalid_0's auc: 0.712699\tvalid_0's binary_logloss: 0.250497\n",
      "[202]\tvalid_0's auc: 0.713297\tvalid_0's binary_logloss: 0.250434\n",
      "[203]\tvalid_0's auc: 0.713132\tvalid_0's binary_logloss: 0.250446\n",
      "[204]\tvalid_0's auc: 0.713272\tvalid_0's binary_logloss: 0.250421\n",
      "[205]\tvalid_0's auc: 0.713167\tvalid_0's binary_logloss: 0.250427\n",
      "[206]\tvalid_0's auc: 0.713388\tvalid_0's binary_logloss: 0.2504\n",
      "[207]\tvalid_0's auc: 0.713195\tvalid_0's binary_logloss: 0.250384\n",
      "[208]\tvalid_0's auc: 0.713713\tvalid_0's binary_logloss: 0.250298\n",
      "[209]\tvalid_0's auc: 0.713685\tvalid_0's binary_logloss: 0.250295\n",
      "[210]\tvalid_0's auc: 0.713559\tvalid_0's binary_logloss: 0.250325\n",
      "[211]\tvalid_0's auc: 0.713636\tvalid_0's binary_logloss: 0.250314\n",
      "[212]\tvalid_0's auc: 0.713688\tvalid_0's binary_logloss: 0.250295\n",
      "[213]\tvalid_0's auc: 0.713748\tvalid_0's binary_logloss: 0.250271\n",
      "[214]\tvalid_0's auc: 0.714213\tvalid_0's binary_logloss: 0.250211\n",
      "[215]\tvalid_0's auc: 0.714055\tvalid_0's binary_logloss: 0.250192\n",
      "[216]\tvalid_0's auc: 0.714006\tvalid_0's binary_logloss: 0.250189\n",
      "[217]\tvalid_0's auc: 0.714307\tvalid_0's binary_logloss: 0.250131\n",
      "[218]\tvalid_0's auc: 0.714325\tvalid_0's binary_logloss: 0.250137\n",
      "[219]\tvalid_0's auc: 0.714909\tvalid_0's binary_logloss: 0.250031\n",
      "[220]\tvalid_0's auc: 0.715153\tvalid_0's binary_logloss: 0.250019\n",
      "[221]\tvalid_0's auc: 0.714951\tvalid_0's binary_logloss: 0.250018\n",
      "[222]\tvalid_0's auc: 0.715035\tvalid_0's binary_logloss: 0.25002\n",
      "[223]\tvalid_0's auc: 0.715388\tvalid_0's binary_logloss: 0.249997\n",
      "[224]\tvalid_0's auc: 0.715227\tvalid_0's binary_logloss: 0.250017\n",
      "[225]\tvalid_0's auc: 0.715332\tvalid_0's binary_logloss: 0.249999\n",
      "[226]\tvalid_0's auc: 0.715566\tvalid_0's binary_logloss: 0.249957\n",
      "[227]\tvalid_0's auc: 0.715454\tvalid_0's binary_logloss: 0.249984\n",
      "[228]\tvalid_0's auc: 0.715314\tvalid_0's binary_logloss: 0.249944\n",
      "[229]\tvalid_0's auc: 0.714856\tvalid_0's binary_logloss: 0.249996\n",
      "[230]\tvalid_0's auc: 0.715069\tvalid_0's binary_logloss: 0.249959\n",
      "[231]\tvalid_0's auc: 0.714737\tvalid_0's binary_logloss: 0.250007\n",
      "[232]\tvalid_0's auc: 0.714804\tvalid_0's binary_logloss: 0.249968\n",
      "[233]\tvalid_0's auc: 0.714846\tvalid_0's binary_logloss: 0.249976\n",
      "[234]\tvalid_0's auc: 0.714975\tvalid_0's binary_logloss: 0.249997\n",
      "[235]\tvalid_0's auc: 0.714863\tvalid_0's binary_logloss: 0.250032\n",
      "[236]\tvalid_0's auc: 0.714723\tvalid_0's binary_logloss: 0.250046\n",
      "[237]\tvalid_0's auc: 0.714828\tvalid_0's binary_logloss: 0.250001\n",
      "[238]\tvalid_0's auc: 0.714853\tvalid_0's binary_logloss: 0.250019\n",
      "[239]\tvalid_0's auc: 0.714814\tvalid_0's binary_logloss: 0.25003\n",
      "[240]\tvalid_0's auc: 0.715195\tvalid_0's binary_logloss: 0.249994\n",
      "[241]\tvalid_0's auc: 0.71551\tvalid_0's binary_logloss: 0.249933\n",
      "[242]\tvalid_0's auc: 0.715814\tvalid_0's binary_logloss: 0.24987\n",
      "[243]\tvalid_0's auc: 0.715577\tvalid_0's binary_logloss: 0.249884\n",
      "[244]\tvalid_0's auc: 0.715521\tvalid_0's binary_logloss: 0.24991\n",
      "[245]\tvalid_0's auc: 0.715206\tvalid_0's binary_logloss: 0.249955\n",
      "[246]\tvalid_0's auc: 0.715244\tvalid_0's binary_logloss: 0.24994\n",
      "[247]\tvalid_0's auc: 0.714846\tvalid_0's binary_logloss: 0.249968\n",
      "[248]\tvalid_0's auc: 0.715157\tvalid_0's binary_logloss: 0.249932\n",
      "[249]\tvalid_0's auc: 0.715087\tvalid_0's binary_logloss: 0.249989\n",
      "[250]\tvalid_0's auc: 0.715374\tvalid_0's binary_logloss: 0.249905\n",
      "[251]\tvalid_0's auc: 0.715335\tvalid_0's binary_logloss: 0.249947\n",
      "[252]\tvalid_0's auc: 0.715349\tvalid_0's binary_logloss: 0.249913\n",
      "[253]\tvalid_0's auc: 0.715538\tvalid_0's binary_logloss: 0.249904\n",
      "[254]\tvalid_0's auc: 0.715398\tvalid_0's binary_logloss: 0.24993\n",
      "[255]\tvalid_0's auc: 0.715146\tvalid_0's binary_logloss: 0.249938\n",
      "[256]\tvalid_0's auc: 0.715356\tvalid_0's binary_logloss: 0.249908\n",
      "[257]\tvalid_0's auc: 0.715468\tvalid_0's binary_logloss: 0.249883\n",
      "[258]\tvalid_0's auc: 0.715552\tvalid_0's binary_logloss: 0.249909\n",
      "[259]\tvalid_0's auc: 0.715615\tvalid_0's binary_logloss: 0.249882\n",
      "[260]\tvalid_0's auc: 0.715678\tvalid_0's binary_logloss: 0.249886\n",
      "[261]\tvalid_0's auc: 0.715912\tvalid_0's binary_logloss: 0.24983\n",
      "[262]\tvalid_0's auc: 0.716126\tvalid_0's binary_logloss: 0.249806\n",
      "[263]\tvalid_0's auc: 0.715923\tvalid_0's binary_logloss: 0.249835\n",
      "[264]\tvalid_0's auc: 0.715891\tvalid_0's binary_logloss: 0.249818\n",
      "[265]\tvalid_0's auc: 0.71614\tvalid_0's binary_logloss: 0.249792\n",
      "[266]\tvalid_0's auc: 0.716181\tvalid_0's binary_logloss: 0.249819\n",
      "[267]\tvalid_0's auc: 0.716241\tvalid_0's binary_logloss: 0.24983\n",
      "[268]\tvalid_0's auc: 0.715989\tvalid_0's binary_logloss: 0.249868\n",
      "[269]\tvalid_0's auc: 0.715839\tvalid_0's binary_logloss: 0.249869\n",
      "[270]\tvalid_0's auc: 0.715832\tvalid_0's binary_logloss: 0.249872\n",
      "[271]\tvalid_0's auc: 0.716038\tvalid_0's binary_logloss: 0.249831\n",
      "[272]\tvalid_0's auc: 0.715996\tvalid_0's binary_logloss: 0.24981\n",
      "[273]\tvalid_0's auc: 0.716007\tvalid_0's binary_logloss: 0.249814\n",
      "[274]\tvalid_0's auc: 0.716112\tvalid_0's binary_logloss: 0.249812\n",
      "[275]\tvalid_0's auc: 0.716119\tvalid_0's binary_logloss: 0.249794\n",
      "[276]\tvalid_0's auc: 0.715804\tvalid_0's binary_logloss: 0.249848\n",
      "[277]\tvalid_0's auc: 0.715594\tvalid_0's binary_logloss: 0.24989\n",
      "[278]\tvalid_0's auc: 0.715779\tvalid_0's binary_logloss: 0.249812\n",
      "[279]\tvalid_0's auc: 0.715979\tvalid_0's binary_logloss: 0.249782\n",
      "[280]\tvalid_0's auc: 0.716014\tvalid_0's binary_logloss: 0.249784\n",
      "[281]\tvalid_0's auc: 0.716209\tvalid_0's binary_logloss: 0.249721\n",
      "[282]\tvalid_0's auc: 0.716255\tvalid_0's binary_logloss: 0.249715\n",
      "[283]\tvalid_0's auc: 0.716105\tvalid_0's binary_logloss: 0.24975\n",
      "[284]\tvalid_0's auc: 0.716014\tvalid_0's binary_logloss: 0.249767\n",
      "[285]\tvalid_0's auc: 0.7158\tvalid_0's binary_logloss: 0.249798\n",
      "[286]\tvalid_0's auc: 0.715769\tvalid_0's binary_logloss: 0.249785\n",
      "[287]\tvalid_0's auc: 0.715699\tvalid_0's binary_logloss: 0.24978\n",
      "[288]\tvalid_0's auc: 0.715542\tvalid_0's binary_logloss: 0.24978\n",
      "[289]\tvalid_0's auc: 0.715461\tvalid_0's binary_logloss: 0.24983\n",
      "[290]\tvalid_0's auc: 0.715895\tvalid_0's binary_logloss: 0.249782\n",
      "[291]\tvalid_0's auc: 0.715975\tvalid_0's binary_logloss: 0.249766\n",
      "[292]\tvalid_0's auc: 0.715804\tvalid_0's binary_logloss: 0.249801\n",
      "[293]\tvalid_0's auc: 0.71558\tvalid_0's binary_logloss: 0.249857\n",
      "[294]\tvalid_0's auc: 0.715685\tvalid_0's binary_logloss: 0.249817\n",
      "[295]\tvalid_0's auc: 0.715814\tvalid_0's binary_logloss: 0.249827\n",
      "[296]\tvalid_0's auc: 0.715657\tvalid_0's binary_logloss: 0.249873\n",
      "[297]\tvalid_0's auc: 0.715542\tvalid_0's binary_logloss: 0.249904\n",
      "[298]\tvalid_0's auc: 0.715825\tvalid_0's binary_logloss: 0.249879\n",
      "[299]\tvalid_0's auc: 0.715835\tvalid_0's binary_logloss: 0.249874\n",
      "[300]\tvalid_0's auc: 0.715821\tvalid_0's binary_logloss: 0.249885\n",
      "[301]\tvalid_0's auc: 0.715727\tvalid_0's binary_logloss: 0.249881\n",
      "[302]\tvalid_0's auc: 0.715591\tvalid_0's binary_logloss: 0.249928\n",
      "[303]\tvalid_0's auc: 0.715706\tvalid_0's binary_logloss: 0.249897\n",
      "[304]\tvalid_0's auc: 0.715692\tvalid_0's binary_logloss: 0.249937\n",
      "[305]\tvalid_0's auc: 0.715811\tvalid_0's binary_logloss: 0.249922\n",
      "[306]\tvalid_0's auc: 0.715811\tvalid_0's binary_logloss: 0.249917\n",
      "[307]\tvalid_0's auc: 0.715748\tvalid_0's binary_logloss: 0.249916\n",
      "[308]\tvalid_0's auc: 0.715629\tvalid_0's binary_logloss: 0.249899\n",
      "[309]\tvalid_0's auc: 0.715727\tvalid_0's binary_logloss: 0.249902\n",
      "[310]\tvalid_0's auc: 0.715706\tvalid_0's binary_logloss: 0.249895\n",
      "[311]\tvalid_0's auc: 0.715951\tvalid_0's binary_logloss: 0.249874\n",
      "[312]\tvalid_0's auc: 0.715972\tvalid_0's binary_logloss: 0.249831\n",
      "[313]\tvalid_0's auc: 0.716063\tvalid_0's binary_logloss: 0.249818\n",
      "[314]\tvalid_0's auc: 0.71614\tvalid_0's binary_logloss: 0.249797\n",
      "[315]\tvalid_0's auc: 0.716059\tvalid_0's binary_logloss: 0.249806\n",
      "[316]\tvalid_0's auc: 0.716122\tvalid_0's binary_logloss: 0.249814\n",
      "[317]\tvalid_0's auc: 0.716119\tvalid_0's binary_logloss: 0.249824\n",
      "[318]\tvalid_0's auc: 0.715986\tvalid_0's binary_logloss: 0.24984\n",
      "[319]\tvalid_0's auc: 0.715937\tvalid_0's binary_logloss: 0.249824\n",
      "[320]\tvalid_0's auc: 0.71586\tvalid_0's binary_logloss: 0.249854\n",
      "[321]\tvalid_0's auc: 0.716178\tvalid_0's binary_logloss: 0.249767\n",
      "[322]\tvalid_0's auc: 0.716129\tvalid_0's binary_logloss: 0.249772\n",
      "[323]\tvalid_0's auc: 0.71643\tvalid_0's binary_logloss: 0.249739\n",
      "[324]\tvalid_0's auc: 0.716342\tvalid_0's binary_logloss: 0.249729\n",
      "[325]\tvalid_0's auc: 0.716538\tvalid_0's binary_logloss: 0.249708\n",
      "[326]\tvalid_0's auc: 0.716195\tvalid_0's binary_logloss: 0.249743\n",
      "[327]\tvalid_0's auc: 0.715937\tvalid_0's binary_logloss: 0.249799\n",
      "[328]\tvalid_0's auc: 0.715954\tvalid_0's binary_logloss: 0.24982\n",
      "[329]\tvalid_0's auc: 0.71594\tvalid_0's binary_logloss: 0.24985\n",
      "[330]\tvalid_0's auc: 0.715944\tvalid_0's binary_logloss: 0.249854\n",
      "[331]\tvalid_0's auc: 0.715867\tvalid_0's binary_logloss: 0.249866\n",
      "[332]\tvalid_0's auc: 0.715923\tvalid_0's binary_logloss: 0.249868\n",
      "[333]\tvalid_0's auc: 0.715993\tvalid_0's binary_logloss: 0.249861\n",
      "[334]\tvalid_0's auc: 0.715797\tvalid_0's binary_logloss: 0.249877\n",
      "[335]\tvalid_0's auc: 0.716195\tvalid_0's binary_logloss: 0.249821\n",
      "[336]\tvalid_0's auc: 0.716318\tvalid_0's binary_logloss: 0.249801\n",
      "[337]\tvalid_0's auc: 0.716248\tvalid_0's binary_logloss: 0.249795\n",
      "[338]\tvalid_0's auc: 0.716237\tvalid_0's binary_logloss: 0.249776\n",
      "[339]\tvalid_0's auc: 0.716038\tvalid_0's binary_logloss: 0.249811\n",
      "[340]\tvalid_0's auc: 0.71622\tvalid_0's binary_logloss: 0.249776\n",
      "[341]\tvalid_0's auc: 0.716346\tvalid_0's binary_logloss: 0.249756\n",
      "[342]\tvalid_0's auc: 0.71637\tvalid_0's binary_logloss: 0.24976\n",
      "[343]\tvalid_0's auc: 0.716202\tvalid_0's binary_logloss: 0.249797\n",
      "[344]\tvalid_0's auc: 0.716363\tvalid_0's binary_logloss: 0.249776\n",
      "[345]\tvalid_0's auc: 0.716514\tvalid_0's binary_logloss: 0.249787\n",
      "[346]\tvalid_0's auc: 0.716594\tvalid_0's binary_logloss: 0.2498\n",
      "[347]\tvalid_0's auc: 0.716629\tvalid_0's binary_logloss: 0.249772\n",
      "[348]\tvalid_0's auc: 0.717003\tvalid_0's binary_logloss: 0.249735\n",
      "[349]\tvalid_0's auc: 0.717115\tvalid_0's binary_logloss: 0.249715\n",
      "[350]\tvalid_0's auc: 0.71714\tvalid_0's binary_logloss: 0.249719\n",
      "[351]\tvalid_0's auc: 0.717213\tvalid_0's binary_logloss: 0.249721\n",
      "[352]\tvalid_0's auc: 0.71737\tvalid_0's binary_logloss: 0.249708\n",
      "[353]\tvalid_0's auc: 0.717587\tvalid_0's binary_logloss: 0.249693\n",
      "[354]\tvalid_0's auc: 0.717423\tvalid_0's binary_logloss: 0.249712\n",
      "[355]\tvalid_0's auc: 0.717199\tvalid_0's binary_logloss: 0.249753\n",
      "[356]\tvalid_0's auc: 0.716919\tvalid_0's binary_logloss: 0.249758\n",
      "[357]\tvalid_0's auc: 0.717077\tvalid_0's binary_logloss: 0.249723\n",
      "[358]\tvalid_0's auc: 0.717248\tvalid_0's binary_logloss: 0.249688\n",
      "[359]\tvalid_0's auc: 0.717339\tvalid_0's binary_logloss: 0.2497\n",
      "[360]\tvalid_0's auc: 0.717143\tvalid_0's binary_logloss: 0.249746\n",
      "[361]\tvalid_0's auc: 0.717073\tvalid_0's binary_logloss: 0.249736\n",
      "[362]\tvalid_0's auc: 0.717192\tvalid_0's binary_logloss: 0.249722\n",
      "[363]\tvalid_0's auc: 0.717189\tvalid_0's binary_logloss: 0.249744\n",
      "[364]\tvalid_0's auc: 0.717356\tvalid_0's binary_logloss: 0.249754\n",
      "[365]\tvalid_0's auc: 0.717307\tvalid_0's binary_logloss: 0.249796\n",
      "[366]\tvalid_0's auc: 0.716804\tvalid_0's binary_logloss: 0.249849\n",
      "[367]\tvalid_0's auc: 0.716856\tvalid_0's binary_logloss: 0.249828\n",
      "[368]\tvalid_0's auc: 0.716682\tvalid_0's binary_logloss: 0.249856\n",
      "[369]\tvalid_0's auc: 0.716703\tvalid_0's binary_logloss: 0.249836\n",
      "[370]\tvalid_0's auc: 0.7165\tvalid_0's binary_logloss: 0.249886\n",
      "[371]\tvalid_0's auc: 0.716283\tvalid_0's binary_logloss: 0.24996\n",
      "[372]\tvalid_0's auc: 0.716017\tvalid_0's binary_logloss: 0.249993\n",
      "[373]\tvalid_0's auc: 0.716101\tvalid_0's binary_logloss: 0.249993\n",
      "[374]\tvalid_0's auc: 0.715898\tvalid_0's binary_logloss: 0.250016\n",
      "[375]\tvalid_0's auc: 0.716024\tvalid_0's binary_logloss: 0.250003\n",
      "[376]\tvalid_0's auc: 0.716328\tvalid_0's binary_logloss: 0.249963\n",
      "[377]\tvalid_0's auc: 0.716192\tvalid_0's binary_logloss: 0.249999\n",
      "[378]\tvalid_0's auc: 0.716066\tvalid_0's binary_logloss: 0.25001\n",
      "[379]\tvalid_0's auc: 0.716056\tvalid_0's binary_logloss: 0.250009\n",
      "[380]\tvalid_0's auc: 0.716112\tvalid_0's binary_logloss: 0.249988\n",
      "[381]\tvalid_0's auc: 0.716126\tvalid_0's binary_logloss: 0.249998\n",
      "[382]\tvalid_0's auc: 0.716188\tvalid_0's binary_logloss: 0.249962\n",
      "[383]\tvalid_0's auc: 0.716234\tvalid_0's binary_logloss: 0.249956\n",
      "[384]\tvalid_0's auc: 0.716479\tvalid_0's binary_logloss: 0.24994\n",
      "[385]\tvalid_0's auc: 0.716381\tvalid_0's binary_logloss: 0.249937\n",
      "[386]\tvalid_0's auc: 0.71607\tvalid_0's binary_logloss: 0.249992\n",
      "[387]\tvalid_0's auc: 0.71608\tvalid_0's binary_logloss: 0.249999\n",
      "[388]\tvalid_0's auc: 0.716024\tvalid_0's binary_logloss: 0.25\n",
      "[389]\tvalid_0's auc: 0.715737\tvalid_0's binary_logloss: 0.250037\n",
      "[390]\tvalid_0's auc: 0.715636\tvalid_0's binary_logloss: 0.25006\n",
      "[391]\tvalid_0's auc: 0.715489\tvalid_0's binary_logloss: 0.250109\n",
      "[392]\tvalid_0's auc: 0.715507\tvalid_0's binary_logloss: 0.250108\n",
      "[393]\tvalid_0's auc: 0.715409\tvalid_0's binary_logloss: 0.250119\n",
      "[394]\tvalid_0's auc: 0.715272\tvalid_0's binary_logloss: 0.250144\n",
      "[395]\tvalid_0's auc: 0.715304\tvalid_0's binary_logloss: 0.250183\n",
      "[396]\tvalid_0's auc: 0.715157\tvalid_0's binary_logloss: 0.250212\n",
      "[397]\tvalid_0's auc: 0.715111\tvalid_0's binary_logloss: 0.250214\n",
      "[398]\tvalid_0's auc: 0.71522\tvalid_0's binary_logloss: 0.250232\n",
      "[399]\tvalid_0's auc: 0.715066\tvalid_0's binary_logloss: 0.25026\n",
      "[400]\tvalid_0's auc: 0.715094\tvalid_0's binary_logloss: 0.250266\n",
      "[401]\tvalid_0's auc: 0.714842\tvalid_0's binary_logloss: 0.250291\n",
      "[402]\tvalid_0's auc: 0.714678\tvalid_0's binary_logloss: 0.250319\n",
      "[403]\tvalid_0's auc: 0.714856\tvalid_0's binary_logloss: 0.250301\n",
      "[404]\tvalid_0's auc: 0.714804\tvalid_0's binary_logloss: 0.250308\n",
      "[405]\tvalid_0's auc: 0.714618\tvalid_0's binary_logloss: 0.250339\n",
      "[406]\tvalid_0's auc: 0.714559\tvalid_0's binary_logloss: 0.25035\n",
      "[407]\tvalid_0's auc: 0.714454\tvalid_0's binary_logloss: 0.250382\n",
      "[408]\tvalid_0's auc: 0.714548\tvalid_0's binary_logloss: 0.250395\n",
      "[409]\tvalid_0's auc: 0.714409\tvalid_0's binary_logloss: 0.250422\n",
      "[410]\tvalid_0's auc: 0.714353\tvalid_0's binary_logloss: 0.250463\n",
      "[411]\tvalid_0's auc: 0.714297\tvalid_0's binary_logloss: 0.250449\n",
      "[412]\tvalid_0's auc: 0.714562\tvalid_0's binary_logloss: 0.250406\n",
      "[413]\tvalid_0's auc: 0.714433\tvalid_0's binary_logloss: 0.250421\n",
      "[414]\tvalid_0's auc: 0.714416\tvalid_0's binary_logloss: 0.250467\n",
      "[415]\tvalid_0's auc: 0.714384\tvalid_0's binary_logloss: 0.250471\n",
      "[416]\tvalid_0's auc: 0.71451\tvalid_0's binary_logloss: 0.250457\n",
      "[417]\tvalid_0's auc: 0.714388\tvalid_0's binary_logloss: 0.250503\n",
      "[418]\tvalid_0's auc: 0.714262\tvalid_0's binary_logloss: 0.250521\n",
      "[419]\tvalid_0's auc: 0.714353\tvalid_0's binary_logloss: 0.250517\n",
      "[420]\tvalid_0's auc: 0.714353\tvalid_0's binary_logloss: 0.250526\n",
      "[421]\tvalid_0's auc: 0.714541\tvalid_0's binary_logloss: 0.250501\n",
      "[422]\tvalid_0's auc: 0.714503\tvalid_0's binary_logloss: 0.250515\n",
      "[423]\tvalid_0's auc: 0.714514\tvalid_0's binary_logloss: 0.250503\n",
      "[424]\tvalid_0's auc: 0.714356\tvalid_0's binary_logloss: 0.250538\n",
      "[425]\tvalid_0's auc: 0.714489\tvalid_0's binary_logloss: 0.250501\n",
      "[426]\tvalid_0's auc: 0.714562\tvalid_0's binary_logloss: 0.250528\n",
      "[427]\tvalid_0's auc: 0.71416\tvalid_0's binary_logloss: 0.250575\n",
      "[428]\tvalid_0's auc: 0.714405\tvalid_0's binary_logloss: 0.250557\n",
      "[429]\tvalid_0's auc: 0.714321\tvalid_0's binary_logloss: 0.250587\n",
      "[430]\tvalid_0's auc: 0.714409\tvalid_0's binary_logloss: 0.250578\n",
      "[431]\tvalid_0's auc: 0.714437\tvalid_0's binary_logloss: 0.250553\n",
      "[432]\tvalid_0's auc: 0.714832\tvalid_0's binary_logloss: 0.25047\n",
      "[433]\tvalid_0's auc: 0.714877\tvalid_0's binary_logloss: 0.25046\n",
      "[434]\tvalid_0's auc: 0.714912\tvalid_0's binary_logloss: 0.250469\n",
      "[435]\tvalid_0's auc: 0.714979\tvalid_0's binary_logloss: 0.250473\n",
      "[436]\tvalid_0's auc: 0.715087\tvalid_0's binary_logloss: 0.250478\n",
      "[437]\tvalid_0's auc: 0.714758\tvalid_0's binary_logloss: 0.250527\n",
      "[438]\tvalid_0's auc: 0.714562\tvalid_0's binary_logloss: 0.250569\n",
      "[439]\tvalid_0's auc: 0.714667\tvalid_0's binary_logloss: 0.250531\n",
      "[440]\tvalid_0's auc: 0.714755\tvalid_0's binary_logloss: 0.250535\n",
      "[441]\tvalid_0's auc: 0.714877\tvalid_0's binary_logloss: 0.250528\n",
      "[442]\tvalid_0's auc: 0.714944\tvalid_0's binary_logloss: 0.250503\n",
      "[443]\tvalid_0's auc: 0.715007\tvalid_0's binary_logloss: 0.2505\n",
      "[444]\tvalid_0's auc: 0.714968\tvalid_0's binary_logloss: 0.250507\n",
      "[445]\tvalid_0's auc: 0.714972\tvalid_0's binary_logloss: 0.250513\n",
      "[446]\tvalid_0's auc: 0.715024\tvalid_0's binary_logloss: 0.250485\n",
      "[447]\tvalid_0's auc: 0.715132\tvalid_0's binary_logloss: 0.250489\n",
      "[448]\tvalid_0's auc: 0.715157\tvalid_0's binary_logloss: 0.250489\n",
      "[449]\tvalid_0's auc: 0.715167\tvalid_0's binary_logloss: 0.250519\n",
      "[450]\tvalid_0's auc: 0.715017\tvalid_0's binary_logloss: 0.250574\n",
      "[451]\tvalid_0's auc: 0.714898\tvalid_0's binary_logloss: 0.250633\n",
      "[452]\tvalid_0's auc: 0.714993\tvalid_0's binary_logloss: 0.250612\n",
      "[453]\tvalid_0's auc: 0.714926\tvalid_0's binary_logloss: 0.250627\n",
      "[454]\tvalid_0's auc: 0.714937\tvalid_0's binary_logloss: 0.250625\n",
      "[455]\tvalid_0's auc: 0.714972\tvalid_0's binary_logloss: 0.250602\n",
      "[456]\tvalid_0's auc: 0.71494\tvalid_0's binary_logloss: 0.250624\n",
      "[457]\tvalid_0's auc: 0.715167\tvalid_0's binary_logloss: 0.25061\n",
      "[458]\tvalid_0's auc: 0.715244\tvalid_0's binary_logloss: 0.25065\n",
      "[459]\tvalid_0's auc: 0.715374\tvalid_0's binary_logloss: 0.250638\n",
      "[460]\tvalid_0's auc: 0.715321\tvalid_0's binary_logloss: 0.250647\n",
      "[461]\tvalid_0's auc: 0.715167\tvalid_0's binary_logloss: 0.250661\n",
      "[462]\tvalid_0's auc: 0.715377\tvalid_0's binary_logloss: 0.250651\n",
      "[463]\tvalid_0's auc: 0.715363\tvalid_0's binary_logloss: 0.250639\n",
      "[464]\tvalid_0's auc: 0.715199\tvalid_0's binary_logloss: 0.250696\n",
      "[465]\tvalid_0's auc: 0.715227\tvalid_0's binary_logloss: 0.250721\n",
      "[466]\tvalid_0's auc: 0.715202\tvalid_0's binary_logloss: 0.250746\n",
      "[467]\tvalid_0's auc: 0.715269\tvalid_0's binary_logloss: 0.250738\n",
      "[468]\tvalid_0's auc: 0.715262\tvalid_0's binary_logloss: 0.250726\n",
      "[469]\tvalid_0's auc: 0.715339\tvalid_0's binary_logloss: 0.250707\n",
      "[470]\tvalid_0's auc: 0.71536\tvalid_0's binary_logloss: 0.250737\n",
      "[471]\tvalid_0's auc: 0.715056\tvalid_0's binary_logloss: 0.25078\n",
      "[472]\tvalid_0's auc: 0.715076\tvalid_0's binary_logloss: 0.250741\n",
      "[473]\tvalid_0's auc: 0.715143\tvalid_0's binary_logloss: 0.250728\n",
      "[474]\tvalid_0's auc: 0.715325\tvalid_0's binary_logloss: 0.25073\n",
      "[475]\tvalid_0's auc: 0.715195\tvalid_0's binary_logloss: 0.250735\n",
      "[476]\tvalid_0's auc: 0.715188\tvalid_0's binary_logloss: 0.2507\n",
      "[477]\tvalid_0's auc: 0.715042\tvalid_0's binary_logloss: 0.250764\n",
      "[478]\tvalid_0's auc: 0.714825\tvalid_0's binary_logloss: 0.250831\n",
      "[479]\tvalid_0's auc: 0.714643\tvalid_0's binary_logloss: 0.250879\n",
      "[480]\tvalid_0's auc: 0.714958\tvalid_0's binary_logloss: 0.250818\n",
      "[481]\tvalid_0's auc: 0.714748\tvalid_0's binary_logloss: 0.250869\n",
      "[482]\tvalid_0's auc: 0.71473\tvalid_0's binary_logloss: 0.250909\n",
      "[483]\tvalid_0's auc: 0.714552\tvalid_0's binary_logloss: 0.250955\n",
      "[484]\tvalid_0's auc: 0.714332\tvalid_0's binary_logloss: 0.250982\n",
      "[485]\tvalid_0's auc: 0.714388\tvalid_0's binary_logloss: 0.250958\n",
      "[486]\tvalid_0's auc: 0.714384\tvalid_0's binary_logloss: 0.250953\n",
      "[487]\tvalid_0's auc: 0.714167\tvalid_0's binary_logloss: 0.250993\n",
      "[488]\tvalid_0's auc: 0.71429\tvalid_0's binary_logloss: 0.250982\n",
      "[489]\tvalid_0's auc: 0.714447\tvalid_0's binary_logloss: 0.250974\n",
      "[490]\tvalid_0's auc: 0.714604\tvalid_0's binary_logloss: 0.250957\n",
      "[491]\tvalid_0's auc: 0.714685\tvalid_0's binary_logloss: 0.250977\n",
      "[492]\tvalid_0's auc: 0.714804\tvalid_0's binary_logloss: 0.250963\n",
      "[493]\tvalid_0's auc: 0.714604\tvalid_0's binary_logloss: 0.251004\n",
      "[494]\tvalid_0's auc: 0.714646\tvalid_0's binary_logloss: 0.251013\n",
      "[495]\tvalid_0's auc: 0.714783\tvalid_0's binary_logloss: 0.250979\n",
      "[496]\tvalid_0's auc: 0.715014\tvalid_0's binary_logloss: 0.250968\n",
      "[497]\tvalid_0's auc: 0.71508\tvalid_0's binary_logloss: 0.250955\n",
      "[498]\tvalid_0's auc: 0.715115\tvalid_0's binary_logloss: 0.25095\n",
      "[499]\tvalid_0's auc: 0.71515\tvalid_0's binary_logloss: 0.25092\n",
      "[500]\tvalid_0's auc: 0.714972\tvalid_0's binary_logloss: 0.250955\n",
      "[501]\tvalid_0's auc: 0.714968\tvalid_0's binary_logloss: 0.25099\n",
      "[502]\tvalid_0's auc: 0.714783\tvalid_0's binary_logloss: 0.251026\n",
      "[503]\tvalid_0's auc: 0.714664\tvalid_0's binary_logloss: 0.251053\n",
      "[504]\tvalid_0's auc: 0.714587\tvalid_0's binary_logloss: 0.251063\n",
      "[505]\tvalid_0's auc: 0.714496\tvalid_0's binary_logloss: 0.251109\n",
      "[506]\tvalid_0's auc: 0.714335\tvalid_0's binary_logloss: 0.251168\n",
      "[507]\tvalid_0's auc: 0.714342\tvalid_0's binary_logloss: 0.25118\n",
      "[508]\tvalid_0's auc: 0.714433\tvalid_0's binary_logloss: 0.251164\n",
      "[509]\tvalid_0's auc: 0.714727\tvalid_0's binary_logloss: 0.25111\n",
      "[510]\tvalid_0's auc: 0.714709\tvalid_0's binary_logloss: 0.251146\n",
      "[511]\tvalid_0's auc: 0.714562\tvalid_0's binary_logloss: 0.251176\n",
      "[512]\tvalid_0's auc: 0.714486\tvalid_0's binary_logloss: 0.251186\n",
      "[513]\tvalid_0's auc: 0.714409\tvalid_0's binary_logloss: 0.251227\n",
      "[514]\tvalid_0's auc: 0.714178\tvalid_0's binary_logloss: 0.251265\n",
      "[515]\tvalid_0's auc: 0.714213\tvalid_0's binary_logloss: 0.251295\n",
      "[516]\tvalid_0's auc: 0.714174\tvalid_0's binary_logloss: 0.25129\n",
      "[517]\tvalid_0's auc: 0.714083\tvalid_0's binary_logloss: 0.251341\n",
      "[518]\tvalid_0's auc: 0.713912\tvalid_0's binary_logloss: 0.251381\n",
      "[519]\tvalid_0's auc: 0.713709\tvalid_0's binary_logloss: 0.251431\n",
      "[520]\tvalid_0's auc: 0.713639\tvalid_0's binary_logloss: 0.251448\n",
      "[521]\tvalid_0's auc: 0.713552\tvalid_0's binary_logloss: 0.251475\n",
      "[522]\tvalid_0's auc: 0.713559\tvalid_0's binary_logloss: 0.251476\n",
      "[523]\tvalid_0's auc: 0.713538\tvalid_0's binary_logloss: 0.251484\n",
      "[524]\tvalid_0's auc: 0.713597\tvalid_0's binary_logloss: 0.251494\n",
      "[525]\tvalid_0's auc: 0.713492\tvalid_0's binary_logloss: 0.25156\n",
      "[526]\tvalid_0's auc: 0.713608\tvalid_0's binary_logloss: 0.251568\n",
      "[527]\tvalid_0's auc: 0.71337\tvalid_0's binary_logloss: 0.251608\n",
      "[528]\tvalid_0's auc: 0.713167\tvalid_0's binary_logloss: 0.251648\n",
      "[529]\tvalid_0's auc: 0.713129\tvalid_0's binary_logloss: 0.251686\n",
      "[530]\tvalid_0's auc: 0.713111\tvalid_0's binary_logloss: 0.251679\n",
      "[531]\tvalid_0's auc: 0.713276\tvalid_0's binary_logloss: 0.251687\n",
      "[532]\tvalid_0's auc: 0.7133\tvalid_0's binary_logloss: 0.251675\n",
      "[533]\tvalid_0's auc: 0.713136\tvalid_0's binary_logloss: 0.251716\n",
      "[534]\tvalid_0's auc: 0.713069\tvalid_0's binary_logloss: 0.251767\n",
      "[535]\tvalid_0's auc: 0.713108\tvalid_0's binary_logloss: 0.251798\n",
      "[536]\tvalid_0's auc: 0.712992\tvalid_0's binary_logloss: 0.25182\n",
      "[537]\tvalid_0's auc: 0.712985\tvalid_0's binary_logloss: 0.25181\n",
      "[538]\tvalid_0's auc: 0.713069\tvalid_0's binary_logloss: 0.251817\n",
      "[539]\tvalid_0's auc: 0.71323\tvalid_0's binary_logloss: 0.251795\n",
      "[540]\tvalid_0's auc: 0.713139\tvalid_0's binary_logloss: 0.251798\n",
      "[541]\tvalid_0's auc: 0.713048\tvalid_0's binary_logloss: 0.251804\n",
      "[542]\tvalid_0's auc: 0.712769\tvalid_0's binary_logloss: 0.251863\n",
      "[543]\tvalid_0's auc: 0.712786\tvalid_0's binary_logloss: 0.251837\n",
      "[544]\tvalid_0's auc: 0.712901\tvalid_0's binary_logloss: 0.251828\n",
      "[545]\tvalid_0's auc: 0.713006\tvalid_0's binary_logloss: 0.251816\n",
      "[546]\tvalid_0's auc: 0.712933\tvalid_0's binary_logloss: 0.251833\n",
      "[547]\tvalid_0's auc: 0.713059\tvalid_0's binary_logloss: 0.251795\n",
      "[548]\tvalid_0's auc: 0.712887\tvalid_0's binary_logloss: 0.251828\n",
      "[549]\tvalid_0's auc: 0.712908\tvalid_0's binary_logloss: 0.251841\n",
      "[550]\tvalid_0's auc: 0.713017\tvalid_0's binary_logloss: 0.251849\n",
      "[551]\tvalid_0's auc: 0.712786\tvalid_0's binary_logloss: 0.251913\n",
      "[552]\tvalid_0's auc: 0.712685\tvalid_0's binary_logloss: 0.251934\n",
      "[553]\tvalid_0's auc: 0.712807\tvalid_0's binary_logloss: 0.251898\n",
      "Early stopping, best iteration is:\n",
      "[353]\tvalid_0's auc: 0.717587\tvalid_0's binary_logloss: 0.249693\n"
     ]
    }
   ],
   "source": [
    "lgbc=LGBMClassifier(**default_params)\n",
    "lgbc.fit(first_level_output, train_target, eval_set=(first_level_output_test, test_target), eval_metric = 'auc')\n",
    "predicted_train = lgbc.predict_proba(first_level_output)\n",
    "predicted_test = lgbc.predict_proba(first_level_output_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "057c468f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7175872016784683"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_target.values, predicted_test[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a63e87af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.960137750397698"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(train_target.values, predicted_train[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d53dc8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a695edef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09521cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c6ae7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a9f4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
