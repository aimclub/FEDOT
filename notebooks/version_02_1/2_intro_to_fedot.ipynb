{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "644190b0",
   "metadata": {},
   "source": [
    "# FEDOT framework\n",
    "#### FEDOT version = 0.2.1\n",
    "\n",
    "Below is a description of the FEDOT framework and its main functions, which can be used to solve various ML tasks, namely:\n",
    "\n",
    "* Regression\n",
    "* Classification\n",
    "* Time series forecasting\n",
    "* Clustering\n",
    "\n",
    "FEDOT can construct complex composite models (consisting of multiple machine learning models and preprocessing operations) based on an evolutionary algorithm. Thus, it is possible to create pipelines for solving various tasks.\n",
    "\n",
    "The structure of the FEDOT framework can be seen in the figure below:\n",
    "\n",
    "![fedot_structure.png](../jupyter_media/fedot_structure/fedot_structure_02.png)\n",
    "\n",
    "Figure 1. The structure of the FEDOT framework. The main modules of the library are shown.\n",
    "\n",
    "As you can see from the picture there are two ways to start FEDOT:\n",
    "1) API - allows you to run framework models in a few lines of code;\n",
    "2) Low-level methods from the core - you can call methods by accessing the core directly. In this case, you will have to write more code, but more functionality opens up.\n",
    "\n",
    "## Composite models\n",
    "\n",
    "FEDOT has following abstractions:\n",
    "* Model - is a machine learning model, exactly the same models we can use with [scikit-learn](https://scikit-learn.org/stable/) for example;\n",
    "* Node - is a container in which the model is placed. Data preprocessing, feature scaling operations are performed in the nodes. A single node can contain only one model;\n",
    "* Chain - is directed acyclic graph-like structure that contains several connected nodes. The analogue can be a computation graph from tensorflow, or simple workflow (from Apache Airflow, for instance). Chains are complex composite models. A single chain can consist of multiple nodes, or a single node.\n",
    "\n",
    "![model_node_chain.png](../jupyter_media/fedot_structure/model_node_chain.png)\n",
    "\n",
    "## Generate synthetic dataset for classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9aec2fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features table shape: (250, 3), type: <class 'numpy.ndarray'>\n",
      "Target vector: (250,), type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from fedot.utilities.synthetic.data import classification_dataset\n",
    "from sklearn.metrics import roc_auc_score as roc_auc\n",
    "\n",
    "# Generate numpy arrays with features and target\n",
    "features_options = {'informative': 1, 'redundant': 0,\n",
    "                    'repeated': 0, 'clusters_per_class': 1}\n",
    "x_data, y_data = classification_dataset(samples_amount=250,\n",
    "                                        features_amount=3,\n",
    "                                        classes_amount=2,\n",
    "                                        features_options=features_options)\n",
    "\n",
    "print(f'Features table shape: {x_data.shape}, type: {type(x_data)}')\n",
    "print(f'Target vector: {y_data.shape}, type: {type(y_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d332d747-aee2-4b4f-b0a6-2bcaa88ce91e",
   "metadata": {},
   "source": [
    "Prepare the necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ba213ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "# Create chain\n",
    "from fedot.core.chains.chain import Chain\n",
    "from fedot.core.chains.node import PrimaryNode, SecondaryNode\n",
    "\n",
    "# Tasks to solve\n",
    "from fedot.core.repository.tasks import Task, TaskTypesEnum\n",
    "\n",
    "# Dataclass for wrapping arrays into it\n",
    "from fedot.core.data.data import InputData\n",
    "\n",
    "# Type of the input data\n",
    "from fedot.core.repository.dataset_types import DataTypesEnum\n",
    "\n",
    "# Define classification task\n",
    "task = Task(TaskTypesEnum.classification)\n",
    "\n",
    "# Prepare data to train the model\n",
    "input_data = InputData(idx=np.arange(0, len(x_data)), features=x_data,\n",
    "                       target=y_data, task=task,\n",
    "                       data_type=DataTypesEnum.table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cf564f",
   "metadata": {},
   "source": [
    "## Manual chain \n",
    "\n",
    "Below, we will try to set the chain manually, and obtain a prediction using it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9585958c-118c-447c-8ba4-f82722ca2d2d",
   "metadata": {},
   "source": [
    "Manually create a chain of the following configuration:\n",
    "\n",
    "![logit_scaling_lda.png](../jupyter_media/fedot_structure/logit_qda_lda.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9eabcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score on training sample: 0.934\n"
     ]
    }
   ],
   "source": [
    "# Define chain \n",
    "node_logit = PrimaryNode('logit')\n",
    "node_qda = PrimaryNode('qda')\n",
    "node_logit = SecondaryNode('lda', nodes_from=[node_logit, node_qda])\n",
    "chain = Chain(node_logit)\n",
    "\n",
    "# Fit it\n",
    "chain.fit(input_data)\n",
    "\n",
    "# Make prediction\n",
    "predicted_output = chain.predict(input_data)\n",
    "\n",
    "# Check metric value\n",
    "print(f'ROC AUC score on training sample: {roc_auc(y_data, predicted_output.predict):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f496339",
   "metadata": {},
   "source": [
    "This is how you learned the concept of chains in FEDOT.\n",
    "\n",
    "But FEDOT can automatically construct such chains to solve the task.\n",
    "\n",
    "Below are two examples for solving the classification task (with such chains) using API methods and using FEDOT.core function directly. Both examples, regardless of the way they interact, run an automatic machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1595e643",
   "metadata": {},
   "source": [
    "## AutoML\n",
    "\n",
    "### API example\n",
    "\n",
    "Using the API allows you to find good solutions using a few lines of code, but on the other hand, this approach has less abilities for modification than using core-based methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b8f0ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light_tun preset is used. Parameters tuning: True. Set of candidate models: ['logit', 'lda', 'qda', 'dt', 'rf', 'knn', 'xgboost', 'bernb', 'direct_data_model', 'pca_data_model']. Composing time limit: 0:01:00\n",
      "Model composition started\n",
      "Hyperparameters tuning started\n",
      "Start tuning of primary nodes\n",
      "End tuning\n",
      "Model composition finished\n",
      "Fit chain from scratch\n"
     ]
    }
   ],
   "source": [
    "from fedot.api.main import Fedot\n",
    "\n",
    "# Task selection, initialisation of the framework\n",
    "fedot_model = Fedot(problem='classification', learning_time=1,\n",
    "                    seed=42, verbose_level=4)\n",
    "\n",
    "# During fit, the chain composition algorithm is started\n",
    "pipeline = fedot_model.fit(features=x_data,\n",
    "                           target=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b144699c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'depth': 2, 'length': 3, 'nodes': [logit, qda, lda]}\n",
      "ROC AUC score on training sample: 0.877\n"
     ]
    }
   ],
   "source": [
    "prediction = fedot_model.predict_proba(features=x_data)\n",
    "print(pipeline)\n",
    "print(f'ROC AUC score on training sample: {roc_auc(y_data, prediction):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300574c6",
   "metadata": {},
   "source": [
    "### Core-based example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11124a4",
   "metadata": {},
   "source": [
    "We will transform the data into a specific format (InputData) for the algorithm launch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f236e0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np \n",
    "\n",
    "# Dataclass for wrapping arrays into it\n",
    "from fedot.core.data.data import InputData\n",
    "\n",
    "# Different tasks to solve\n",
    "from fedot.core.repository.tasks import Task, TaskTypesEnum\n",
    "\n",
    "# Type of the input data\n",
    "from fedot.core.repository.dataset_types import DataTypesEnum\n",
    "\n",
    "# Repository with models in the FEDOT\n",
    "from fedot.core.repository.model_types_repository import ModelTypesRepository\n",
    "\n",
    "# Chain of the FEDOT\n",
    "from fedot.core.chains.chain import Chain\n",
    "\n",
    "# Evolutionary algorithm classes \n",
    "from fedot.core.composer.gp_composer.gp_composer import GPComposerBuilder, GPComposerRequirements\n",
    "from fedot.core.composer.optimisers.gp_optimiser import GPChainOptimiserParameters, GeneticSchemeTypesEnum\n",
    "from fedot.core.repository.quality_metrics_repository import ClassificationMetricsEnum, MetricsRepository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc69aaf0",
   "metadata": {},
   "source": [
    "Let's define the task that we plan to solve-classification\n",
    "\n",
    "We will also wrap the data in a special structure-Input Data, where we will assign features, specify target, pass the data type (table) and the specified type of the task to be solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f4b599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classification task\n",
    "task = Task(TaskTypesEnum.classification)\n",
    "\n",
    "# Prepare data to train the model\n",
    "input_data = InputData(idx=np.arange(0, len(x_data)), features=x_data,\n",
    "                       target=y_data, task=task,\n",
    "                       data_type=DataTypesEnum.table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6955f6",
   "metadata": {},
   "source": [
    "Now we have identified the data and the task within which we will look for a solution.\n",
    "\n",
    "Next, we want to find a composite model (chain) of such a structure that predicts class labels as accurately as possible. We can determine from which models we can assemble such chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "237992a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logit',\n",
       " 'lda',\n",
       " 'qda',\n",
       " 'dt',\n",
       " 'rf',\n",
       " 'mlp',\n",
       " 'knn',\n",
       " 'xgboost',\n",
       " 'bernb',\n",
       " 'direct_data_model',\n",
       " 'pca_data_model']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The search of the models provided by the framework that can be used as nodes in a chain for the selected task\n",
    "models_repo = ModelTypesRepository()\n",
    "available_model_types, _ = models_repo.suitable_model(task_type=task.task_type)\n",
    "available_model_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd353a4c",
   "metadata": {},
   "source": [
    "Let's set the metric that we will use during the evolution process, select \"ROCAUC_penalty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08c40761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The choice of the metric for the chain quality assessment during composition\n",
    "metric_function = MetricsRepository().metric_by_id(ClassificationMetricsEnum.ROCAUC_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fefe348",
   "metadata": {},
   "source": [
    "#### GPComposer\n",
    "\n",
    "GPComposer is a genetic algorithm that allows you to search for optimal solutions by composing the chains of single machine learning models. \n",
    "\n",
    "Through GPComposerRequirements, we can set some hyperparameters to adjust the behavior of the evolutionary algorithm.\n",
    "\n",
    "With the help of GPComposerRequirements, you can manage:\n",
    "* types of models that can be inserted into primary nodes\n",
    "* types of models that can be inserted into secondary nodes\n",
    "* mutation probability\n",
    "* crossover probability\n",
    "* arity of directed acyclic graph (DAG)\n",
    "* maximum depth of the found chain\n",
    "* time to find a solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55fae208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The choice and initialisation of the GP search\n",
    "max_lead_time = datetime.timedelta(minutes=5)\n",
    "composer_requirements = GPComposerRequirements(\n",
    "    primary=available_model_types,\n",
    "    secondary=available_model_types, \n",
    "    max_arity=3,\n",
    "    max_depth=3, pop_size=10,\n",
    "    num_of_generations=10,\n",
    "    crossover_prob=0.8, \n",
    "    mutation_prob=0.8, \n",
    "    max_lead_time=max_lead_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c873bc7f",
   "metadata": {},
   "source": [
    "Below we will define the genetic scheme of the algorithm. \n",
    "\n",
    "There are several schemes:\n",
    "* steady_state - evolutionary scheme, also known as $(\\mu+\\lambda)$. New population is generated by using a selection operator which is applied to the union of the offspring and the previous population;\n",
    "* generational - the offspring completely replaces the parent population;\n",
    "* parameter_free - steady-state evolutionary scheme, but $\\mu$ (population size) changes during evolution like the Fibonacci sequence and $\\lambda$ always equals to the previous item of the sequence with respect to $\\mu$.\n",
    "\n",
    "For more information you can check [preprint](https://arxiv.org/abs/2103.01301).\n",
    "\n",
    "We will also use the GPComposerBuilder structure, which allows you to set parameters in GPComposer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91c14885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GP optimiser parameters choice\n",
    "scheme_type = GeneticSchemeTypesEnum.steady_state\n",
    "optimiser_parameters = GPChainOptimiserParameters(genetic_scheme_type=scheme_type)\n",
    "\n",
    "# Create builder for composer and set composer params\n",
    "builder = GPComposerBuilder(task=task).\\\n",
    "    with_requirements(composer_requirements).\\\n",
    "    with_metrics(metric_function).\\\n",
    "    with_optimiser_parameters(optimiser_parameters)\n",
    "\n",
    "# Create GP-based composer\n",
    "composer = builder.build()\n",
    "\n",
    "# the optimal chain generation by composition - the most time-consuming task\n",
    "chain_evo_composed = composer.compose_chain(data=input_data,\n",
    "                                            is_visualise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb0005",
   "metadata": {},
   "source": [
    "We got a chain of several machine learning models. But in the course of evolution, the hyperparameters of these models did not change. Now, within the given topology, we will optimize the hyperparameters. We will optimize only the primary nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5eaa717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning failed because of direct_data_model can not be fitted\n"
     ]
    }
   ],
   "source": [
    "chain_evo_composed.fine_tune_primary_nodes(input_data=input_data,\n",
    "                                           iterations=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acc19cc",
   "metadata": {},
   "source": [
    "Once again, we will train the chain on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76e042dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fitted = chain_evo_composed.fit(input_data=input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deeb761",
   "metadata": {},
   "source": [
    "Check the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e93fa8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score on training sample: 1.000\n"
     ]
    }
   ],
   "source": [
    "prediction = chain_evo_composed.predict(input_data)\n",
    "print(f'ROC AUC score on training sample: {roc_auc(y_data, prediction.predict):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2155b4e",
   "metadata": {},
   "source": [
    "As you can see from the metric value, the model was well trained on the training sample. \n",
    "\n",
    "So, in this notebook, you learned how to run FEDOT for the classification task, both using the API and using more complex constructs from the core based on the functionality of the FEDOT framework."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
